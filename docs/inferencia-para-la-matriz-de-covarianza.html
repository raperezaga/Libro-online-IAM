<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.8 Inferencia para la Matriz de Covarianza | Chapter 4</title>
  <meta name="description" content="Este libro contine ……" />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="4.8 Inferencia para la Matriz de Covarianza | Chapter 4" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/imagenes/imagen1.png" />
  <meta property="og:description" content="Este libro contine ……" />
  <meta name="github-repo" content="raperezaga/iam" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.8 Inferencia para la Matriz de Covarianza | Chapter 4" />
  
  <meta name="twitter:description" content="Este libro contine ……" />
  <meta name="twitter:image" content="/imagenes/imagen1.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"/>
<link rel="next" href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preámbulo</a>
<ul>
<li class="chapter" data-level="" data-path="dedicación.html"><a href="dedicación.html"><i class="fa fa-check"></i>Dedicación</a></li>
<li class="chapter" data-level="" data-path="agradecimientos.html"><a href="agradecimientos.html"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="paquetes-usados-en-el-libro.html"><a href="paquetes-usados-en-el-libro.html"><i class="fa fa-check"></i>Paquetes usados en el libro</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="rep_al.html"><a href="rep_al.html"><i class="fa fa-check"></i><b>1</b> Repaso de álgebra lineal</a>
<ul>
<li class="chapter" data-level="1.1" data-path="acb_al.html"><a href="acb_al.html"><i class="fa fa-check"></i><b>1.1</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="acb_al.html"><a href="acb_al.html#matrices"><i class="fa fa-check"></i><b>1.1.1</b> Matrices</a></li>
<li class="chapter" data-level="1.1.2" data-path="acb_al.html"><a href="acb_al.html#vectores"><i class="fa fa-check"></i><b>1.1.2</b> Vectores</a></li>
<li class="chapter" data-level="1.1.3" data-path="acb_al.html"><a href="acb_al.html#operaciones-matrices"><i class="fa fa-check"></i><b>1.1.3</b> Operaciones Matriciales</a></li>
<li class="chapter" data-level="1.1.4" data-path="acb_al.html"><a href="acb_al.html#matrices-especiales"><i class="fa fa-check"></i><b>1.1.4</b> Matrices Especiales</a></li>
<li class="chapter" data-level="1.1.5" data-path="acb_al.html"><a href="acb_al.html#descomp-espectral"><i class="fa fa-check"></i><b>1.1.5</b> Descomposición Espectral de una Matriz (eigen-descomposición)</a></li>
<li class="chapter" data-level="1.1.6" data-path="acb_al.html"><a href="acb_al.html#eigen-descom-msdp"><i class="fa fa-check"></i><b>1.1.6</b> Descomposición Espectral de Matrices Simétricas Definidas (o Semidefinidas) Positivas</a></li>
<li class="chapter" data-level="1.1.7" data-path="acb_al.html"><a href="acb_al.html#traza-determinante-y-rango-de-una-matriz"><i class="fa fa-check"></i><b>1.1.7</b> Traza, Determinante y Rango de una Matriz</a></li>
<li class="chapter" data-level="1.1.8" data-path="acb_al.html"><a href="acb_al.html#formas-cuadraticas"><i class="fa fa-check"></i><b>1.1.8</b> Formas Cuadráticas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="algunas-propiedades-estadísticas-de-la-eigen-descomposición-de-una-matriz.html"><a href="algunas-propiedades-estadísticas-de-la-eigen-descomposición-de-una-matriz.html"><i class="fa fa-check"></i><b>1.2</b> Algunas Propiedades Estadísticas de la Eigen-Descomposición de una Matriz</a></li>
<li class="chapter" data-level="1.3" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html"><i class="fa fa-check"></i><b>1.3</b> Diferenciación con Vectores y Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html#vector-gradiente-para-diferentes-definiciones-de-funderlinex"><i class="fa fa-check"></i><b>1.3.1</b> Vector-Gradiente para diferentes definiciones de <span class="math inline">\(f(\underline{x})\)</span>:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="org_pres_dat.html"><a href="org_pres_dat.html"><i class="fa fa-check"></i><b>2</b> Organización y Presentación de Datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html"><i class="fa fa-check"></i><b>2.1</b> Resumenes Descriptivos</a></li>
<li class="chapter" data-level="2.2" data-path="representación-gráfica-de-observaciones-multivariadas.html"><a href="representación-gráfica-de-observaciones-multivariadas.html"><i class="fa fa-check"></i><b>2.2</b> Representación Gráfica de Observaciones multivariadas</a></li>
<li class="chapter" data-level="2.3" data-path="vectores-y-matrices-aleatorias.html"><a href="vectores-y-matrices-aleatorias.html"><i class="fa fa-check"></i><b>2.3</b> Vectores y Matrices Aleatorias</a></li>
<li class="chapter" data-level="2.4" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html"><i class="fa fa-check"></i><b>2.4</b> Vectores y Matrices Poblacionales Particionados</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-del-vector-de-medias-poblacionales"><i class="fa fa-check"></i><b>2.4.1</b> Particionamiento del Vector de Medias-Poblacionales</a></li>
<li class="chapter" data-level="2.4.2" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-de-la-matriz-de-var-cov-poblacional-mathbfsigma"><i class="fa fa-check"></i><b>2.4.2</b> Particionamiento de la Matriz de Var-Cov Poblacional <span class="math inline">\(\mathbf{\Sigma}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.5</b> Propiedades Sobre la Media y Varianza de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.6" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html"><i class="fa fa-check"></i><b>2.6</b> Vectores y Matrices Muestrales Particionadas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-del-vector-de-medias-muestrales"><i class="fa fa-check"></i><b>2.6.1</b> Particionamiento del Vector de Medias Muestrales</a></li>
<li class="chapter" data-level="2.6.2" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-de-la-matriz-de-var-cov-muestrales"><i class="fa fa-check"></i><b>2.6.2</b> Particionamiento de la Matriz de Var-Cov Muestrales</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="algunas-formas-matriciales-eficientes.html"><a href="algunas-formas-matriciales-eficientes.html"><i class="fa fa-check"></i><b>2.7</b> Algunas formas matriciales Eficientes</a></li>
<li class="chapter" data-level="2.8" data-path="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.8</b> Propiedades Sobre la Media y Varianza Muestral de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.9" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><i class="fa fa-check"></i><b>2.9</b> Varianza Generalizada Muestral y su Interpretación Geométrica</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-1-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.9.1</b> Interpretación Geométrica-1 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.9.2" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-2-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.9.2</b> Interpretación Geométrica-2 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.9.3" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#varianza-generalizada-determinada-por-la-matriz-de-correlación-muestral-mathbfr"><i class="fa fa-check"></i><b>2.9.3</b> Varianza Generalizada Determinada por la Matriz de Correlación Muestral <span class="math inline">\(\mathbf{R}\)</span></a></li>
<li class="chapter" data-level="2.9.4" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#relación-entre-mathbfs-y-mathbfr"><i class="fa fa-check"></i><b>2.9.4</b> Relación entre <span class="math inline">\(|\mathbf{S}|\)</span> y <span class="math inline">\(|\mathbf{R}|\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="varianza-total-muestral.html"><a href="varianza-total-muestral.html"><i class="fa fa-check"></i><b>2.10</b> Varianza Total Muestral</a></li>
<li class="chapter" data-level="2.11" data-path="muestra-aleatoria-de-distribuciones-p-variadas.html"><a href="muestra-aleatoria-de-distribuciones-p-variadas.html"><i class="fa fa-check"></i><b>2.11</b> Muestra Aleatoria de Distribuciones <span class="math inline">\(p\)</span>-Variadas</a></li>
<li class="chapter" data-level="2.12" data-path="distancias.html"><a href="distancias.html"><i class="fa fa-check"></i><b>2.12</b> Distancias</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="distancias.html"><a href="distancias.html#definición-de-algunas-distancias"><i class="fa fa-check"></i><b>2.12.1</b> Definición de Algunas Distancias</a></li>
<li class="chapter" data-level="2.12.2" data-path="distancias.html"><a href="distancias.html#relación-de-la-distancia-de-mahalanobis-con-la-distribución-chi-cuadrado"><i class="fa fa-check"></i><b>2.12.2</b> Relación de la Distancia de Mahalanobis con la Distribución chi-Cuadrado</a></li>
<li class="chapter" data-level="2.12.3" data-path="distancias.html"><a href="distancias.html#ejemplo"><i class="fa fa-check"></i><b>2.12.3</b> Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Normal-Multiv.html"><a href="Normal-Multiv.html"><i class="fa fa-check"></i><b>3</b> Distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.1" data-path="geometria-NM.html"><a href="geometria-NM.html"><i class="fa fa-check"></i><b>3.1</b> Geometría y propiedades de la NM</a></li>
<li class="chapter" data-level="3.2" data-path="normal-univariada.html"><a href="normal-univariada.html"><i class="fa fa-check"></i><b>3.2</b> Normal Univariada</a></li>
<li class="chapter" data-level="3.3" data-path="normal-multivariada.html"><a href="normal-multivariada.html"><i class="fa fa-check"></i><b>3.3</b> Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="normal-multivariada.html"><a href="normal-multivariada.html#algunos-aspectos-geométricos-de-la-nm"><i class="fa fa-check"></i><b>3.3.1</b> Algunos Aspectos Geométricos de la NM</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="prop-nm.html"><a href="prop-nm.html"><i class="fa fa-check"></i><b>3.4</b> Propiedades de la distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="prop-nm.html"><a href="prop-nm.html#prop1"><i class="fa fa-check"></i><b>3.4.1</b> <strong>Propiedad-1:</strong></a></li>
<li class="chapter" data-level="3.4.2" data-path="prop-nm.html"><a href="prop-nm.html#prop2"><i class="fa fa-check"></i><b>3.4.2</b> <strong>Propiedad-2:</strong></a></li>
<li class="chapter" data-level="3.4.3" data-path="prop-nm.html"><a href="prop-nm.html#prop3"><i class="fa fa-check"></i><b>3.4.3</b> <strong>Propiedad-3:</strong></a></li>
<li class="chapter" data-level="3.4.4" data-path="prop-nm.html"><a href="prop-nm.html#prop4"><i class="fa fa-check"></i><b>3.4.4</b> <strong>Propiedad-4:</strong></a></li>
<li class="chapter" data-level="3.4.5" data-path="prop-nm.html"><a href="prop-nm.html#prop5"><i class="fa fa-check"></i><b>3.4.5</b> <strong>Propiedad-5:</strong></a></li>
<li class="chapter" data-level="3.4.6" data-path="prop-nm.html"><a href="prop-nm.html#prop6"><i class="fa fa-check"></i><b>3.4.6</b> <strong>Propiedad-6:</strong></a></li>
<li class="chapter" data-level="3.4.7" data-path="prop-nm.html"><a href="prop-nm.html#prop7"><i class="fa fa-check"></i><b>3.4.7</b> <strong>Propiedad-7:</strong></a></li>
<li class="chapter" data-level="3.4.8" data-path="prop-nm.html"><a href="prop-nm.html#prop8"><i class="fa fa-check"></i><b>3.4.8</b> <strong>Propiedad-8:</strong></a></li>
<li class="chapter" data-level="3.4.9" data-path="prop-nm.html"><a href="prop-nm.html#prop9"><i class="fa fa-check"></i><b>3.4.9</b> <strong>Propiedad-9:</strong></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.5</b> Evaluación del Supuesto de Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-a-nivel-marginal-ie.-normalidad-univariada"><i class="fa fa-check"></i><b>3.5.1</b> Evaluación a nivel marginal (ie. Normalidad Univariada)</a></li>
<li class="chapter" data-level="3.5.2" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-de-la-normalidad-bi-variada"><i class="fa fa-check"></i><b>3.5.2</b> Evaluación de la Normalidad Bi-variada</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="detección-de-observaciones-atípicas.html"><a href="detección-de-observaciones-atípicas.html"><i class="fa fa-check"></i><b>3.6</b> Detección de Observaciones Atípicas</a></li>
<li class="chapter" data-level="3.7" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.7</b> Transformaciones para Acercar a la Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#familia-de-transformaciones-de-potencia-de-box-y-cox-1964"><i class="fa fa-check"></i><b>3.7.1</b> Familia de Transformaciones de Potencia de Box y Cox (1964)</a></li>
<li class="chapter" data-level="3.7.2" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#transformaciones-para-el-caso-multivariado"><i class="fa fa-check"></i><b>3.7.2</b> Transformaciones para el Caso Multivariado:</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html"><i class="fa fa-check"></i><b>3.8</b> Muestra Aleatoria Normal <span class="math inline">\(p\)</span>-Variada</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#estimadores-de-máx-ver-de-una-normal-multivariada"><i class="fa fa-check"></i><b>3.8.1</b> Estimadores de Máx-Ver de una Normal-Multivariada</a></li>
<li class="chapter" data-level="3.8.2" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#distribución-muestral-de-overlineunderlinemathbfx-y-mathbfs_n"><i class="fa fa-check"></i><b>3.8.2</b> Distribución Muestral de <span class="math inline">\(\overline{\underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\mathbf{S}_n\)</span></a></li>
<li class="chapter" data-level="3.8.3" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#comportamiento-de-underlineoverlinemathbfx_p-y-mathbfs-para-tamaños-muestrales-grandes"><i class="fa fa-check"></i><b>3.8.3</b> Comportamiento de <span class="math inline">\(\underline{\overline{\mathbf{x}}}_p\)</span> y <span class="math inline">\(\mathbf{S}\)</span> para Tamaños Muestrales Grandes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferen-estad.html"><a href="inferen-estad.html"><i class="fa fa-check"></i><b>4</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="inferencia-estadística-para-la-media-mu-caso-univariado.html"><a href="inferencia-estadística-para-la-media-mu-caso-univariado.html"><i class="fa fa-check"></i><b>4.2</b> Inferencia Estadística para la Media (<span class="math inline">\(\mu\)</span>)-caso univariado</a></li>
<li class="chapter" data-level="4.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><i class="fa fa-check"></i><b>4.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-desconocida-normal"><i class="fa fa-check"></i><b>4.3.1</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Desconocida (Normal)</a></li>
<li class="chapter" data-level="4.3.2" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-conocida-población-normal"><i class="fa fa-check"></i><b>4.3.2</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Conocida (Población: Normal)</a></li>
<li class="chapter" data-level="4.3.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-en-muestra-grande"><i class="fa fa-check"></i><b>4.3.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> en Muestra Grande</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><i class="fa fa-check"></i><b>4.4</b> PH para Igualdad de Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_1=\underline{\boldsymbol{\mu}}_2\)</span></a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html#caso-1.-mathbfsigma_1mathbfsigma_2mathbfsigma-conocida"><i class="fa fa-check"></i><b>4.4.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.4.2" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html#caso-2.-mathbfsigma_1mathbfsigma_2mathbfsigma-desconocida"><i class="fa fa-check"></i><b>4.4.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.4.3" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html#caso-3.-mathbfsigma_1neq-mathbfsigma_2-desconocida"><i class="fa fa-check"></i><b>4.4.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_1\neq \mathbf{\Sigma}_2\)</span>-Desconocida</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><i class="fa fa-check"></i><b>4.5</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_1\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_2\)</span>,   para muestras grandes</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html#caso-1.-mathbfsigma_1mathbfsigma_2mathbfsigma-conocida-1"><i class="fa fa-check"></i><b>4.5.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.5.2" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html#caso-2.-mathbfsigma_1mathbfsigma_2mathbfsigma-desconocida-1"><i class="fa fa-check"></i><b>4.5.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.5.3" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html#caso-3.-mathbfsigma_1-neq-mathbfsigma_2-desconocidas"><i class="fa fa-check"></i><b>4.5.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_1 \neq \mathbf{\Sigma}_2\)</span>-Desconocidas</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-observaciones-pareadas.html"><i class="fa fa-check"></i><b>4.6</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_1\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_2\)</span>,      Observaciones Pareadas</a></li>
<li class="chapter" data-level="4.7" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><i class="fa fa-check"></i><b>4.7</b> PH Acerca de Contrastes del Vector de Medias Poblacional <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>, de una <span class="math inline">\(N_p(\underline{\boldsymbol{\mu}} \ , \ \mathbf{\Sigma} )\)</span></a></li>
<li class="chapter" data-level="4.8" data-path="inferencia-para-la-matriz-de-covarianza.html"><a href="inferencia-para-la-matriz-de-covarianza.html"><i class="fa fa-check"></i><b>4.8</b> Inferencia para la Matriz de Covarianza</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inferencia-para-la-matriz-de-covarianza.html"><a href="inferencia-para-la-matriz-de-covarianza.html#pruba-de-razón-de-verosimilitud"><i class="fa fa-check"></i><b>4.8.1</b> Pruba de Razón de Verosimilitud</a></li>
<li class="chapter" data-level="4.8.2" data-path="inferencia-para-la-matriz-de-covarianza.html"><a href="inferencia-para-la-matriz-de-covarianza.html#prueba-de-bartlet"><i class="fa fa-check"></i><b>4.8.2</b> Prueba de Bartlet</a></li>
<li class="chapter" data-level="4.8.3" data-path="inferencia-para-la-matriz-de-covarianza.html"><a href="inferencia-para-la-matriz-de-covarianza.html#dos-o-más-matrices-de-covarianzas"><i class="fa fa-check"></i><b>4.8.3</b> Dos o más Matrices de Covarianzas</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><i class="fa fa-check"></i><b>4.9</b> Regiones de Confianza y comparaciones simultáneas entre las componentes del vector de medias <span class="math inline">\(\underline{\mu}\)</span></a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#construcción-de-una-región-de-confianza-para-underlinemu-cuando-la-población-tiene-distribución-n_punderlinemumathbfsigma-con-underlinemu-y-mathbfsigma-desconocidos"><i class="fa fa-check"></i><b>4.9.1</b> Construcción de una región de confianza para <span class="math inline">\(\underline{\mu}\)</span> cuando la población tiene distribución <span class="math inline">\(N_p(\underline{\mu},\mathbf{\Sigma})\)</span>, con <span class="math inline">\(\underline{\mu}\)</span> y <span class="math inline">\(\mathbf{\Sigma}\)</span> desconocidos</a></li>
<li class="chapter" data-level="4.9.2" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#región-de-confianza-para-el-caso-de-p2-elipse-de-confianza"><i class="fa fa-check"></i><b>4.9.2</b> Región de Confianza para el caso de <span class="math inline">\(p=2\)</span> (Elipse de Confianza)</a></li>
<li class="chapter" data-level="4.9.3" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#intervalos-de-confianza-simultáneos-para-las-componentes-del-vector-de-medias-underlinemu"><i class="fa fa-check"></i><b>4.9.3</b> Intervalos de confianza simultáneos para las componentes del vector de medias <span class="math inline">\(\underline{\mu}\)</span></a></li>
<li class="chapter" data-level="4.9.4" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#ic-t2-simultáneos-para-diferencias-de-medias"><i class="fa fa-check"></i><b>4.9.4</b> IC <span class="math inline">\(T^2\)</span> Simultáneos para Diferencias de Medias</a></li>
<li class="chapter" data-level="4.9.5" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#método-de-bonferroni-para-comparaciones-múltiples"><i class="fa fa-check"></i><b>4.9.5</b> Método de Bonferroni para Comparaciones Múltiples</a></li>
<li class="chapter" data-level="4.9.6" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#intervalos-de-confianza-simultáneos-chi2-caso-n-grande"><i class="fa fa-check"></i><b>4.9.6</b> Intervalos de Confianza Simultáneos <span class="math inline">\(\chi^2\)</span> (caso n-Grande)</a></li>
<li class="chapter" data-level="4.9.7" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#ic-simultáneos-para-n-grande-usando-la-normal-estándar-z_alpha"><i class="fa fa-check"></i><b>4.9.7</b> IC simultáneos para n-Grande Usando la Normal Estándar <span class="math inline">\(Z_\alpha\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ACP.html"><a href="ACP.html"><i class="fa fa-check"></i><b>5</b> Análisis de Componentes Principales (AC)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introducción-1.html"><a href="introducción-1.html"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="interpretación-del-acp.html"><a href="interpretación-del-acp.html"><i class="fa fa-check"></i><b>5.2</b> Interpretación del ACP</a></li>
<li class="chapter" data-level="5.3" data-path="interpretación-geométrica-del-acp-mediante-un-ejemplo-simple.html"><a href="interpretación-geométrica-del-acp-mediante-un-ejemplo-simple.html"><i class="fa fa-check"></i><b>5.3</b> Interpretación Geométrica del ACP Mediante un Ejemplo Simple</a></li>
<li class="chapter" data-level="5.4" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html"><i class="fa fa-check"></i><b>5.4</b> Mas de dos Ejes</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#min-cuadrados"><i class="fa fa-check"></i><b>5.4.1</b> Ajuste de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="5.4.2" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#relación-entre-los-sub-espacios-de-mathbbrp-y-de-mathbbrn"><i class="fa fa-check"></i><b>5.4.2</b> Relación entre los Sub-espacios de <span class="math inline">\(\mathbb{R}^p\)</span> y de <span class="math inline">\(\mathbb{R}^n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="componentes-principales-en-análisis-de-regresión.html"><a href="componentes-principales-en-análisis-de-regresión.html"><i class="fa fa-check"></i><b>5.5</b> Componentes Principales en Análisis de Regresión</a></li>
<li class="chapter" data-level="5.6" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html"><i class="fa fa-check"></i><b>5.6</b> Componentes Principales Poblacionales</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#determinación-de-las-cps"><i class="fa fa-check"></i><b>5.6.1</b> Determinación de las CPs</a></li>
<li class="chapter" data-level="5.6.2" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-derivadas-de-una-normal-multivariada"><i class="fa fa-check"></i><b>5.6.2</b> Componentes Principales Derivadas de una Normal Multivariada</a></li>
<li class="chapter" data-level="5.6.3" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-usando-variables-estandarizadas"><i class="fa fa-check"></i><b>5.6.3</b> Componentes principales usando variables estandarizadas</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><i class="fa fa-check"></i><b>5.7</b> Componentes Principales para Matrices de Var-Cov <span class="math inline">\(\mathbf{\Sigma}\)</span> con Estructuras Especiales</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#variables-no-correlacionadas"><i class="fa fa-check"></i><b>5.7.1</b> Variables No-Correlacionadas</a></li>
<li class="chapter" data-level="5.7.2" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#variables-altamente-correlacionadas"><i class="fa fa-check"></i><b>5.7.2</b> Variables Altamente Correlacionadas</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="componentes-principales-muestrales.html"><a href="componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>5.8</b> Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="5.9" data-path="algunos-ejemplos.html"><a href="algunos-ejemplos.html"><i class="fa fa-check"></i><b>5.9</b> Algunos Ejemplos</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="algunos-ejemplos.html"><a href="algunos-ejemplos.html#ejemplo-2"><i class="fa fa-check"></i><b>5.9.1</b> Ejemplo-2</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="cómo-elegir-el-número-de-componentes-principales.html"><a href="cómo-elegir-el-número-de-componentes-principales.html"><i class="fa fa-check"></i><b>5.10</b> Cómo elegir el número de Componentes Principales?</a></li>
<li class="chapter" data-level="5.11" data-path="interpretación-de-las-componentes-principales-muestrales.html"><a href="interpretación-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>5.11</b> Interpretación de las componentes principales muestrales</a></li>
<li class="chapter" data-level="5.12" data-path="estandarización-de-las-componentes-principales-muestrales.html"><a href="estandarización-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>5.12</b> Estandarización de las componentes principales muestrales</a></li>
<li class="chapter" data-level="5.13" data-path="gráficos-en-una-análisis-de-componentes-principales.html"><a href="gráficos-en-una-análisis-de-componentes-principales.html"><i class="fa fa-check"></i><b>5.13</b> Gráficos en una Análisis de componentes principales</a>
<ul>
<li class="chapter" data-level="5.13.1" data-path="gráficos-en-una-análisis-de-componentes-principales.html"><a href="gráficos-en-una-análisis-de-componentes-principales.html#el-gráfico-biplot"><i class="fa fa-check"></i><b>5.13.1</b> El gráfico biplot:</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="propiedades-de-hatlambda_i-y-underlinehate_i-en-muestras-grandes.html"><a href="propiedades-de-hatlambda_i-y-underlinehate_i-en-muestras-grandes.html"><i class="fa fa-check"></i><b>5.14</b> Propiedades de <span class="math inline">\(\hat{\lambda}_i\)</span> y <span class="math inline">\(\underline{\hat{e}}_i\)</span> en muestras grandes</a></li>
<li class="chapter" data-level="5.15" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html"><i class="fa fa-check"></i><b>5.15</b> Ejemplos Finales</a>
<ul>
<li class="chapter" data-level="5.15.1" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-1"><i class="fa fa-check"></i><b>5.15.1</b> Ejemplo-1</a></li>
<li class="chapter" data-level="5.15.2" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-2-1"><i class="fa fa-check"></i><b>5.15.2</b> Ejemplo-2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Chapter 4</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inferencia-para-la-matriz-de-covarianza" class="section level2 hasAnchor" number="4.8">
<h2><span class="header-section-number">4.8</span> Inferencia para la Matriz de Covarianza<a href="inferencia-para-la-matriz-de-covarianza.html#inferencia-para-la-matriz-de-covarianza" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sea <span class="math inline">\(\underline{\mathbf{x}_1},\underline{\mathbf{x}_2},\cdots,\underline{\mathbf{x}_n}\)</span> una m.a de una población normal <span class="math inline">\(p\)</span>-variada con vector de medias <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>-desconocida y matriz de varianzas-covarianzas <span class="math inline">\(\mathbf{\Sigma}\)</span>-Desconocida, ie. <span class="math inline">\(\underline{\mathbf{x}_i} \sim N_p( \underline{\boldsymbol{\mu}}\ , \ \mathbf{\Sigma})\)</span>.</p>
<p>Se tiene interés en la siguiente PH:
<span class="math display">\[
\begin{cases}
H_0 \  : \ \mathbf{\Sigma} = \mathbf{\Sigma}_0 \\
H_a \  : \ \mathbf{\Sigma} \neq \mathbf{\Sigma}_0 \\
\end{cases}
\]</span>
donde, <span class="math inline">\(\mathbf{\Sigma}_0\)</span>-es una matriz de valores fijos conocida para <span class="math inline">\(\mathbf{\Sigma}\)</span> (usualmente planteada por experiencia previa).</p>
<p>Dependiendo de la forma particular de <span class="math inline">\(\mathbf{\Sigma}_0\)</span>, existen distintos nombres para la PH asociada:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mathbf{\Sigma}_0\)</span>-Cualquier matriz de valor fijo. Prueba general.</p></li>
<li><p><span class="math inline">\(\mathbf{\Sigma}_0=\Delta\)</span>-Diagonal. Prueba de independencia de variables.</p></li>
<li><p><span class="math inline">\(\mathbf{\Sigma}_0=\sigma^2 \mathbf{I}_p\)</span>. Prueba de homocedasticidad e independencia.</p></li>
<li><p><span class="math inline">\(\mathbf{\Sigma}_0=\mathbf{I}_p\)</span>. Prueba de Esfericidad, ie. variables con varianzas unitarias e incorreladas.</p></li>
<li><p><span class="math inline">\(\mathbf{\Sigma}_0=\mathbf{B}_m + \sigma^2 \mathbf{I}_p\)</span>, con <span class="math inline">\(\mathbf{B}\)</span>-de rango <span class="math inline">\(m&lt;p\)</span>. Prueba de homocedasticidad e independencia parcial. Con <span class="math inline">\(m=0\)</span>-se tiene la rueba de homocedasticidad e independencia.</p></li>
<li><p><span class="math inline">\(\mathbf{\Sigma}_0=\mathbf{B}_m+ \mathbf{I}_p\)</span>, con <span class="math inline">\(\mathbf{B}\)</span>-de rango <span class="math inline">\(m&lt;p\)</span>. Prueba de Esfericidad parcial. Con <span class="math inline">\(m=0\)</span>-se tiene la Prueba de Esfericidad.</p></li>
</ol>
<div id="pruba-de-razón-de-verosimilitud" class="section level3 hasAnchor" number="4.8.1">
<h3><span class="header-section-number">4.8.1</span> Pruba de Razón de Verosimilitud<a href="inferencia-para-la-matriz-de-covarianza.html#pruba-de-razón-de-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La estadística de Razón de Verosimilitud para la PH considerada está dado por:</p>
<p><span class="math display">\[\begin{align*}
\lambda:&amp;= \frac { \underset{\underline{\boldsymbol{\mu}}}{\text{Máx}} \ \  L(\underline{\mu} \ , \ \mathbf{\Sigma}_0 ) } { \underset{\mathbf{ \underline{\mu} \ ,\ \Sigma}}{\text{Máx}} \ \ L(\underline{\mu} \ , \ \mathbf{\Sigma} ) } =\frac{\text{Máximo de L-Restingida}}{\text{Máximo de L-No Restingida}}\\
&amp; \\
&amp;=\frac{\text{Máximo de L-Bajo $H_0$-Cierta}}{\text{Máximo de L-General}}
\end{align*}\]</span></p>
<p>Luego de realizar los cálculos y simplificaciones necesarias se obtiene que:
<span class="math display">\[
\lambda= \left[ \left( \frac{n-1}{n} \right)^p \frac{|\mathbf{S}|}{|\mathbf{\Sigma}_0|}   \right]^{\frac{n}{2}}\text{Exp}\left\{-\frac{1}{2} \left[(n-1)\text{tr}(\mathbf{S}\mathbf{\Sigma}_0^{-1} ) -np  \right] \right\}
\]</span>
haciendo: <span class="math inline">\(\frac{n-1}{n} \approx 1\)</span>, ie. <span class="math inline">\(n-1 \approx n = v\)</span>, ie. <span class="math inline">\(v=n-1=n\)</span>, se tiene:</p>
<p><span class="math display">\[
\lambda= \frac{|\mathbf{S}|^{\frac{v}{2}}}{|\mathbf{\Sigma}_0|^{\frac{v}{2}}}  \text{Exp}\left\{-\frac{1}{2} \left[v \text{tr}(\mathbf{S}\mathbf{\Sigma}_0^{-1} ) -vp  \right] \right\}
\]</span></p>
<p>y haciendo <span class="math inline">\(\lambda^\star=-2\text{log}\lambda\)</span>, se tiene que:</p>
<p><span class="math display">\[
\lambda^\star = v \left[ \text{Log}|\mathbf{\Sigma}_0| -  \text{Log}|\mathbf{S}| + \text{tr}(\mathbf{S}\mathbf{\Sigma}_0^{-1} ) -p \right]\
\]</span></p>
<p>Bajo <span class="math inline">\(H_0\)</span>-cierta, se tiene que:</p>
<p><span class="math display">\[
\lambda^\star \sim \chi_{k}^2 \  , \ \ \ {para} \  \ \ n-1\ \  \text{grande}
\]</span></p>
<p>con <span class="math inline">\(k=p+\frac{p(p+1)}{2}-p=\frac{p(p+1)}{2}\)</span>, ie.</p>
<p><span class="math inline">\(k\)</span>=Parámetros en <span class="math inline">\(\Theta\)</span> menos parámetros en <span class="math inline">\(\Theta_0\)</span> (ie. menos <span class="math inline">\(p\)</span>).</p>
<p>Rechazamos <span class="math inline">\(H_0\)</span> si.</p>
<p><span class="math display">\[
\lambda^\star &gt; \chi_{\alpha\ ;\ k}^2
\]</span></p>
<p><strong>Ahora, otra forma alterna de <span class="math inline">\(\lambda^\star\)</span> es como sigue:</strong></p>
<p>Si <span class="math inline">\(\lambda_1,\lambda_2,\ldots,\lambda_p\)</span> son los valores propios de <span class="math inline">\(\mathbf{S\Sigma_0^{-1}}\)</span>, entonces se sabe que:
<span class="math display">\[
\text{tr} \left( \mathbf{S\Sigma_0^{-1}} \right) = \sum_{i=1}^p  \lambda_i
\]</span></p>
<p>y usando propiedades de determinantes se tiene que:
<span class="math display">\[
\text{Log}|\mathbf{\Sigma}_0| -  \text{Log}|\mathbf{S}| = -
\text{Log}| \mathbf{S \Sigma_0^{-1} }| = -\text{Log} \left( \prod_{i=1}^p \lambda_i \right),
\]</span></p>
<p>luego,</p>
<p><span class="math display">\[\begin{align*}
\lambda^\star &amp;= v \left[ \text{Log}|\mathbf{\Sigma}_0| -  \text{Log}|\mathbf{S}| + \text{tr}(\mathbf{S}\mathbf{\Sigma}_0^{-1} ) -p \right]\\
&amp;= v \left[-\text{Log} \left( \prod_{i=1}^p \lambda_i \right)+ \sum_{i=1}^p\lambda_i-p \right]\\
\lambda^\star&amp;= v \left[ \sum_{i=1}^p [\lambda_i -\text{Log} \lambda_i ] -p \right] \sim \chi_k^2
\end{align*}\]</span></p>
<p>y rechazamos <span class="math inline">\(H_0\)</span> si <span class="math inline">\(\lambda^\star &gt; \chi_{\alpha\ ;\ k}^2\)</span></p>
<p>con <span class="math inline">\(k=\frac{p(p+1)}{2}\)</span>.</p>
</div>
<div id="prueba-de-bartlet" class="section level3 hasAnchor" number="4.8.2">
<h3><span class="header-section-number">4.8.2</span> Prueba de Bartlet<a href="inferencia-para-la-matriz-de-covarianza.html#prueba-de-bartlet" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una Modificación para <span class="math inline">\(\lambda^\star\)</span>-fue propuesta por Bartlet, (para el caso de muestras pequeñas) la cual es:</p>
<p><span class="math display">\[
\lambda_1^\star = \left\{1- \frac{1}{6(n-1)}\left[2p+1-\frac{2}{p+1}\right]  \right\} \lambda^\star \sim \chi_{k}^2
\]</span></p>
<p>es decir,</p>
<p><span class="math display">\[
\lambda_1^\star = c \lambda^\star \sim \chi_{k}^2
\]</span></p>
<p>con
<span class="math display">\[
c=1- \frac{1}{6(n-1)}\left[2p+1-\frac{2}{p+1}\right]
\]</span></p>
<p>que usarse para tamaños de muestras moderadamente pequeños.</p>
<div class="example">
<p><span id="exm:ejemplo1-ph-matrices-sigma0" class="example"><strong>Ejemplo 4.18  (Ejemplo-1 Inferencia Sobre Matrices de Var-Cov) </strong></span>Se tomaron 20 sujetos y se les midió los tiempos de reacción ante un estímulo en centésimas de segundo. A cada individuo se le midieron estos tiempos en 3 intervalos de tiempos distintos. Se asume que estas mediciones tienen una distribución <span class="math inline">\(N_3(\underline{\boldsymbol{\mu}} \ , \ \mathbf{\Sigma} )\)</span>. Pruebe la hipótesis:</p>
</div>
<p><span class="math display">\[
H_0 \ : \ \mathbf{\Sigma}=\begin{bmatrix}
4 &amp; 3 &amp; 2\\ 3 &amp; 6 &amp; 5 \\ 2 &amp; 5 &amp; 10
\end{bmatrix} \  \ \ \ v.s \ \ \ H_a \ : \ \mathbf{\Sigma}\neq \begin{bmatrix}
4 &amp; 3 &amp; 2\\ 3 &amp; 6 &amp; 5 \\ 2 &amp; 5 &amp; 10
\end{bmatrix}
\]</span></p>
<p><strong>Solución:</strong></p>
<p>Como
<span class="math display">\[
\mathbf{\Sigma}_0=\begin{bmatrix}
4 &amp; 3 &amp; 2\\ 3 &amp; 6 &amp; 5 \\ 2 &amp; 5 &amp; 10
\end{bmatrix}\ , \ \ \text{luego} \ \ \ \mathbf{\Sigma}_0^{-1}=\begin{bmatrix}
0.41 &amp; -0.23 &amp; 0.03\\ -0.23 &amp; 0.42 &amp; -0.16 \\ 0.03 &amp; -0.16 &amp; 0.17
\end{bmatrix}
\]</span></p>
<p>y
<span class="math display">\[
\mathbf{S \Sigma}_0^{-1}=\begin{bmatrix}
0.85 &amp; -0.01 &amp; 0.03\\ -0.58 &amp; 1.68 &amp; -0.08 \\ -0.41 &amp; 0.72 &amp; 0.68
\end{bmatrix}.
\]</span></p>
<p>Los valores propios de <span class="math inline">\(\mathbf{S \Sigma}_0^{-1}\)</span> son: <span class="math inline">\(\lambda_1=1.61\)</span>, <span class="math inline">\(\lambda_2=0.87\)</span> y <span class="math inline">\(\lambda_3=0.73\)</span>, luego:
tr<span class="math inline">\((\mathbf{S \Sigma}_0^{-1})=\sum \lambda_i=3.2216\)</span>, <span class="math inline">\(|\mathbf{\Sigma}_0|=86\)</span>, <span class="math inline">\(|\mathbf{S}|=88.6355\)</span>, de donde:</p>
<p><span class="math display">\[\begin{align*}
\lambda^\star &amp;= v \left[ \text{Log}|\mathbf{\Sigma}_0| -  \text{Log}|\mathbf{S}| + \text{tr}(\mathbf{S}\mathbf{\Sigma}_0^{-1} ) -p \right]\\
&amp;= 20 \left[\text{Log}(86)-\text{Log}(88.6355) + 3.2216 -3 \right]\\
\lambda^\star &amp;= 3.828
\end{align*}\]</span></p>
<p>y
<span class="math display">\[\begin{align*}
\lambda_1^\star &amp;= \left\{1- \frac{1}{6(n-1)}\left[2p+1-\frac{2}{p+1}\right]  \right\} \lambda^\star \\
&amp;= \left\{ 1 - \frac{1}{6(19)} \left[2(3)+1-\frac{2}{3+1}\right]    \right\} 3.63\\
\lambda_1^\star &amp;=3.42
\end{align*}\]</span></p>
<p>Para <span class="math inline">\(\alpha=0.05\)</span>, se tiene que: <span class="math inline">\(\chi_{\alpha;v}=\chi_{0.05; 6}=12.592\)</span></p>
<p>(<span class="math inline">\(v=p(p+1)/2=3(4)/2)6\)</span>) y como <span class="math inline">\(\lambda_1^\star &lt; \chi_{\alpha;v}^2\)</span>, entonces</p>
<p>no se rechaza <span class="math inline">\(H_0\)</span> y se concluye que la evidencia muestral apoya la hipótesis:</p>
<p><span class="math display">\[
H_0 \ : \ \mathbf{\Sigma}=\begin{bmatrix}
4 &amp; 3 &amp; 2\\ 3 &amp; 6 &amp; 5 \\ 2 &amp; 5 &amp; 10
\end{bmatrix},
\]</span></p>
<p>a un nivel de significancia del <span class="math inline">\(5\%\)</span>.</p>
<div class="example">
<p><span id="exm:ejemplo2-ph-matrices-sigma0-npqueña" class="example"><strong>Ejemplo 4.19  (Ejemplo-2 Inferencia Sobre Matrices de Var-Cov) </strong></span>Continuando con los datos del ejemplo <a href="inferencia-estadística-para-la-media-mu-caso-univariado.html#exm:ejemplo1-ph-uni">4.1</a>, donde se tienen los siguientes datos que corresponden a una muestra de tamaño <span class="math inline">\(n=100\)</span> y que se dividen en tres grupos o clases denotados por los números 1,2 y 3 de la variable <em>Clases</em>.</p>
</div>
<p>Utilizando los datos del grupos o clase 1, los cuales se muestran a continuación:</p>
<table>
<caption><span id="tab:unnamed-chunk-38">Tabla 4.17: </span>Encabezado del Conjunto de Datos del Grupo-1</caption>
<thead>
<tr class="header">
<th align="center">X1</th>
<th align="center">X2</th>
<th align="center">X3</th>
<th align="center">Clases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">-0.0758</td>
<td align="center">-2.2825</td>
<td align="center">-0.4553</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.1436</td>
<td align="center">-0.5651</td>
<td align="center">-0.5009</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">-1.8002</td>
<td align="center">-1.0732</td>
<td align="center">-0.4070</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.8298</td>
<td align="center">3.1684</td>
<td align="center">-2.8147</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">0.7292</td>
<td align="center">1.3984</td>
<td align="center">-1.2794</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-3.2951</td>
<td align="center">-6.1390</td>
<td align="center">-2.7887</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Ahora, se desea realizar la siguiente PH:</p>
<p><span class="math display">\[
H_0 \ : \ \mathbf{\Sigma}=\mathbf{\Sigma}_0=\begin{bmatrix}
4 &amp; 4 &amp; 4\\ 4 &amp; 9 &amp; 4 \\ 4 &amp; 4 &amp; 9
\end{bmatrix} \  \ \ \ v.s \ \ \ H_a \ : \ \mathbf{\Sigma}\neq \mathbf{\Sigma}_0 = \begin{bmatrix}
4 &amp; 4 &amp; 4\\ 4 &amp; 9 &amp; 4 \\ 4 &amp; 4 &amp; 9
\end{bmatrix}
\]</span></p>
<p>Utilizando la prueba de Razón de Verosimilitud se tienen los siguientes resultados:</p>
<pre><code>##   Lamda_Est Lamda_1_Est          df   Chi_tabla     Valor_p 
##    10.11245     9.69110     6.00000    12.59159     0.13828</code></pre>
<p>Es decir que el estadístico de prueba es:</p>
<p><span class="math display">\[
\lambda^\star = v \left[ \text{Log}|\mathbf{\Sigma}_0| -  \text{Log}|\mathbf{S}| + \text{tr}(\mathbf{S}\mathbf{\Sigma}_0^{-1} ) -p \right] = 9.6911
\]</span></p>
<p>con <span class="math inline">\(n=27\)</span>.</p>
<p>y el valor-p de la prueba es: 0.13828 de donde se conluye que como el valor-p=0.13828
&gt; 0.05 entonces no se rechaza la hipótesis nula H0.</p>
<div class="example">
<p><span id="exm:ejemplo3-ph-matrices-sigma0-ngrande" class="example"><strong>Ejemplo 4.20  (Ejemplo-2 Inferencia Sobre Matrices de Var-Cov) </strong></span>Continuando con los datos del ejemplo <a href="inferencia-estadística-para-la-media-mu-caso-univariado.html#exm:ejemplo1-ph-uni">4.1</a>, donde se tienen los siguientes datos que corresponden a una muestra de tamaño <span class="math inline">\(n=100\)</span> y que se dividen en tres grupos o clases denotados por los números 1,2 y 3 de la variable <em>Clases</em>.</p>
</div>
<p>Utilizando los datos completos, cuyo encabezado se muestran a continuación:</p>
<table>
<caption><span id="tab:unnamed-chunk-41">Tabla 4.18: </span>Encabezado del Conjunto de Datos Completo</caption>
<thead>
<tr class="header">
<th align="center">X1</th>
<th align="center">X2</th>
<th align="center">X3</th>
<th align="center">Clases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">-0.0758</td>
<td align="center">-2.2825</td>
<td align="center">-0.4553</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.1436</td>
<td align="center">-0.5651</td>
<td align="center">-0.5009</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">-1.8002</td>
<td align="center">-1.0732</td>
<td align="center">-0.4070</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.8298</td>
<td align="center">3.1684</td>
<td align="center">-2.8147</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">0.7292</td>
<td align="center">1.3984</td>
<td align="center">-1.2794</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-3.2951</td>
<td align="center">-6.1390</td>
<td align="center">-2.7887</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Ahora, se desea realizar la siguiente PH:</p>
<p><span class="math display">\[
H_0 \ : \ \mathbf{\Sigma}=\mathbf{\Sigma}_0=\begin{bmatrix}
4 &amp; 4 &amp; 4\\ 4 &amp; 9 &amp; 4 \\ 4 &amp; 4 &amp; 9
\end{bmatrix} \  \ \ \ v.s \ \ \ H_a \ : \ \mathbf{\Sigma}\neq \mathbf{\Sigma}_0 = \begin{bmatrix}
4 &amp; 4 &amp; 4\\ 4 &amp; 9 &amp; 4 \\ 4 &amp; 4 &amp; 9
\end{bmatrix}
\]</span></p>
<p>Utilizando la prueba de Razón de Verosimilitud se tienen los siguientes resultados:</p>
<pre><code>## Lamda_Est        df Chi_tabla   Valor_p 
##   4.98221   6.00000  12.59159   0.54610</code></pre>
<p>Es decir que el estadístico de prueba es:</p>
<p><span class="math display">\[
\lambda^\star = v \left[ \text{Log}|\mathbf{\Sigma}_0| -  \text{Log}|\mathbf{S}| + \text{tr}(\mathbf{S}\mathbf{\Sigma}_0^{-1} ) -p \right] = 4.98221
\]</span></p>
<p>con <span class="math inline">\(n=27\)</span>.</p>
<p>y el valor-p de la prueba es: 0.5461 de donde se conluye que como el valor-p=0.5461
&gt; 0.05 entonces no se rechaza la hipótesis nula H0.</p>
</div>
<div id="dos-o-más-matrices-de-covarianzas" class="section level3 hasAnchor" number="4.8.3">
<h3><span class="header-section-number">4.8.3</span> Dos o más Matrices de Covarianzas<a href="inferencia-para-la-matriz-de-covarianza.html#dos-o-más-matrices-de-covarianzas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recordar que uno de los supuestos cuando se comparan dos o más vectores de medias, es que las respectivas matrices de Var-Cov asociadas a cada población diferente, sean iguales. Un test muy común para probar la igualdad de matrices de Var-Cov es el <strong>M-Test de Box</strong>.</p>
<p>Suponga que se tienen <span class="math inline">\(g\)</span>-poblaciones diferentes, con matrices de Var-Cov asociadas dadas por: <span class="math inline">\(\mathbf{\Sigma}_1,\mathbf{\Sigma}_2,\ldots,\mathbf{\Sigma}_g\)</span>, respectivamente. Se desea contrastar las hipótesis:</p>
<p><span class="math display">\[
\begin{cases}
H_0 \ : \ \mathbf{\Sigma}_1=\mathbf{\Sigma}_2= \cdots = \mathbf{\Sigma}_g = \mathbf{\Sigma}\\
H_a \ : \ \mathbf{\Sigma}_i \neq  \mathbf{\Sigma}_j \ \ p.a \ \ i,j
\end{cases}
\]</span>
donde <span class="math inline">\(\mathbf{\Sigma}\)</span>-es una matriz de Var-Cov común.</p>
<p>Si se tienen <span class="math inline">\(g\)</span>-muestras aleatorias, una para cada población, de tamaños <span class="math inline">\(n_1,n_2,\ldots,n_g\)</span>, respectivamente y además se asume que cada muestra proviene de una población con distribución normal <span class="math inline">\(p\)</span>-variada, entonces el estadístico de prueba de razón de verosimilitud para esta PH es:
<span class="math display">\[
\lambda= \prod_{i=1}^g \left( \frac{|\mathbf{S}_i|}{|\mathbf{S}_p|} \right)^{\frac{n_i-1}{2}},
\]</span></p>
<p>donde, <span class="math inline">\(\mathbf{S}_i\)</span>-es la matriz de Var-Cov muestral asosciada a la m.a de la <span class="math inline">\(i\)</span>-ésima población, <span class="math inline">\(i=1,2,\ldots,g\)</span> y
<span class="math display">\[
\mathbf{S}_p=\frac{1}{\sum_{i=1}^g(n_i-1)} \left[\sum_{i=1}^g(n_i-1)\mathbf{S}_i \right] \ \ \ \ ;\ \ \  \ \biggl(  \text{para} \ \ g=2, \ \ \ \mathbf{S}=\frac{(n_1-1)\mathbf{S}_1+(n_2-1)\mathbf{S}_2}{n_1+n_2-2} \biggr)
\]</span></p>
<p>haciendo, <span class="math inline">\(v_i=n_i-1\)</span>  y   <span class="math inline">\(v=\sum_{i=1}^g v_i=\sum_{i=1}^g (n_i-1)\)</span> (para <span class="math inline">\(g=2,\ \  v=n_1+n_2-2\)</span>), se tiene que:
<span class="math display">\[
\mathbf{S}_p=\frac{1}{v} \left[\sum_{i=1}^g v_i \mathbf{S}_i \right] \ \ \ \ ;\ \ \  \ \biggl(  \text{para} \ \ g=2, \ \ \ \mathbf{S}=\frac{(n_1-1)\mathbf{S}_1+(n_2-1)\mathbf{S}_2}{n_1+n_2-2} \biggr)
\]</span></p>
<p>Haciendo <span class="math inline">\(M=-2\text{Log} \lambda \sim \chi^2\)</span>, <strong>M-Estadística de Box, (n-grande)</strong>.
<span class="math display">\[\begin{align*}
M&amp;=\left[ \sum_{i=1}^g(n_i-1) \right] \text{Log}|\mathbf{S}_p|-\sum_{i=1}^g(n_i-1)\text{Log}|\mathbf{S}_i|\\
&amp;= v \text{Log}|\mathbf{S}_p|-\sum_{i=1}^g v_i\text{Log}|\mathbf{S}_i|
\end{align*}\]</span></p>
<p>Bajo <span class="math inline">\(H_0\)</span>-cierto, se espera que las matrices de Var-Cov muestrales no sean muy diferentes, en cuyo caso, el valor de <span class="math inline">\(\lambda\)</span> estaría cerca a uno y por lo tanto <span class="math inline">\(M\)</span>-sería pequeño.</p>
<p>Ahora, sea</p>
<p><span class="math display">\[\begin{align*}
u&amp;=\left[\sum_{i=1}^g\left( \frac{1}{n_i-1} \right)-\frac{1}{\sum_{i=1}^g(n_i-1)} \right]\left( \frac{2p^2+3p-1}{6(p+1)(g-1)} \right)\\ \\
u&amp;=\left[\sum_{i=1}^g  \frac{1}{v_i} -\frac{1}{v} \right]\left( \frac{2p^2+3p-1}{6(p+1)(g-1)} \right)
\end{align*}\]</span></p>
<p><strong>luego por un Resultado Estadístico se tiene que:</strong></p>
<p><span class="math display">\[
C=(1-u)M \ \ \underset{\longrightarrow}{d} \ \ \chi_{k}^2
\]</span>
ie. <span class="math inline">\(C\)</span>-converge en distribución a una chi-cuadrado con:</p>
<p><span class="math inline">\(k=\left[gp+g\frac{1}{2}p(p+1)\right]-\left[gp+\frac{1}{2}p(p+1)\right] =\frac{p(p+1)}{2}(g-1)\)</span> grados de libertad.</p>
<p>Se rechaza <span class="math inline">\(H_0\)</span>, si <span class="math inline">\(C &gt; \chi_{\alpha \ ; \ k}^2\)</span>.</p>
<p>Esta aproximación es buena para situaciones donde, <span class="math inline">\(n_i&gt;20\)</span> y con <span class="math inline">\(p\)</span> y <span class="math inline">\(g\)</span>-no mayores a 5, <em>en otros casos, ver Aproximación a la F-Snedecor propuesta por Box en la Página 311 del texto guía</em>.</p>
<div class="example">
<p><span id="exm:ejemplo1-ph-matrices-mbox" class="example"><strong>Ejemplo 4.21  (Ejemplo-1 PH M-Box Matrices) </strong></span>En el departamento de salud y servicios sociales de Wisconsin se realizó un estudio para investigar el efecto de la propiedad o la certificación ( o ambas) sobre los costos. Cuatro costos fueron seleccionados para el análisis; estos fueron calculados diariamente por paciente y fueron medidos en horas por paciente diario. Las variables fueron: <span class="math inline">\(X_1\)</span>-Costo de la enfermería, <span class="math inline">\(X_2\)</span>-Costo de alimentación, <span class="math inline">\(X_4\)</span>-Costo de operación y mantenimiento y <span class="math inline">\(X_4\)</span>-Costo de administración y lavandería. Se registraron un total de <span class="math inline">\(n=516\)</span>-observaciones de cada una de las cuatro variables, separadas previamente en tres grupos de interés: Privados (<span class="math inline">\(n_1=271\)</span>), Públicos (<span class="math inline">\(n_2=138\)</span>) y Gubernamentales (<span class="math inline">\(n_3=107\)</span>). Se asume que el vector
<span class="math inline">\(\underline{\mathbf{x}}=(X_1,X_2,X_3,X_4)^t\)</span> tiene una distribución <span class="math inline">\(N_4(\underline{\boldsymbol{\mu}_i} \ , \ \mathbf{\Sigma}_i )\)</span>, para <span class="math inline">\(i=1,2,3\)</span>. Se desea probar la hipótesis:</p>
</div>
<p><span class="math display">\[
\begin{cases}
H_0 \ : \ \mathbf{\Sigma}_1=\mathbf{\Sigma}_2= \mathbf{\Sigma}_3 = \mathbf{\Sigma}\\
H_a \ : \ \mathbf{\Sigma}_i \neq  \mathbf{\Sigma}_j \ \ p.a \ \ i\neq j=1,2,3
\end{cases}
\]</span></p>
<p>Los resultados muestrales obtenidos a partir de los datos fueron:
<span class="math display">\[
n_1=271, \ \ \ \underline{\overline{\mathbf{x}}}_1=\begin{bmatrix}
2.066\\ 0.480\\ 0.082\\ 0.360
\end{bmatrix}, \ \ \ \mathbf{S}_1=\begin{bmatrix}
0.291 &amp; -0.010 &amp; 0.020 &amp; 0.010 \\
&amp; 0.011 &amp; 0.000 &amp; 0.003 \\
&amp;&amp; 0.001 &amp; 0.000 \\
&amp;&amp;&amp; 0.100
\end{bmatrix}
\]</span>
<span class="math display">\[
n_2=138, \ \ \ \underline{\overline{\mathbf{x}}}_2=\begin{bmatrix}
2.167\\ 0.596\\ 0.124\\ 0.418
\end{bmatrix}, \ \ \ \mathbf{S}_2=\begin{bmatrix}
0.561 &amp; 0.011 &amp; 0.001 &amp; 0.037 \\
&amp; 0.025 &amp; 0.004 &amp; 0.007 \\
&amp;&amp; 0.005 &amp; 0.002 \\
&amp;&amp;&amp; 0.019
\end{bmatrix}
\]</span>
<span class="math display">\[
n_3=107, \ \ \ \underline{\overline{\mathbf{x}}}_3=\begin{bmatrix}
2.273\\ 0.521\\ 0.125\\ 0.383
\end{bmatrix}, \ \ \ \mathbf{S}_3=\begin{bmatrix}
0.261 &amp; 0.030 &amp; 0.003 &amp; 0.018 \\
&amp; 0.017 &amp; 0.000 &amp; 0.004 \\
&amp;&amp; 0.004 &amp; 0.001 \\
&amp;&amp;&amp; 0.013
\end{bmatrix}
\]</span></p>
<p>En este caso se tiene: <span class="math inline">\(v=n_1+n_2+n_3-3=271+138+107-3\)</span>= 513.</p>
<p>Con la información anterior se obtiene:
<span class="math display">\[
|\mathbf{S}_1 |=2.783\times 10^{-8}\ , \ \ \ \  \ \ Log|\mathbf{S}_1 |=-17.397
\]</span></p>
<p><span class="math display">\[
|\mathbf{S}_2 |=89.539\times 10^{-8}\ , \ \ \ \  \ \ Log|\mathbf{S}_2 |=-13.926
\]</span></p>
<p><span class="math display">\[
|\mathbf{S}_3 |=14.579\times 10^{-8}\ , \ \ \ \  \ \ Log|\mathbf{S}_3 |=-15.741
\]</span></p>
<p><span class="math display">\[
|\mathbf{S}_p |=17.398\times 10^{-8}\ , \ \ \ \  \ \ Log|\mathbf{S}_1 |=-15.564
\]</span></p>
<p><span class="math display">\[\begin{align*}
u&amp;=\left[\sum_{i=1}^g  \frac{1}{v_i} -\frac{1}{v} \right]\left( \frac{2p^2+3p-1}{6(p+1)(g-1)} \right)\\ \\ &amp;=\left[\frac{1}{270}+\frac{1}{137}+\frac{1}{106} -\frac{1}{513}  \right]\left[\frac{2(4)^2+3(4)-1}{6(4+1)(3-1)} \right]\\ \\
u&amp;=0.0133
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
M&amp;=\left[ \sum_{i=1}^g(n_i-1) \right] \text{Log}|\mathbf{S}_p|-\sum_{i=1}^g(n_i-1)\text{Log}|\mathbf{S}_i|\\ \\
&amp;= \left(270+137+106\right)\left(-15.564 \right)-\left[270(-17.397)+137(-13.926)+106(-15.741) \right]\\ \\
M&amp;= 289.3
\end{align*}\]</span></p>
<p><span class="math display">\[
C=(1-u)M=(1-0.0133)289.3=285.5
\]</span></p>
<p>Ahora, para <span class="math inline">\(\alpha=0.05\)</span>, se tiene que:</p>
<p><span class="math display">\[
\chi_{\alpha ; k}^2=\chi_{0.05\ ; \ \frac{p(p+1)}{2}(g-1)}^2=\chi_{0.05 \ ;\ 20}^2=31.34,
\]</span></p>
<p>Como <span class="math inline">\(C &gt;\chi_{\alpha ; k}^2\)</span>, entonces se rechaza <span class="math inline">\(H_0\)</span> y se concluye que las matrices de Var-Cov asociadas a los vectores de costos para las las tres poblaciones consideradas son diferentes a un nivel de significancia del <span class="math inline">\(5\%\)</span>.</p>
<div class="example">
<p><span id="exm:ejemplo2-ph-matrices-mbox" class="example"><strong>Ejemplo 4.22  (Ejemplo-2 PH M-Box Matrices) </strong></span>Continuando con los datos del ejemplo <a href="inferencia-estadística-para-la-media-mu-caso-univariado.html#exm:ejemplo1-ph-uni">4.1</a>, donde se tienen los siguientes datos que corresponden a una muestra de tamaño <span class="math inline">\(n=100\)</span> y que se dividen en tres grupos o clases denotados por los números 1,2 y 3 de la variable <em>Clases</em>.</p>
</div>
<p>Utilizando los datos de los grupos o clases 1,2 y 3 de los cuales, a continuación se muestran los encabezados de dichos datos:</p>
<table>
<caption><span id="tab:unnamed-chunk-44">Tabla 4.19: </span>Encabezado del Conjunto de Datos del Grupo-1</caption>
<thead>
<tr class="header">
<th align="center">X1</th>
<th align="center">X2</th>
<th align="center">X3</th>
<th align="center">Clases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">-0.0758</td>
<td align="center">-2.2825</td>
<td align="center">-0.4553</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.1436</td>
<td align="center">-0.5651</td>
<td align="center">-0.5009</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">-1.8002</td>
<td align="center">-1.0732</td>
<td align="center">-0.4070</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.8298</td>
<td align="center">3.1684</td>
<td align="center">-2.8147</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">0.7292</td>
<td align="center">1.3984</td>
<td align="center">-1.2794</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-3.2951</td>
<td align="center">-6.1390</td>
<td align="center">-2.7887</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:unnamed-chunk-44">Tabla 4.19: </span>Encabezado del Conjunto de Datos del Grupo-2</caption>
<thead>
<tr class="header">
<th align="center">X1</th>
<th align="center">X2</th>
<th align="center">X3</th>
<th align="center">Clases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">-0.1803</td>
<td align="center">-2.0742</td>
<td align="center">-1.9101</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">1.8201</td>
<td align="center">0.3161</td>
<td align="center">0.8247</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">-0.1967</td>
<td align="center">-0.6833</td>
<td align="center">-3.6792</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">-2.5997</td>
<td align="center">-4.4505</td>
<td align="center">-3.7421</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">-0.4859</td>
<td align="center">-2.3237</td>
<td align="center">1.3284</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">1.9805</td>
<td align="center">5.3640</td>
<td align="center">-0.9451</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:unnamed-chunk-44">Tabla 4.19: </span>Encabezado del Conjunto de Datos del Grupo-3</caption>
<thead>
<tr class="header">
<th align="center">X1</th>
<th align="center">X2</th>
<th align="center">X3</th>
<th align="center">Clases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">-0.3249</td>
<td align="center">0.3130</td>
<td align="center">-3.0578</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">-3.0623</td>
<td align="center">-1.2797</td>
<td align="center">1.5485</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">-0.3919</td>
<td align="center">-0.1554</td>
<td align="center">-0.0718</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">-1.9706</td>
<td align="center">-1.2920</td>
<td align="center">1.5413</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">6.3046</td>
<td align="center">6.4707</td>
<td align="center">8.3824</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">-3.3819</td>
<td align="center">-1.8752</td>
<td align="center">-6.2753</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p>Ahora, se desea realizar la siguiente PH:</p>
<p><span class="math display">\[
\begin{cases}
H_0 \ : \ \mathbf{\Sigma}_1=\mathbf{\Sigma}_2= \mathbf{\Sigma}_3 = \mathbf{\Sigma}\\
H_a \ : \ \mathbf{\Sigma}_i \neq  \mathbf{\Sigma}_j \ \ p.a \ \ i\neq j=1,2,3
\end{cases}
\]</span></p>
<p>Utilizando la prueba <strong>M-Box</strong> (prueba de Razón de Verosimilitud Modificada) se tienen los siguientes resultados:</p>
<pre><code>## 
##  Box&#39;s M-test for Homogeneity of Covariance Matrices
## 
## data:  datos1[, 1:3]
## Chi-Sq (approx.) = 15.986, df = 12, p-value = 0.1919</code></pre>
<p>Es decir que el estadístico de prueba <span class="math inline">\(C\)</span> es:</p>
<p><span class="math display">\[
C=(1-u)M= 15.9860898
\]</span></p>
<p>con <span class="math inline">\(k=p(p+1)(g-1)/2=3(4)(2)/2=\)</span> 12 -grados de libertad.</p>
<p>y el valor-p de la prueba es: 0.191874 de donde se conluye que como el valor-p=0.191874 &gt; 0.05 , entonces no se rechaza la hipótesis nula H0.</p>
<p>Similarmente el valor crítico de la tabla <span class="math inline">\(\chi^2\)</span> es:
<span class="math display">\[
\chi^2_{tabla}=\chi^2_{1-\alpha \ ,\ k}=\chi^2_{1-0.05\ ,\ 12}=\chi^2_{0.95\ ,\ 12}=21.0260698
\]</span></p>
<p>de donde como el valor del <span class="math inline">\(\chi^2_0=C_0\)</span>-calculado,
<span class="math display">\[
C_0 = \chi^2_0=15.9860898 &lt; 21.0260698
\]</span>
entonces no se rechaza la hipótesis nula H0.</p>
<div class="example">
<p><span id="exm:ejemplo3-ph-matrices-mbox" class="example"><strong>Ejemplo 4.23  (Ejemplo-3 PH M-Box Matrices) </strong></span>Continuando con los datos del ejemplo <a href="inferencia-estadística-para-la-media-mu-caso-univariado.html#exm:ejemplo1-ph-uni">4.1</a>, donde se tienen los siguientes datos que corresponden a una muestra de tamaño <span class="math inline">\(n=100\)</span> y que se dividen en tres grupos o clases denotados por los números 1,2 y 3 de la variable <em>Clases</em>.</p>
</div>
<p>Utilizando los datos de los grupos o clases 1 y 2 de los cuales, a continuación se muestran los encabezados de dichos datos:</p>
<table>
<caption><span id="tab:unnamed-chunk-47">Tabla 4.20: </span>Encabezado del Conjunto de Datos del Grupo-1</caption>
<thead>
<tr class="header">
<th align="center">X1</th>
<th align="center">X2</th>
<th align="center">X3</th>
<th align="center">Clases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">-0.0758</td>
<td align="center">-2.2825</td>
<td align="center">-0.4553</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.1436</td>
<td align="center">-0.5651</td>
<td align="center">-0.5009</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">-1.8002</td>
<td align="center">-1.0732</td>
<td align="center">-0.4070</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-0.8298</td>
<td align="center">3.1684</td>
<td align="center">-2.8147</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">0.7292</td>
<td align="center">1.3984</td>
<td align="center">-1.2794</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">-3.2951</td>
<td align="center">-6.1390</td>
<td align="center">-2.7887</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:unnamed-chunk-47">Tabla 4.20: </span>Encabezado del Conjunto de Datos del Grupo-2</caption>
<thead>
<tr class="header">
<th align="center">X1</th>
<th align="center">X2</th>
<th align="center">X3</th>
<th align="center">Clases</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">-0.1803</td>
<td align="center">-2.0742</td>
<td align="center">-1.9101</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">1.8201</td>
<td align="center">0.3161</td>
<td align="center">0.8247</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">-0.1967</td>
<td align="center">-0.6833</td>
<td align="center">-3.6792</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">-2.5997</td>
<td align="center">-4.4505</td>
<td align="center">-3.7421</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">-0.4859</td>
<td align="center">-2.3237</td>
<td align="center">1.3284</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">1.9805</td>
<td align="center">5.3640</td>
<td align="center">-0.9451</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<p>Ahora, se desea realizar la siguiente PH:</p>
<p><span class="math display">\[
\begin{cases}
H_0 \ : \ \mathbf{\Sigma}_1=\mathbf{\Sigma}_2= \mathbf{\Sigma}\\
H_a \ : \ \mathbf{\Sigma}_i \neq  \mathbf{\Sigma}_j \ \ p.a \ \ i\neq j=1,2
\end{cases}
\]</span></p>
<p>Utilizando la prueba <strong>M-Box</strong> (prueba de Razón de Verosimilitud Modificada) se tienen los siguientes resultados:</p>
<pre><code>## 
##  Box&#39;s M-test for Homogeneity of Covariance Matrices
## 
## data:  datos12[, 1:3]
## Chi-Sq (approx.) = 8.4788, df = 6, p-value = 0.2051</code></pre>
<p>Es decir que el estadístico de prueba <span class="math inline">\(C\)</span> es:</p>
<p><span class="math display">\[
C=(1-u)M= 8.4788235
\]</span></p>
<p>con <span class="math inline">\(k=p(p+1)(g-1)/2=3(4)(1)/2=\)</span> 6 -grados de libertad.</p>
<p>y el valor-p de la prueba es: 0.2050789 de donde se conluye que como el valor-p=0.2050789 &gt; 0.05 , entonces no se rechaza la hipótesis nula H0.</p>
<p>Similarmente el valor crítico de la tabla <span class="math inline">\(\chi^2\)</span> es:
<span class="math display">\[
\chi^2_{tabla}=\chi^2_{1-\alpha \ ,\ k}=\chi^2_{1-0.05\ ,\ 6}=\chi^2_{0.95\ ,\ 6}=12.5915872
\]</span></p>
<p>de donde como el valor del <span class="math inline">\(\chi^2_0=C_0\)</span>-calculado,
<span class="math display">\[
C_0 = \chi^2_0=8.4788235 &lt; 12.5915872
\]</span>
entonces no se rechaza la hipótesis nula H0.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-iam.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsubsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
