<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.9 Factores-Scores (o Puntuaciones) de los Factores | Chapter 10</title>
  <meta name="description" content="Este libro contine ……" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="7.9 Factores-Scores (o Puntuaciones) de los Factores | Chapter 10" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/imagenes/imagen1.png" />
  <meta property="og:description" content="Este libro contine ……" />
  <meta name="github-repo" content="raperezaga/iam" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.9 Factores-Scores (o Puntuaciones) de los Factores | Chapter 10" />
  
  <meta name="twitter:description" content="Este libro contine ……" />
  <meta name="twitter:image" content="/imagenes/imagen1.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rotación-de-factores.html"/>
<link rel="next" href="perspectivas-y-estrategías-para-el-análisis-de-factor.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preámbulo</a>
<ul>
<li class="chapter" data-level="" data-path="descripción.html"><a href="descripción.html"><i class="fa fa-check"></i>Descripción</a></li>
<li class="chapter" data-level="" data-path="acerca-del-autor.html"><a href="acerca-del-autor.html"><i class="fa fa-check"></i>Acerca del Autor</a></li>
<li class="chapter" data-level="" data-path="dedicación.html"><a href="dedicación.html"><i class="fa fa-check"></i>Dedicación</a></li>
<li class="chapter" data-level="" data-path="agradecimientos.html"><a href="agradecimientos.html"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="paquetes-usados-en-el-libro.html"><a href="paquetes-usados-en-el-libro.html"><i class="fa fa-check"></i>Paquetes usados en el libro</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="rep-al.html"><a href="rep-al.html"><i class="fa fa-check"></i><b>1</b> Repaso de álgebra lineal</a>
<ul>
<li class="chapter" data-level="1.1" data-path="acb-al.html"><a href="acb-al.html"><i class="fa fa-check"></i><b>1.1</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="acb-al.html"><a href="acb-al.html#matrices"><i class="fa fa-check"></i><b>1.1.1</b> Matrices</a></li>
<li class="chapter" data-level="1.1.2" data-path="acb-al.html"><a href="acb-al.html#vectores"><i class="fa fa-check"></i><b>1.1.2</b> Vectores</a></li>
<li class="chapter" data-level="1.1.3" data-path="acb-al.html"><a href="acb-al.html#operaciones-matrices"><i class="fa fa-check"></i><b>1.1.3</b> Operaciones Matriciales</a></li>
<li class="chapter" data-level="1.1.4" data-path="acb-al.html"><a href="acb-al.html#matrices-especiales"><i class="fa fa-check"></i><b>1.1.4</b> Matrices Especiales</a></li>
<li class="chapter" data-level="1.1.5" data-path="acb-al.html"><a href="acb-al.html#descomp-espectral"><i class="fa fa-check"></i><b>1.1.5</b> Descomposición Espectral de una Matriz (eigen-descomposición)</a></li>
<li class="chapter" data-level="1.1.6" data-path="acb-al.html"><a href="acb-al.html#diagonalización-de-una-matriz"><i class="fa fa-check"></i><b>1.1.6</b> Diagonalización de una Matriz</a></li>
<li class="chapter" data-level="1.1.7" data-path="acb-al.html"><a href="acb-al.html#diagonalización-ortogonal"><i class="fa fa-check"></i><b>1.1.7</b> Diagonalización Ortogonal</a></li>
<li class="chapter" data-level="1.1.8" data-path="acb-al.html"><a href="acb-al.html#diagonalizacion-inversa"><i class="fa fa-check"></i><b>1.1.8</b> Diagonalización de la Inversa de una Matriz</a></li>
<li class="chapter" data-level="1.1.9" data-path="acb-al.html"><a href="acb-al.html#diagonalización-de-la-matriz-raíz-cuadrada"><i class="fa fa-check"></i><b>1.1.9</b> Diagonalización de la Matriz Raíz Cuadrada</a></li>
<li class="chapter" data-level="1.1.10" data-path="acb-al.html"><a href="acb-al.html#traza-determinante-y-rango-de-una-matriz"><i class="fa fa-check"></i><b>1.1.10</b> Traza, Determinante y Rango de una Matriz</a></li>
<li class="chapter" data-level="1.1.11" data-path="acb-al.html"><a href="acb-al.html#formas-cuadraticas"><i class="fa fa-check"></i><b>1.1.11</b> Formas Cuadráticas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="algunas-propiedades-estadísticas-de-la-descomposición-de-una-matriz-en-valores-y-vectores-propios.html"><a href="algunas-propiedades-estadísticas-de-la-descomposición-de-una-matriz-en-valores-y-vectores-propios.html"><i class="fa fa-check"></i><b>1.2</b> Algunas Propiedades Estadísticas de la Descomposición de una Matriz en Valores y Vectores Propios</a></li>
<li class="chapter" data-level="1.3" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html"><i class="fa fa-check"></i><b>1.3</b> Diferenciación con Vectores y Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html#vector-gradiente-para-diferentes-definiciones-de-funderlinemathbfx"><i class="fa fa-check"></i><b>1.3.1</b> Vector-Gradiente para diferentes definiciones de <span class="math inline">\(f(\underline{\mathbf{x}})\)</span>:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="org_pres_dat.html"><a href="org_pres_dat.html"><i class="fa fa-check"></i><b>2</b> Organización y Presentación de Datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html"><i class="fa fa-check"></i><b>2.1</b> Resumenes Descriptivos</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#matriz-de-datos"><i class="fa fa-check"></i><b>2.1.1</b> Matriz de Datos</a></li>
<li class="chapter" data-level="2.1.2" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#estadísticos-descriptivos"><i class="fa fa-check"></i><b>2.1.2</b> Estadísticos descriptivos</a></li>
<li class="chapter" data-level="2.1.3" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#algunas-notaciones"><i class="fa fa-check"></i><b>2.1.3</b> Algunas Notaciones</a></li>
<li class="chapter" data-level="2.1.4" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#representación-gráfica-de-observaciones-multivariadas"><i class="fa fa-check"></i><b>2.1.4</b> Representación Gráfica de Observaciones multivariadas</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="vectores-y-matrices-aleatorias.html"><a href="vectores-y-matrices-aleatorias.html"><i class="fa fa-check"></i><b>2.2</b> Vectores y Matrices Aleatorias</a></li>
<li class="chapter" data-level="2.3" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html"><i class="fa fa-check"></i><b>2.3</b> Vectores y Matrices Poblacionales Particionados</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-del-vector-de-medias-poblacionales"><i class="fa fa-check"></i><b>2.3.1</b> Particionamiento del Vector de Medias-Poblacionales</a></li>
<li class="chapter" data-level="2.3.2" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-de-la-matriz-de-var-cov-poblacional-mathbfsigma"><i class="fa fa-check"></i><b>2.3.2</b> Particionamiento de la Matriz de Var-Cov Poblacional <span class="math inline">\(\mathbf{\Sigma}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.4</b> Propiedades Sobre la Media y Varianza de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.5" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html"><i class="fa fa-check"></i><b>2.5</b> Vectores y Matrices Muestrales Particionadas</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-del-vector-de-medias-muestrales"><i class="fa fa-check"></i><b>2.5.1</b> Particionamiento del Vector de Medias Muestrales</a></li>
<li class="chapter" data-level="2.5.2" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-de-la-matriz-de-var-cov-muestrales"><i class="fa fa-check"></i><b>2.5.2</b> Particionamiento de la Matriz de Var-Cov Muestrales</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="algunas-formas-matriciales-eficientes.html"><a href="algunas-formas-matriciales-eficientes.html"><i class="fa fa-check"></i><b>2.6</b> Algunas formas matriciales Eficientes</a></li>
<li class="chapter" data-level="2.7" data-path="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.7</b> Propiedades Sobre la Media y Varianza Muestral de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.8" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><i class="fa fa-check"></i><b>2.8</b> Varianza Generalizada Muestral y su Interpretación Geométrica</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-1-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.8.1</b> Interpretación Geométrica-1 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.8.2" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-2-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.8.2</b> Interpretación Geométrica-2 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.8.3" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#varianza-generalizada-determinada-por-la-matriz-de-correlación-muestral-mathbfr"><i class="fa fa-check"></i><b>2.8.3</b> Varianza Generalizada Determinada por la Matriz de Correlación Muestral <span class="math inline">\(\mathbf{R}\)</span></a></li>
<li class="chapter" data-level="2.8.4" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#relación-entre-mathbfs-y-mathbfr"><i class="fa fa-check"></i><b>2.8.4</b> Relación entre <span class="math inline">\(|\mathbf{S}|\)</span> y <span class="math inline">\(|\mathbf{R}|\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="varianza-total-muestral.html"><a href="varianza-total-muestral.html"><i class="fa fa-check"></i><b>2.9</b> Varianza Total Muestral</a></li>
<li class="chapter" data-level="2.10" data-path="muestra-aleatoria-de-distribuciones-p-variadas.html"><a href="muestra-aleatoria-de-distribuciones-p-variadas.html"><i class="fa fa-check"></i><b>2.10</b> Muestra Aleatoria de Distribuciones <span class="math inline">\(p\)</span>-Variadas</a></li>
<li class="chapter" data-level="2.11" data-path="distancias.html"><a href="distancias.html"><i class="fa fa-check"></i><b>2.11</b> Distancias</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="distancias.html"><a href="distancias.html#dist_euclidea"><i class="fa fa-check"></i><b>2.11.1</b> Definición de Algunas Distancias</a></li>
<li class="chapter" data-level="2.11.2" data-path="distancias.html"><a href="distancias.html#relación-de-la-distancia-de-mahalanobis-con-la-distribución-chi-cuadrado"><i class="fa fa-check"></i><b>2.11.2</b> Relación de la Distancia de Mahalanobis con la Distribución chi-Cuadrado</a></li>
<li class="chapter" data-level="2.11.3" data-path="distancias.html"><a href="distancias.html#ejemplo"><i class="fa fa-check"></i><b>2.11.3</b> Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Normal-Multiv.html"><a href="Normal-Multiv.html"><i class="fa fa-check"></i><b>3</b> Distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.1" data-path="geometria-NM.html"><a href="geometria-NM.html"><i class="fa fa-check"></i><b>3.1</b> Geometría y propiedades de la NM</a></li>
<li class="chapter" data-level="3.2" data-path="normal-univariada.html"><a href="normal-univariada.html"><i class="fa fa-check"></i><b>3.2</b> Normal Univariada</a></li>
<li class="chapter" data-level="3.3" data-path="normal-multivariada.html"><a href="normal-multivariada.html"><i class="fa fa-check"></i><b>3.3</b> Normal Multivariada</a></li>
<li class="chapter" data-level="3.4" data-path="algunos-aspectos-geométricos-de-la-nm.html"><a href="algunos-aspectos-geométricos-de-la-nm.html"><i class="fa fa-check"></i><b>3.4</b> Algunos Aspectos Geométricos de la NM</a></li>
<li class="chapter" data-level="3.5" data-path="prop-nm.html"><a href="prop-nm.html"><i class="fa fa-check"></i><b>3.5</b> Propiedades de la distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="prop-nm.html"><a href="prop-nm.html#prop1"><i class="fa fa-check"></i><b>3.5.1</b> <strong>Propiedad-1:</strong></a></li>
<li class="chapter" data-level="3.5.2" data-path="prop-nm.html"><a href="prop-nm.html#prop2"><i class="fa fa-check"></i><b>3.5.2</b> <strong>Propiedad-2:</strong></a></li>
<li class="chapter" data-level="3.5.3" data-path="prop-nm.html"><a href="prop-nm.html#prop3"><i class="fa fa-check"></i><b>3.5.3</b> <strong>Propiedad-3:</strong></a></li>
<li class="chapter" data-level="3.5.4" data-path="prop-nm.html"><a href="prop-nm.html#prop4"><i class="fa fa-check"></i><b>3.5.4</b> <strong>Propiedad-4:</strong></a></li>
<li class="chapter" data-level="3.5.5" data-path="prop-nm.html"><a href="prop-nm.html#prop5"><i class="fa fa-check"></i><b>3.5.5</b> <strong>Propiedad-5:</strong></a></li>
<li class="chapter" data-level="3.5.6" data-path="prop-nm.html"><a href="prop-nm.html#prop6"><i class="fa fa-check"></i><b>3.5.6</b> <strong>Propiedad-6:</strong></a></li>
<li class="chapter" data-level="3.5.7" data-path="prop-nm.html"><a href="prop-nm.html#prop7"><i class="fa fa-check"></i><b>3.5.7</b> <strong>Propiedad-7:</strong></a></li>
<li class="chapter" data-level="3.5.8" data-path="prop-nm.html"><a href="prop-nm.html#prop8"><i class="fa fa-check"></i><b>3.5.8</b> <strong>Propiedad-8:</strong></a></li>
<li class="chapter" data-level="3.5.9" data-path="prop-nm.html"><a href="prop-nm.html#prop9"><i class="fa fa-check"></i><b>3.5.9</b> <strong>Propiedad-9:</strong></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.6</b> Evaluación del Supuesto de Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-a-nivel-marginal-ie.-normalidad-univariada"><i class="fa fa-check"></i><b>3.6.1</b> Evaluación a nivel marginal (ie. Normalidad Univariada)</a></li>
<li class="chapter" data-level="3.6.2" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-de-la-normalidad-bi-variada"><i class="fa fa-check"></i><b>3.6.2</b> Evaluación de la Normalidad Bi-variada</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="detección-de-observaciones-atípicas.html"><a href="detección-de-observaciones-atípicas.html"><i class="fa fa-check"></i><b>3.7</b> Detección de Observaciones Atípicas</a></li>
<li class="chapter" data-level="3.8" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.8</b> Transformaciones para Acercar a la Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#familia-de-transformaciones-de-potencia-de-box-y-cox-1964"><i class="fa fa-check"></i><b>3.8.1</b> Familia de Transformaciones de Potencia de Box y Cox (1964)</a></li>
<li class="chapter" data-level="3.8.2" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#transformaciones-para-el-caso-multivariado"><i class="fa fa-check"></i><b>3.8.2</b> Transformaciones para el Caso Multivariado:</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html"><i class="fa fa-check"></i><b>3.9</b> Muestra Aleatoria Normal <span class="math inline">\(p\)</span>-Variada</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#estimadores-de-máx-ver-de-una-normal-multivariada"><i class="fa fa-check"></i><b>3.9.1</b> Estimadores de Máx-Ver de una Normal-Multivariada</a></li>
<li class="chapter" data-level="3.9.2" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#distribución-muestral-de-overlineunderlinemathbfx-y-mathbfs_n"><i class="fa fa-check"></i><b>3.9.2</b> Distribución Muestral de <span class="math inline">\(\overline{\underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\mathbf{S}_n\)</span></a></li>
<li class="chapter" data-level="3.9.3" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#comportamiento-de-underlineoverlinemathbfx_p-y-mathbfs-para-tamaños-muestrales-grandes"><i class="fa fa-check"></i><b>3.9.3</b> Comportamiento de <span class="math inline">\(\underline{\overline{\mathbf{x}}}_p\)</span> y <span class="math inline">\(\mathbf{S}\)</span> para Tamaños Muestrales Grandes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferen-estad.html"><a href="inferen-estad.html"><i class="fa fa-check"></i><b>4</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="inferencia-estadística-para-la-media-mu-caso-univariado.html"><a href="inferencia-estadística-para-la-media-mu-caso-univariado.html"><i class="fa fa-check"></i><b>4.2</b> Inferencia Estadística para la Media (<span class="math inline">\(\mu\)</span>)-caso univariado</a></li>
<li class="chapter" data-level="4.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><i class="fa fa-check"></i><b>4.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-desconocida-normal"><i class="fa fa-check"></i><b>4.3.1</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Desconocida (Normal)</a></li>
<li class="chapter" data-level="4.3.2" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-conocida-población-normal"><i class="fa fa-check"></i><b>4.3.2</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Conocida (Población: Normal)</a></li>
<li class="chapter" data-level="4.3.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-en-muestra-grande"><i class="fa fa-check"></i><b>4.3.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> en Muestra Grande</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><i class="fa fa-check"></i><b>4.4</b> PH Acerca de Contrastes del Vector de Medias Poblacional <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>, de una <span class="math inline">\(N_p(\underline{\boldsymbol{\mu}} \ , \ \mathbf{\Sigma} )\)</span></a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html#ph-de-contrastes-para-el-caso-de-pnm"><i class="fa fa-check"></i><b>4.4.1</b> PH de Contrastes para el Caso de PNM</a></li>
<li class="chapter" data-level="4.4.2" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html#ph-de-contrastes-en-en-caso-de-n-grande"><i class="fa fa-check"></i><b>4.4.2</b> PH de Contrastes en en caso de <span class="math inline">\(n\)</span>-Grande</a></li>
<li class="chapter" data-level="4.4.3" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html#prueba-de-hipótesis-para-igualdad-de-medias"><i class="fa fa-check"></i><b>4.4.3</b> Prueba de hipótesis para igualdad de medias</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><i class="fa fa-check"></i><b>4.5</b> PH para Igualdad de Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{x}}}=\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{y}}}\)</span></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html#caso-1.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-conocida"><i class="fa fa-check"></i><b>4.5.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.5.2" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html#caso-2.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-desconocida"><i class="fa fa-check"></i><b>4.5.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.5.3" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html#caso-3.-mathbfsigma_-underlinemathbfxneq-mathbfsigma_-underlinemathbfy-desconocida"><i class="fa fa-check"></i><b>4.5.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}\neq \mathbf{\Sigma}_{\ \underline{\mathbf{y}}}\)</span>-Desconocida</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><i class="fa fa-check"></i><b>4.6</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{y}}}\)</span>,   para muestras grandes</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html#caso-1.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-conocida-1"><i class="fa fa-check"></i><b>4.6.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.6.2" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html#caso-2.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-desconocida-1"><i class="fa fa-check"></i><b>4.6.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.6.3" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html#caso-3.-mathbfsigma_-underlinemathbfx-neq-mathbfsigma_-underlinemathbfy-desconocidas"><i class="fa fa-check"></i><b>4.6.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}} \neq \mathbf{\Sigma}_{\ \underline{\mathbf{y}}}\)</span>-Desconocidas</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><i class="fa fa-check"></i><b>4.7</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{y}}}\)</span>,      Observaciones Pareadas</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#caso-univariado"><i class="fa fa-check"></i><b>4.7.1</b> Caso Univariado</a></li>
<li class="chapter" data-level="4.7.2" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#caso-multivariado"><i class="fa fa-check"></i><b>4.7.2</b> Caso Multivariado</a></li>
<li class="chapter" data-level="4.7.3" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#uso-de-contrastes-para-la-comparación-de-medias-en-muestras-pareadas"><i class="fa fa-check"></i><b>4.7.3</b> Uso de Contrastes para la Comparación de Medias en Muestras Pareadas</a></li>
<li class="chapter" data-level="4.7.4" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#un-diseño-de-medidas-repetidas-para-comparar-tratamientos"><i class="fa fa-check"></i><b>4.7.4</b> Un Diseño de Medidas Repetidas para Comparar Tratamientos</a></li>
<li class="chapter" data-level="4.7.5" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#análisis-de-perfiles"><i class="fa fa-check"></i><b>4.7.5</b> Análisis de Perfiles</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html"><i class="fa fa-check"></i><b>4.8</b> Inferencia para la Matriz de Varianzas Covarianza</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#prueva-de-rv-sigma"><i class="fa fa-check"></i><b>4.8.1</b> Pruba de Razón de Verosimilitud</a></li>
<li class="chapter" data-level="4.8.2" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#prueba-de-bartlet"><i class="fa fa-check"></i><b>4.8.2</b> Prueba de Bartlet</a></li>
<li class="chapter" data-level="4.8.3" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#dos-o-más-matrices-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.3</b> Dos o más Matrices de Varianzas Covarianzas</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><i class="fa fa-check"></i><b>4.9</b> Regiones de Confianza y Comparaciones Simultáneas entre las Componentes del Vector de Medias <span class="math inline">\(\underline{\boldsymbol \mu}\)</span></a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#construcción-de-una-región-de-confianza-para-underlineboldsymbol-mu-cuando-la-población-tiene-distribución-n_punderlineboldsymbol-mumathbfsigma-con-underlineboldsymbol-mu-y-mathbfsigma-desconocidos"><i class="fa fa-check"></i><b>4.9.1</b> Construcción de una Región de Confianza para <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> Cuando la Población tiene Distribución <span class="math inline">\(N_p(\underline{\boldsymbol \mu},\mathbf{\Sigma})\)</span>, con <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> y <span class="math inline">\(\mathbf{\Sigma}\)</span> desconocidos</a></li>
<li class="chapter" data-level="4.9.2" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#región-de-confianza-para-el-caso-de-p2-elipse-de-confianza"><i class="fa fa-check"></i><b>4.9.2</b> Región de Confianza para el Caso de <span class="math inline">\(p=2\)</span> (Elipse de Confianza)</a></li>
<li class="chapter" data-level="4.9.3" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#intervalos-de-confianza-simultáneos-para-las-componentes-del-vector-de-medias-underlineboldsymbol-mu"><i class="fa fa-check"></i><b>4.9.3</b> Intervalos de Confianza Simultáneos para las Componentes del Vector de Medias <span class="math inline">\(\underline{\boldsymbol \mu}\)</span></a></li>
<li class="chapter" data-level="4.9.4" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#ic-t2-simultáneos-para-diferencias-de-medias"><i class="fa fa-check"></i><b>4.9.4</b> IC <span class="math inline">\(T^2\)</span> Simultáneos para Diferencias de Medias</a></li>
<li class="chapter" data-level="4.9.5" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#IC-Bonferroni"><i class="fa fa-check"></i><b>4.9.5</b> Método de Bonferroni para Comparaciones Múltiples</a></li>
<li class="chapter" data-level="4.9.6" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#intervalos-de-confianza-simultáneos-chi2-caso-n-grande"><i class="fa fa-check"></i><b>4.9.6</b> Intervalos de Confianza Simultáneos <span class="math inline">\(\chi^2\)</span> (caso n-Grande)</a></li>
<li class="chapter" data-level="4.9.7" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#ic-simultáneos-para-n-grande-usando-la-normal-estándar-z_alpha"><i class="fa fa-check"></i><b>4.9.7</b> IC Simultáneos para n-Grande Usando la Normal Estándar <span class="math inline">\(Z_\alpha\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mrlm.html"><a href="mrlm.html"><i class="fa fa-check"></i><b>5</b> Modelos de Regresión Lineal Multivariados</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introducción-2.html"><a href="introducción-2.html"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="rlm.html"><a href="rlm.html"><i class="fa fa-check"></i><b>5.2</b> Modelo de Regresión Lineal Múltiple (RLM)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="rlm.html"><a href="rlm.html#estimación-de-mínimos-cuadrados"><i class="fa fa-check"></i><b>5.2.1</b> Estimación de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="5.2.2" data-path="rlm.html"><a href="rlm.html#inferencias-acerca-del-modelo-de-regresión-lineal-múltiple"><i class="fa fa-check"></i><b>5.2.2</b> Inferencias Acerca del Modelo de Regresión Lineal Múltiple</a></li>
<li class="chapter" data-level="5.2.3" data-path="rlm.html"><a href="rlm.html#inferencias-a-partir-de-la-función-de-regresión-estimada"><i class="fa fa-check"></i><b>5.2.3</b> Inferencias A partir de la Función de Regresión Estimada</a></li>
<li class="chapter" data-level="5.2.4" data-path="rlm.html"><a href="rlm.html#validación-de-los-supuestos-del-modelo-y-otros-aspectos-del-la-regresión"><i class="fa fa-check"></i><b>5.2.4</b> Validación de los Supuestos del Modelo y Otros Aspectos del la Regresión</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="mrl-multiv.html"><a href="mrl-multiv.html"><i class="fa fa-check"></i><b>5.3</b> Modelo de Regresión Lineal Multivariado (RL-Multivariado)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="mrl-multiv.html"><a href="mrl-multiv.html#algunas-notaciones-1"><i class="fa fa-check"></i><b>5.3.1</b> Algunas Notaciones</a></li>
<li class="chapter" data-level="5.3.2" data-path="mrl-multiv.html"><a href="mrl-multiv.html#mrl-multivariado-en-forma-matricial"><i class="fa fa-check"></i><b>5.3.2</b> MRL-Multivariado en forma Matricial</a></li>
<li class="chapter" data-level="5.3.3" data-path="mrl-multiv.html"><a href="mrl-multiv.html#m-mrl-múltiples"><i class="fa fa-check"></i><b>5.3.3</b> <span class="math inline">\(m\)</span>-MRL-Múltiples</a></li>
<li class="chapter" data-level="5.3.4" data-path="mrl-multiv.html"><a href="mrl-multiv.html#estimador-de-mínimos-cuadrados-de-los-parámetros"><i class="fa fa-check"></i><b>5.3.4</b> Estimador de Mínimos Cuadrados de los Parámetros</a></li>
<li class="chapter" data-level="5.3.5" data-path="mrl-multiv.html"><a href="mrl-multiv.html#propiedades-de-estimadores-de-mínimos-cuadrados-del-mrl-multivariado"><i class="fa fa-check"></i><b>5.3.5</b> Propiedades de Estimadores de Mínimos Cuadrados del MRL-Multivariado</a></li>
<li class="chapter" data-level="5.3.6" data-path="mrl-multiv.html"><a href="mrl-multiv.html#prv-mrl-multivariado"><i class="fa fa-check"></i><b>5.3.6</b> Prueba de Razón de Verosimilitud para Parámetros de Regresión en MRL-Multivariados</a></li>
<li class="chapter" data-level="5.3.7" data-path="mrl-multiv.html"><a href="mrl-multiv.html#otras-pruebas-estadísticas-multivariadas"><i class="fa fa-check"></i><b>5.3.7</b> Otras Pruebas Estadísticas Multivariadas</a></li>
<li class="chapter" data-level="5.3.8" data-path="mrl-multiv.html"><a href="mrl-multiv.html#predicciones-a-partir-de-un-modelo-de-regresión-múltiple-multivariado"><i class="fa fa-check"></i><b>5.3.8</b> Predicciones A Partir de un Modelo de Regresión Múltiple Multivariado</a></li>
<li class="chapter" data-level="5.3.9" data-path="mrl-multiv.html"><a href="mrl-multiv.html#el-concepto-de-regresión-lineal"><i class="fa fa-check"></i><b>5.3.9</b> El Concepto de Regresión Lineal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ACP.html"><a href="ACP.html"><i class="fa fa-check"></i><b>6</b> Análisis de Componentes Principales (ACP)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducción-3.html"><a href="introducción-3.html"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="interpretaciones-geométricas-y-algebraícas-del-acp.html"><a href="interpretaciones-geométricas-y-algebraícas-del-acp.html"><i class="fa fa-check"></i><b>6.2</b> Interpretaciones Geométricas y Algebraícas del ACP</a></li>
<li class="chapter" data-level="6.3" data-path="interpretación-geométrica-del-acp-mediante-un-ejemplo-simple-p2.html"><a href="interpretación-geométrica-del-acp-mediante-un-ejemplo-simple-p2.html"><i class="fa fa-check"></i><b>6.3</b> Interpretación Geométrica del ACP Mediante un Ejemplo Simple <span class="math inline">\(p=2\)</span></a></li>
<li class="chapter" data-level="6.4" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html"><i class="fa fa-check"></i><b>6.4</b> Mas de dos Ejes</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#min-cuadrados"><i class="fa fa-check"></i><b>6.4.1</b> Ajuste de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="6.4.2" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#relación-entre-los-sub-espacios-de-mathbbrp-y-de-mathbbrn"><i class="fa fa-check"></i><b>6.4.2</b> Relación entre los Sub-espacios de <span class="math inline">\(\mathbb{R}^p\)</span> y de <span class="math inline">\(\mathbb{R}^n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="componentes-principales-en-análisis-de-regresión.html"><a href="componentes-principales-en-análisis-de-regresión.html"><i class="fa fa-check"></i><b>6.5</b> Componentes Principales en Análisis de Regresión</a></li>
<li class="chapter" data-level="6.6" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html"><i class="fa fa-check"></i><b>6.6</b> Componentes Principales Poblacionales</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#definicón-de-las-cps-poblacionales"><i class="fa fa-check"></i><b>6.6.1</b> Definicón de las CPs Poblacionales</a></li>
<li class="chapter" data-level="6.6.2" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#determinación-de-las-cps-poblacionales"><i class="fa fa-check"></i><b>6.6.2</b> Determinación de las CPs Poblacionales</a></li>
<li class="chapter" data-level="6.6.3" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-derivadas-de-una-normal-multivariada"><i class="fa fa-check"></i><b>6.6.3</b> Componentes Principales Derivadas de una Normal Multivariada</a></li>
<li class="chapter" data-level="6.6.4" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-usando-variables-estandarizadas"><i class="fa fa-check"></i><b>6.6.4</b> Componentes Principales usando Variables Estandarizadas</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><i class="fa fa-check"></i><b>6.7</b> Componentes Principales para Matrices de Var-Cov <span class="math inline">\(\mathbf{\Sigma}\)</span> con Estructuras Especiales</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#variables-no-correlacionadas"><i class="fa fa-check"></i><b>6.7.1</b> Variables No-Correlacionadas</a></li>
<li class="chapter" data-level="6.7.2" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#var-correlacionadas"><i class="fa fa-check"></i><b>6.7.2</b> Variables Altamente Correlacionadas</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="componentes-principales-muestrales.html"><a href="componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>6.8</b> Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="6.9" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html"><i class="fa fa-check"></i><b>6.9</b> Algunos Ejemplos de ACP</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo1"><i class="fa fa-check"></i><b>6.9.1</b> Ejemplo-1</a></li>
<li class="chapter" data-level="6.9.2" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo-2"><i class="fa fa-check"></i><b>6.9.2</b> Ejemplo-2</a></li>
<li class="chapter" data-level="6.9.3" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo-3"><i class="fa fa-check"></i><b>6.9.3</b> Ejemplo-3</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="cómo-elegir-el-número-de-componentes-principales.html"><a href="cómo-elegir-el-número-de-componentes-principales.html"><i class="fa fa-check"></i><b>6.10</b> Cómo elegir el número de Componentes Principales?</a></li>
<li class="chapter" data-level="6.11" data-path="interpretación-de-las-componentes-principales-muestrales.html"><a href="interpretación-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>6.11</b> Interpretación de las Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="6.12" data-path="estandarización-de-las-componentes-principales-muestrales.html"><a href="estandarización-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>6.12</b> Estandarización de las Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="6.13" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html"><i class="fa fa-check"></i><b>6.13</b> Gráficas en un Análisis de Componentes Principales</a>
<ul>
<li class="chapter" data-level="6.13.1" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html#graficos-de-las-cps"><i class="fa fa-check"></i><b>6.13.1</b> Graficos de las CPS</a></li>
<li class="chapter" data-level="6.13.2" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html#el-gráfico-biplot"><i class="fa fa-check"></i><b>6.13.2</b> El gráfico biplot:</a></li>
</ul></li>
<li class="chapter" data-level="6.14" data-path="propiedades-de-hatlambda_i-y-underlinehatmathbfe_i-en-muestras-grandes.html"><a href="propiedades-de-hatlambda_i-y-underlinehatmathbfe_i-en-muestras-grandes.html"><i class="fa fa-check"></i><b>6.14</b> Propiedades de <span class="math inline">\(\hat{\lambda}_i\)</span> y <span class="math inline">\(\underline{\hat{\mathbf{e}}}_i\)</span> en Muestras Grandes</a></li>
<li class="chapter" data-level="6.15" data-path="prueba-de-hipótesis-para-estructura-de-correlación-igual.html"><a href="prueba-de-hipótesis-para-estructura-de-correlación-igual.html"><i class="fa fa-check"></i><b>6.15</b> Prueba de Hipótesis para Estructura de Correlación Igual</a></li>
<li class="chapter" data-level="6.16" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html"><i class="fa fa-check"></i><b>6.16</b> Ejemplos Finales</a>
<ul>
<li class="chapter" data-level="6.16.1" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-1"><i class="fa fa-check"></i><b>6.16.1</b> Ejemplo-1</a></li>
<li class="chapter" data-level="6.16.2" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-acp-con-individuos-y-variables-suplementarias"><i class="fa fa-check"></i><b>6.16.2</b> Ejemplo ACP con Individuos y Variables Suplementarias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="affc.html"><a href="affc.html"><i class="fa fa-check"></i><b>7</b> Análisis Factorial de Factores Comunes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introducción-4.html"><a href="introducción-4.html"><i class="fa fa-check"></i><b>7.1</b> Introducción</a></li>
<li class="chapter" data-level="7.2" data-path="tipos-de-factores.html"><a href="tipos-de-factores.html"><i class="fa fa-check"></i><b>7.2</b> Tipos de Factores</a></li>
<li class="chapter" data-level="7.3" data-path="motivación-del-análisis-factorial.html"><a href="motivación-del-análisis-factorial.html"><i class="fa fa-check"></i><b>7.3</b> Motivación del Análisis Factorial</a></li>
<li class="chapter" data-level="7.4" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html"><i class="fa fa-check"></i><b>7.4</b> Enfoques del AF</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#métodos-para-realizar-la-extracción-de-los-factores"><i class="fa fa-check"></i><b>7.4.1</b> Métodos para realizar la extracción de los factores</a></li>
<li class="chapter" data-level="7.4.2" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#rotación-de-ejes"><i class="fa fa-check"></i><b>7.4.2</b> Rotación de Ejes</a></li>
<li class="chapter" data-level="7.4.3" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#puntuaciones-o-scores-de-los-sujetos-en-los-factores-extraídos"><i class="fa fa-check"></i><b>7.4.3</b> Puntuaciones o Scores de los Sujetos en los Factores Extraídos</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html"><i class="fa fa-check"></i><b>7.5</b> El Modelo de Factor Ortogonal</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html#estructura-de-covarianzas-del-modelo-de-factor-ortogonal"><i class="fa fa-check"></i><b>7.5.1</b> Estructura de Covarianzas del Modelo de Factor Ortogonal</a></li>
<li class="chapter" data-level="7.5.2" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html#ejemplos"><i class="fa fa-check"></i><b>7.5.2</b> Ejemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html"><i class="fa fa-check"></i><b>7.6</b> Métodos de Estimación</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#metodo-cp"><i class="fa fa-check"></i><b>7.6.1</b> El Método de la Componente Principal</a></li>
<li class="chapter" data-level="7.6.2" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#metodo-pa"><i class="fa fa-check"></i><b>7.6.2</b> Una Aproximación Modificada (La Solución del Factor Principal o de las CP-Iteradas o de Ejes Principales-PA)</a></li>
<li class="chapter" data-level="7.6.3" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#metodo-mle"><i class="fa fa-check"></i><b>7.6.3</b> El Método de Máxima Verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="prueba-para-el-número-de-factores-muestra-grande..html"><a href="prueba-para-el-número-de-factores-muestra-grande..html"><i class="fa fa-check"></i><b>7.7</b> Prueba para el Número de Factores (Muestra Grande).</a></li>
<li class="chapter" data-level="7.8" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html"><i class="fa fa-check"></i><b>7.8</b> Rotación de Factores</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#rotaciones-cuando-m2-factores"><i class="fa fa-check"></i><b>7.8.1</b> Rotaciones cuando <span class="math inline">\(m=2\)</span>-Factores</a></li>
<li class="chapter" data-level="7.8.2" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#criterio-varimáx"><i class="fa fa-check"></i><b>7.8.2</b> Criterio Varimáx:</a></li>
<li class="chapter" data-level="7.8.3" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#rotaciones-oblicuas"><i class="fa fa-check"></i><b>7.8.3</b> Rotaciones Oblicuas</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="factores-scores-o-puntuaciones-de-los-factores.html"><a href="factores-scores-o-puntuaciones-de-los-factores.html"><i class="fa fa-check"></i><b>7.9</b> Factores-Scores (o Puntuaciones) de los Factores</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="factores-scores-o-puntuaciones-de-los-factores.html"><a href="factores-scores-o-puntuaciones-de-los-factores.html#método-de-los-mínimos-cuadrados-ponderados"><i class="fa fa-check"></i><b>7.9.1</b> Método de los Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="7.9.2" data-path="factores-scores-o-puntuaciones-de-los-factores.html"><a href="factores-scores-o-puntuaciones-de-los-factores.html#el-método-de-la-regresión"><i class="fa fa-check"></i><b>7.9.2</b> El Método de la Regresión</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="perspectivas-y-estrategías-para-el-análisis-de-factor.html"><a href="perspectivas-y-estrategías-para-el-análisis-de-factor.html"><i class="fa fa-check"></i><b>7.10</b> Perspectivas y Estrategías para el Análisis de Factor</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="avm.html"><a href="avm.html"><i class="fa fa-check"></i><b>8</b> Análisis de Varianza Multivariado (MANOVA)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="introducción-5.html"><a href="introducción-5.html"><i class="fa fa-check"></i><b>8.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="introducción-5.html"><a href="introducción-5.html#suposiciones-del-manova"><i class="fa fa-check"></i><b>8.1.1</b> Suposiciones del MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>8.2</b> Análisis de Varianza Univariado (ANOVA)</a></li>
<li class="chapter" data-level="8.3" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>8.3</b> Análisis de Varianza Multivariado (MANOVA)</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="manova.html"><a href="manova.html#modelo-manova-para-comparar-g-vectores-de-medias-poblacionales"><i class="fa fa-check"></i><b>8.3.1</b> Modelo MANOVA para comparar <span class="math inline">\(g\)</span>-Vectores de Medias Poblacionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="adiscriminante.html"><a href="adiscriminante.html"><i class="fa fa-check"></i><b>9</b> Análisis Discriminante y Clasificación</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introducción-6.html"><a href="introducción-6.html"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html"><a href="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.2</b> Separación y Clasificación para el caso de dos poblaciones</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html"><a href="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html#clasificación-de-dos-poblaciones"><i class="fa fa-check"></i><b>9.2.1</b> Clasificación de dos Poblaciones</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.3</b> Regla de Discriminación para dos Poblaciones</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html#costo-esperado-de-mal-clasificación"><i class="fa fa-check"></i><b>9.3.1</b> Costo Esperado de Mal Clasificación</a></li>
<li class="chapter" data-level="9.3.2" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html#probabilidad-total-de-mal-clasificación"><i class="fa fa-check"></i><b>9.3.2</b> Probabilidad Total de Mal Clasificación</a></li>
<li class="chapter" data-level="9.3.3" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html#regla-de-clasificación-de-bayes"><i class="fa fa-check"></i><b>9.3.3</b> Regla de Clasificación de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="dos-pob-nm.html"><a href="dos-pob-nm.html"><i class="fa fa-check"></i><b>9.4</b> Clasificación con Dos Poblaciones Normales Multivariadas</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="dos-pob-nm.html"><a href="dos-pob-nm.html#clasificación-con-dos-poblaciones-normales-donde-mathbfsigma_1mathbfsigma_2mathbfsigma"><i class="fa fa-check"></i><b>9.4.1</b> Clasificación con dos Poblaciones Normales donde <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span></a></li>
<li class="chapter" data-level="9.4.2" data-path="dos-pob-nm.html"><a href="dos-pob-nm.html#clasificación-con-dos-poblaciones-normales-donde-mathbfsigma_1neq-mathbfsigma_2"><i class="fa fa-check"></i><b>9.4.2</b> Clasificación con dos Poblaciones Normales donde <span class="math inline">\(\mathbf{\Sigma}_1\neq \mathbf{\Sigma}_2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html"><i class="fa fa-check"></i><b>9.5</b> Evaluación de las Funciones de Clasificación</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-óptimo-teo"><i class="fa fa-check"></i><b>9.5.1</b> Tasa de Error Óptimo (TEO)</a></li>
<li class="chapter" data-level="9.5.2" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-actual"><i class="fa fa-check"></i><b>9.5.2</b> Tasa de Error Actual</a></li>
<li class="chapter" data-level="9.5.3" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-aparente-teap"><i class="fa fa-check"></i><b>9.5.3</b> Tasa de Error Aparente (TEAP)</a></li>
<li class="chapter" data-level="9.5.4" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-actual-esperada"><i class="fa fa-check"></i><b>9.5.4</b> Tasa de Error Actual Esperada</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html"><a href="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.6</b> Clasificación con Varias Poblaciones (Es decir Más de dos Poblaciones)</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html"><a href="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html#costo-esperado-de-mal-clasificación-ecm"><i class="fa fa-check"></i><b>9.6.1</b> Costo Esperado de Mal Clasificación (ECM)</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.7</b> Clasificación con Poblaciones Normales y más de dos Poblaciones</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html#un-clasificador-equivalente-para-el-caso-de-matrices-de-var-cov-iguales"><i class="fa fa-check"></i><b>9.7.1</b> Un Clasificador Equivalente para el Caso de Matrices de Var-Cov Iguales</a></li>
<li class="chapter" data-level="9.7.2" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html#comparación-dos-a-dos-de-los-scores-de-la-función-de-clasificación-lineal"><i class="fa fa-check"></i><b>9.7.2</b> Comparación Dos a Dos de los Scores de la Función de Clasificación Lineal</a></li>
<li class="chapter" data-level="9.7.3" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html#tasa-de-error-actual-esperada-aer-estimada"><i class="fa fa-check"></i><b>9.7.3</b> Tasa de Error Actual Esperada (AER) Estimada</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><i class="fa fa-check"></i><b>9.8</b> Método de Fisher Para Discriminar Entre Varias Poblaciones</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html#uso-de-la-función-de-discriminación-de-fisher-para-clasificación"><i class="fa fa-check"></i><b>9.8.1</b> Uso de la Función de Discriminación de Fisher Para Clasificación</a></li>
<li class="chapter" data-level="9.8.2" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html#relación-entre-la-regla-de-clasificación-de-fisher-y-las-funciones-de-discriminación-de-la-teoría-normal"><i class="fa fa-check"></i><b>9.8.2</b> Relación entre la Regla de Clasificación de Fisher y las Funciones de Discriminación de la Teoría Normal</a></li>
<li class="chapter" data-level="9.8.3" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html#regla-de-clasificación-de-fisher-basado-en-discriminantes-muestrales"><i class="fa fa-check"></i><b>9.8.3</b> Regla de Clasificación de Fisher Basado en Discriminantes Muestrales</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html"><i class="fa fa-check"></i><b>9.9</b> Regresión Logística y Clasificación</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#el-modelo-logit"><i class="fa fa-check"></i><b>9.9.1</b> El Modelo Logit</a></li>
<li class="chapter" data-level="9.9.2" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#análisis-de-regresión-logística"><i class="fa fa-check"></i><b>9.9.2</b> Análisis de Regresión Logística</a></li>
<li class="chapter" data-level="9.9.3" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#regresión-logística-con-respuestas-binomiales"><i class="fa fa-check"></i><b>9.9.3</b> Regresión Logística con Respuestas Binomiales</a></li>
<li class="chapter" data-level="9.9.4" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#chequeo-del-modelo"><i class="fa fa-check"></i><b>9.9.4</b> Chequeo del Modelo</a></li>
<li class="chapter" data-level="9.9.5" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#prueba-de-residuales-y-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>9.9.5</b> Prueba de Residuales y de Bondad de Ajuste</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="acluster.html"><a href="acluster.html"><i class="fa fa-check"></i><b>10</b> Análisis de Agrupamiento o Cluster</a>
<ul>
<li class="chapter" data-level="10.1" data-path="introducción-7.html"><a href="introducción-7.html"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="consideraciones-iniciales.html"><a href="consideraciones-iniciales.html"><i class="fa fa-check"></i><b>10.2</b> Consideraciones Iniciales</a></li>
<li class="chapter" data-level="10.3" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html"><i class="fa fa-check"></i><b>10.3</b> Medidas de Similaridad entre Pares de Observaciones</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html#medidas-de-distancia"><i class="fa fa-check"></i><b>10.3.1</b> Medidas de Distancia</a></li>
<li class="chapter" data-level="10.3.2" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html#coeficientes-de-correlación-entre-casos"><i class="fa fa-check"></i><b>10.3.2</b> Coeficientes de Correlación (entre casos)</a></li>
<li class="chapter" data-level="10.3.3" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html#coeficientes-binarios-de-asociación-o-similaridad-entre-observaciones"><i class="fa fa-check"></i><b>10.3.3</b> Coeficientes Binarios de Asociación o Similaridad Entre Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="medidas-de-similaridad-o-asociación-para-pares-de-variables.html"><a href="medidas-de-similaridad-o-asociación-para-pares-de-variables.html"><i class="fa fa-check"></i><b>10.4</b> Medidas de Similaridad o Asociación para Pares de Variables</a></li>
<li class="chapter" data-level="10.5" data-path="métodos-jerárquicos-de-agrupamiento.html"><a href="métodos-jerárquicos-de-agrupamiento.html"><i class="fa fa-check"></i><b>10.5</b> Métodos Jerárquicos de Agrupamiento</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="métodos-jerárquicos-de-agrupamiento.html"><a href="métodos-jerárquicos-de-agrupamiento.html#métodos-jerarquicos-de-enlaces-para-agupamientos-aglomerativos"><i class="fa fa-check"></i><b>10.5.1</b> Métodos Jerarquicos de Enlaces para Agupamientos Aglomerativos</a></li>
<li class="chapter" data-level="10.5.2" data-path="métodos-jerárquicos-de-agrupamiento.html"><a href="métodos-jerárquicos-de-agrupamiento.html#métodos-jerarquicos-de-agrupamientos-desaglomerativos"><i class="fa fa-check"></i><b>10.5.2</b> Métodos Jerarquicos de Agrupamientos Desaglomerativos</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><a href="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><i class="fa fa-check"></i><b>10.6</b> Métodos NO-Jerárquicos de Partición o Agrupamiento</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><a href="métodos-no-jerárquicos-de-partición-o-agrupamiento.html#pasos-o-etapas-de-un-método-de-clasificación-no-jararquico"><i class="fa fa-check"></i><b>10.6.1</b> Pasos o etapas de un Método de Clasificación No-Jararquico</a></li>
<li class="chapter" data-level="10.6.2" data-path="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><a href="métodos-no-jerárquicos-de-partición-o-agrupamiento.html#método-de-las-k-medias-o-k-means"><i class="fa fa-check"></i><b>10.6.2</b> Método de las <span class="math inline">\(k\)</span>-Medias o <span class="math inline">\(k\)</span>-means</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="cómo-determinar-el-número-apropiado-de-conglomerados.html"><a href="cómo-determinar-el-número-apropiado-de-conglomerados.html"><i class="fa fa-check"></i><b>10.7</b> Cómo determinar el número apropiado de conglomerados?</a></li>
<li class="chapter" data-level="10.8" data-path="agrupamientos-basados-en-modelos-estadísticos.html"><a href="agrupamientos-basados-en-modelos-estadísticos.html"><i class="fa fa-check"></i><b>10.8</b> Agrupamientos Basados en Modelos Estadísticos</a></li>
<li class="chapter" data-level="10.9" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html"><i class="fa fa-check"></i><b>10.9</b> Escalamiento Multidimensional</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#el-algoritmo-básico"><i class="fa fa-check"></i><b>10.9.1</b> El Algoritmo Básico</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html"><i class="fa fa-check"></i><b>10.10</b> Análisis de Correspondencia</a>
<ul>
<li class="chapter" data-level="10.10.1" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html#desarrollo-algebraíco-del-análsisi-de-correspondencia"><i class="fa fa-check"></i><b>10.10.1</b> Desarrollo Algebraíco del Análsisi de Correspondencia</a></li>
<li class="chapter" data-level="10.10.2" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html#análisis-de-correspondencia-como-un-problema-de-mínimos-cuadrados-ponderado"><i class="fa fa-check"></i><b>10.10.2</b> Análisis de Correspondencia como un Problema de Mínimos Cuadrados Ponderado</a></li>
<li class="chapter" data-level="10.10.3" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html#análisis-de-correspondencia-medinate-el-método-de-aproximación-de-perfiles"><i class="fa fa-check"></i><b>10.10.3</b> Análisis de Correspondencia Medinate el Método de Aproximación de Perfiles</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html"><a href="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html"><i class="fa fa-check"></i><b>10.11</b> Biplots para la Visualización de Unidades Muestrales y Variables</a>
<ul>
<li class="chapter" data-level="10.11.1" data-path="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html"><a href="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html#construcción-de-un-biplot"><i class="fa fa-check"></i><b>10.11.1</b> Construcción de un Biplot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Chapter 10</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="factores-scores-o-puntuaciones-de-los-factores" class="section level2 hasAnchor" number="7.9">
<h2><span class="header-section-number">7.9</span> Factores-Scores (o Puntuaciones) de los Factores<a href="factores-scores-o-puntuaciones-de-los-factores.html#factores-scores-o-puntuaciones-de-los-factores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En el análisis de factor, el interés generalmente se centra en los parámetros del modelo ( es decir, las matrices <span class="math inline">\(\mathbf{L}\)</span> y <span class="math inline">\(\mathbf{\Psi}\)</span>). Sin embargo, los valores estimados de los factores comunes, <strong>llamados Factores-Scores o Puntuaciones de los Factores</strong>, también pueden ser de utilidad. Estas cantidades son usadas frecuentemente para propósitos de diagnóstico del modelo y como insumos para análisis posteriores.</p>
<p>Dado el vector de los <span class="math inline">\(m\)</span>-factores:
<span class="math display">\[
\underline{\mathbf{f}}= \begin{bmatrix} F_{1} \\ F_{2} \\ \vdots \\ F_{m} \end{bmatrix}_{m\times 1}
\]</span></p>
<p>y
<span class="math display">\[
\underline{\mathbf{f}}_j= \begin{bmatrix} f_{j1} &amp; f_{j2} &amp; \cdots &amp; f_{jm} \end{bmatrix}_{1\times m} \ \ \ \ \ , \ \ \ \ \ \hat{\underline{\mathbf{f}}}_j= \begin{bmatrix} \hat{f}_{j1} &amp; \hat{f}_{j2} &amp; \cdots &amp; \hat{f}_{jm} \end{bmatrix}_{1\times m} \ \ \ j=1,2,\ldots,n
\]</span></p>
<p>donde los Factores-Scores o puntuaciones de los factores <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> no son estimaciones de parámetros desconocidos en el sentido usual, en realidad, son estimaciones para los valores de los <strong>Vectores Aleatorios no Observables</strong> <span class="math inline">\(\underline{\mathbf{f}}_j\)</span>, <span class="math inline">\(j=1, 2, \ldots, n\)</span>. Es decir, <span class="math inline">\(\underline{\mathbf{f}}_j\)</span> contiene <strong>los puntajes obtenidos</strong> por el <span class="math inline">\(j\)</span>-ésimo caso (u observación) en los <span class="math inline">\(m\)</span> factores y <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> contiene las resepctivas estimaciones de los valores de <span class="math inline">\(\underline{\mathbf{f}}_j\)</span>.</p>
<p>La matriz de Factores-Scores o Puntuaciones de los Factores es denotada por:
<span class="math display">\[
\mathbf{F}_{n\times m}=\begin{bmatrix}
f_{11} &amp; f_{12} &amp; \cdots &amp; f_{1m}\\
f_{21} &amp; f_{22} &amp; \cdots &amp; f_{2m}\\
\vdots &amp; \vdots &amp; &amp; \vdots \\
f_{n1} &amp; f_{n2} &amp; \cdots &amp; f_{nm}
\end{bmatrix}=
\begin{bmatrix}
\underline{\mathbf{f}}_1 \\ \underline{\mathbf{f}}_2 \\ \vdots \\ \underline{\mathbf{f}}_n
\end{bmatrix}=
\begin{bmatrix}
\underline{\mathbf{f}}^{(1)} &amp; \underline{\mathbf{f}}^{(2)} &amp; \cdots &amp; \underline{\mathbf{f}}^{(m)}
\end{bmatrix}
\]</span></p>
<p>La estimación de estas cantidades se complica por el hecho de que las cantidades no observadas <span class="math inline">\(\underline{\mathbf{f}}_j\)</span> y los <span class="math inline">\(\underline{\boldsymbol{\varepsilon}}_j\)</span> superan en número a los valores observados <span class="math inline">\(\underline{\mathbf{x}}_j\)</span>, <span class="math inline">\(j=1,2,\cdots,n\)</span>, es decir superan a:
<span class="math display">\[
\mathbf{X}_{n\times p}=\begin{bmatrix}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{bmatrix}=\begin{bmatrix}
\underline{\mathbf{x}}_1 \\ \underline{\mathbf{x}}_2 \\ \vdots \\ \underline{\mathbf{x}}_n
\end{bmatrix}=
\begin{bmatrix}
\underline{\mathbf{x}}^{(1)} &amp; \underline{\mathbf{x}}^{(2)} &amp; \cdots &amp; \underline{\mathbf{x}}^{(p)}
\end{bmatrix}
\]</span></p>
<p>A continuación se presentarán dos aproximaciones para estimar a <span class="math inline">\(\mathbf{F}\)</span>, que tienen los siguientes dos elementos en común:</p>
<ol style="list-style-type: decimal">
<li><p>Tratan <strong>las ponderaciones estimadas</strong> <span class="math inline">\(\hat{l}_{ij}\)</span> y las <strong>varianzas específicas estimadas</strong> <span class="math inline">\(\hat{\psi}_i\)</span>, como si fueran los verdaderos valores de <span class="math inline">\(l_{ij}\)</span> y de <span class="math inline">\(\psi_i\)</span> respectivamente.</p></li>
<li><p>Usan transformaciones lineales de los datos originales, ya
sea el centrado o la estandarización de datos.</p></li>
</ol>
<p>En general, para estimar las puntuaciones de los factores (o Factores-Scores) <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span>, generalmente, se usan <em>las ponderaciones estimadas rotadas en lugar de las ponderaciones estimadas originales</em>. Las fórmulas dadas a continuación no cambian cuando las ponderaciones rotadas son sustituidas por las ponderaciones no rotadas, de donde no hay diferenciación entre ellas.</p>
<div id="método-de-los-mínimos-cuadrados-ponderados" class="section level3 hasAnchor" number="7.9.1">
<h3><span class="header-section-number">7.9.1</span> Método de los Mínimos Cuadrados Ponderados<a href="factores-scores-o-puntuaciones-de-los-factores.html#método-de-los-mínimos-cuadrados-ponderados" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que el vector <span class="math inline">\(\underline{\boldsymbol\mu}\)</span>, las ponderaciones de los factores <span class="math inline">\(\mathbf{L}\)</span> y las varianzas específicas <span class="math inline">\(\mathbf{\Psi}\)</span> son conocidas para el Modelo de Factor Ortogonal:</p>
<p><span class="math display">\[
\underset{p\times 1}{\underline{\mathbf{x}}}-\underset{p\times 1}{\underline{\boldsymbol\mu}}=\underset{p\times m}{\mathbf{L}}\ \underset{m\times p}{\underline{\mathbf{f}}} + \underset{p\times 1}{\underline{\boldsymbol\varepsilon}}
\]</span></p>
<p>El modelo anterior puede ser considerado como un <em>modelo de regresión donde los factores específicos</em>
<span class="math display">\[
\underline{\boldsymbol\varepsilon}=\begin{bmatrix}\varepsilon_1 \\ \varepsilon_2 \\ \vdots \\ \varepsilon_p \end{bmatrix}_{p\times 1}
\]</span></p>
<p><strong>son considerados como los errores del modelo</strong>.</p>
<p>Como,
<span class="math display">\[
Var[\underline{\boldsymbol\varepsilon}]= \mathbf{\Psi}= \begin{bmatrix} \psi_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \psi_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \psi_p\end{bmatrix}_{p\times p} \neq \sigma^2\mathbf{I} \ \ , \ \ \ \text{es decir:}\ \ \ \ \  Var[\varepsilon_i]=\psi_i\neq \sigma^2 \ , \ \  i=1, 2, \ldots, p
\]</span></p>
<p>Bartlett en <span class="citation">(<a href="#ref-bartlett1937">1937</a>)</span>, sugirió usar mínimos cuadrados ponderados <strong>para estimar el vector valores de los factores comunes</strong> (es decir, “el vector de coeficientes del modelo de regresión”):
<span class="math display">\[
\underline{\mathbf{f}}= \begin{bmatrix} F_{1} \\ F_{2} \\ \vdots \\ F_{m} \end{bmatrix}_{m\times 1}
\]</span></p>
<p>La suma cuadrática de errores <em>ponderada por el recíproco de sus varianzas</em> esta dada por:
<span class="math display">\[
Q(\underline{\mathbf{f}})=\sum_{i=1}^p \ \frac{\varepsilon_i^2}{\psi_i}=\underline{\boldsymbol{\varepsilon}}^t\ \mathbf{\Psi}^{-1} \ \underline{\boldsymbol{\varepsilon}}= \biggl(\underline{\mathbf{x}}-\underline{\boldsymbol\mu}- \mathbf{L}\ \underline{\mathbf{f}} \biggr)^T\mathbf{\Psi}^{-1}\ \biggl(\underline{\mathbf{x}}-\underline{\boldsymbol\mu}- \mathbf{L}\ \underline{\mathbf{f}} \biggr)
\]</span></p>
<p>La solución de <strong>Mínimos Cuadrados Ponderados</strong> es aquel vector <span class="math inline">\(\hat{\underline{\mathbf{f}}}\)</span> que minimiza a <span class="math inline">\(Q(\underline{\mathbf{f}})\)</span> y dicha solución está dada por:</p>
<p><span class="math display">\[
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}}= \underset{m\times p}{ \underbrace{ \left( \mathbf{L}^T \mathbf{\Psi}^{-1}\mathbf{L} \right)^{-1}\mathbf{L}^T \mathbf{\Psi}^{-1}}}\ \underset{p\times1}{ \underbrace{(\underline{\mathbf{x}}-\underline{\boldsymbol\mu}) }}
\]</span></p>
<p>Ahora, <strong>usando las estimaciones</strong>:
<span class="math display">\[
\hat{\mathbf{L}} \ , \ \ \hat{\mathbf{\Psi}} \ \ \ \text{y} \ \ \ \hat{\underline{\boldsymbol\mu}}=\underline{\overline{\mathbf{x}}}
\]</span></p>
<p><em>como los verdaderos valores</em> entonces se tiene que, <strong>los Factores-Scores o Puntuaciones</strong> para el <span class="math inline">\(j\)</span>-caso u observación están dadas por:</p>
<p><span class="math display">\[
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}= \underset{m\times p}{ \hat{\underline{\mathbf{f}}}}\ \underset{p\times 1}{ (\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})}= \underset{m\times p}{ \underbrace{ \left( \mathbf{L}^T \mathbf{\Psi}^{-1}\mathbf{L} \right)^{-1}\mathbf{L}^T \mathbf{\Psi}^{-1}}}\ \underset{p\times1}{ \underbrace{(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}}) }}
\]</span></p>
<p>Ahora, cuando <span class="math inline">\(\hat{\mathbf{L}}\)</span> y <span class="math inline">\(\hat{\mathbf{\Psi}}\)</span> son determinados por el Método de Máxima Verosimilitud, estos estimadores deben cumplir la condición de unicidad de que:
<span class="math display">\[
\hat{\mathbf{L}}^T \hat{ \mathbf{\Psi}}^{-1} \hat{ \mathbf{L} } =\hat{\mathbf{\Delta}}
\]</span></p>
<p>sea una matriz diagonal.</p>
<div id="cargas-obtendidas-mediante-el-método-mle" class="section level4 hasAnchor" number="7.9.1.1">
<h4><span class="header-section-number">7.9.1.1</span> Cargas Obtendidas Mediante el Método MLE<a href="factores-scores-o-puntuaciones-de-los-factores.html#cargas-obtendidas-mediante-el-método-mle" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Los Factores-Scores o Puntuaciones de los Factores obtenidas por el <em>Método de Mínimos Cuadrados Ponderados</em> Usando <em>Estimaciones de las Ponderaciones por Máxima Verosimilitud</em> están dados por:
<span class="math display" id="eq:factores-scores-mle">\[
\begin{equation}
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j} = \underset{m\times p}{ \underbrace{ \left( \hat{\mathbf{L}}^T \hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}} \right)^{-1}\hat{\mathbf{L}}^T \hat{\mathbf{\Psi}}^{-1}}}\ \underset{p\times 1}{\underbrace{(\underline{\mathbf{x}}_j-\hat{\underline{\boldsymbol\mu}})}}\\
\ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \  \ \  = \underset{m\times m}{\hat{\mathbf{\Delta}}^{-1}}\ \ \underset{m\times p}{\underbrace{\hat{\mathbf{L}}^T \hat{\mathbf{\Psi}}^{-1}}}\ \ \underset{p\times 1}{(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})} \ \ \ , \ \ \ \ \ j=1,2,\ldots.n \\
\text{o si se usan variables estandarizadas entonces:} \\
\hat{\underline{\mathbf{f}}}_j= \underset{m\times p}{ \underbrace{\left( \hat{\mathbf{L}}_{\underline{\mathbf{z}}}^T \hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}^{-1}\hat{\mathbf{L}}_{\underline{\mathbf{z}}} \right)^{-1}\hat{\mathbf{L}}_{\underline{\mathbf{z}}}^T \hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}^{-1}}}\ \ \underset{p\times 1}{ \underline{\mathbf{z}}_j}\\
\ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \  \ \  = \underset{m\times m}{ \hat{\mathbf{\Delta}}_{\underline{\mathbf{z}}}^{-1}}\ \underset{m\times p}{  \underbrace{\hat{\mathbf{L}}_{\underline{\mathbf{z}}}^T \hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}^{-1}}}\ \underset{p\times 1}{\underline{\mathbf{z}}_j} \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\end{equation}
\tag{7.15}
\]</span></p>
<p>donde
<span class="math display">\[
\underline{\mathbf{z}}_j=\mathbf{D}^{-1/2}( \underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}} ) \ \ \ \  \text{y} \ \ \ \ \ \ \hat{\boldsymbol\rho}=\hat{\mathbf{L}}_{\underline{\mathbf{z}}} \hat{\mathbf{L}}_{\underline{\mathbf{z}}}^T +\hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}
\]</span></p>
<p>Los Factores-Scores o Puntuaciones generadas por <a href="factores-scores-o-puntuaciones-de-los-factores.html#eq:factores-scores-mle">(7.15)</a>, tienen vector de medias muestral cero y covarianzas muestrales cero, ver ejercicio 9.16 de <span class="citation">(<a href="#ref-johnson2007applied">Johnson and Wichern 2007</a>)</span>.</p>
<p>Si se usan las ponderaciones rotadas <span class="math inline">\(\hat{\mathbf{L}}^\star=\hat{\mathbf{L}}\ \mathbf{T}\)</span> en lugar de las ponderaciones originales <span class="math inline">\(\hat{\mathbf{L}}\)</span>, entonces los Factores-Scores que resultan <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j^\star\)</span> se relacionan con los <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> medinate:
<span class="math display">\[
\hat{\underline{\mathbf{f}}}_j^\star = \mathbf{T}^T\ \hat{\underline{\mathbf{f}}}_j \ \ \ ; \ \ \ \ j=1,2,\ldots,n.
\]</span></p>
</div>
<div id="cargas-obtenidas-mediante-el-método-de-la-cp" class="section level4 hasAnchor" number="7.9.1.2">
<h4><span class="header-section-number">7.9.1.2</span> Cargas Obtenidas Mediante el Método de la CP<a href="factores-scores-o-puntuaciones-de-los-factores.html#cargas-obtenidas-mediante-el-método-de-la-cp" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si las ponderaciones de los factores son calculadas por medio del <strong>Método de la CP</strong>, se acostumbra a generar los Factores-Scores o Puntuaciones de los Factores usando el procedimiento de <strong>Mínimos Cuadrados Ordinarios</strong> ( no ponderados). <em>Implícitamente se supone que los <span class="math inline">\(\hat{\psi}_i\)</span> son iguales o aproximadamente iguales</em>.</p>
<p>Los Factores-Scores o Puntuaciones de los Factores obtenidas por Mínimos Cuadrados Ordinarios Usando Estimaciones mediante le Método de la CP están dados por:
<span class="math display" id="eq:factores-scores-cp1">\[
\begin{equation}
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}= \underset{m\times p}{ \underbrace{ \left( \widetilde{ \mathbf{L}}^T  \widetilde{ \mathbf{L} } \right)^{-1} \widetilde{ \mathbf{L}}^T }} \ \underset{p\times 1}{ \underbrace{  (\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})} }\\
\text{o para datos estandarizados se tiene:} \\
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}= \underset{m\times p}{\underbrace{ \left( \widetilde{ \mathbf{L}}_{\underline{\mathbf{z}}}^T \widetilde{ \mathbf{L} }_{\underline{\mathbf{z}}} \right)^{-1} \widetilde{ \mathbf{L}}_{\underline{\mathbf{z}}}^T} } \ \underset{p \times 1}{  \underline{\mathbf{z}}_j}
\tag{7.16}
\end{equation}
\]</span></p>
<p>Como
<span class="math display">\[
\underset{p\times m}{\widetilde{\mathbf{L}}}=\begin{bmatrix}
\uparrow  &amp; &amp;  \uparrow &amp; &amp; \cdots &amp; &amp; \uparrow  \\
\sqrt{\hat{\lambda}_1}\underline{\hat{\mathbf{e}}}_1 &amp; \biggl| &amp; \sqrt{\hat{\lambda}_2}\underline{\hat{\mathbf{e}}}_2 &amp; \biggl| &amp; \cdots &amp; \biggl| &amp; \sqrt{\hat{\lambda}_m}\underline{\hat{\mathbf{e}}}_m \\
\downarrow  &amp; &amp;  \downarrow &amp; &amp; \cdots &amp; &amp; \downarrow  \\
\end{bmatrix}_{p\times m}
\]</span></p>
<p>luego,
<span class="math display" id="eq:factores-scores-cp2">\[
\begin{equation}
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}= \underset{m\times p}{ \underbrace{ \left( \widetilde{ \mathbf{L}}^T \widetilde{ \mathbf{L} } \right)^{-1} \widetilde{ \mathbf{L}}^T}}\ \underset{p\times 1}{  \underbrace{ (\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})}}=\begin{bmatrix}
\frac{1}{\sqrt{\hat{\lambda}_1}}\underline{\hat{\mathbf{e}}}_1^T(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})  \\
\frac{1}{\sqrt{\hat{\lambda}_2}}\underline{\hat{\mathbf{e}}}_2^T(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})  \\
\vdots \\
\frac{1}{\sqrt{\hat{\lambda}_m}}\underline{\hat{\mathbf{e}}}_m^T(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})  \\
\end{bmatrix}_{m\times 1} \ \ \ \ \ ; \ \ \ \ j=1,2,\ldots,n
\end{equation}
\tag{7.17}
\]</span></p>
<p>Los Factores-Scores obtenido en <a href="factores-scores-o-puntuaciones-de-los-factores.html#eq:factores-scores-cp2">(7.17)</a>, tienen vector de medias muestral cero y matriz de varianzas covarianzas muestral la <span class="math inline">\(\mathbf{I}\)</span>, es decir:
<span class="math display">\[
\underset{m\times 1}{\overline{\underline{\mathbf{f}}}}=\frac{1}{n}\sum_{j=1}^n\  \hat{\underline{\mathbf{f}}}_j = \underline{\mathbf{0}}
\]</span></p>
<p>y
<span class="math display">\[
\underset{m\times m}{\mathbf{S}}=\frac{1}{n-1}\sum_{j=1}^n\  \hat{\underline{\mathbf{f}}}_j\ \hat{\underline{\mathbf{f}}}_j^t = \mathbf{I}_m
\]</span></p>
<p><em>Comparando con el Análisis de Componentes Principales</em>, <em>los Factores-Scores o Puntuaciones de los Factores</em> <strong>no son más que las <span class="math inline">\(m\)</span> componentes principales (escaladas) evaluadas en</strong> <span class="math inline">\(\underline{\mathbf{x}}_j\)</span>.</p>
</div>
</div>
<div id="el-método-de-la-regresión" class="section level3 hasAnchor" number="7.9.2">
<h3><span class="header-section-number">7.9.2</span> El Método de la Regresión<a href="factores-scores-o-puntuaciones-de-los-factores.html#el-método-de-la-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Considerando el Modelo de Factor Ortogonal:
<span class="math display">\[
\underset{p\times 1}{\underline{\mathbf{x}}-\underline{\mu}}=\underset{p\times m}{\mathbf{L}}\ \ \underset{m\times 1}{\underline{\mathbf{f}}} + \underset{p\times 1}{\underline{\boldsymbol\varepsilon}}
\]</span></p>
<p>inicialmente tratamos a la matriz de ponderaciones <span class="math inline">\(\mathbf{L}\)</span> y a la matriz de varianza específica <span class="math inline">\(\mathbf{\Psi}\)</span> <em>como si fueran conocidas</em>.</p>
<p>Cuando los factores comunes <span class="math inline">\(\underline{\mathbf{f}}\)</span> y los factores específicos (o errores) <span class="math inline">\(\underline{\boldsymbol\varepsilon}\)</span> tienen una distribución conjunta normal multivariada con vectores de media y matrices de varianzas covarianzas dadas por:
<span class="math display">\[
E[\underline{\mathbf{f}}]=\underline{0}_{\ m\times 1} \ \ \ , \ \ \ \ Var[\underline{\mathbf{f}}]=E[\underline{\mathbf{f}}\underline{\mathbf{f}}^T]=\begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; &amp; 0  &amp; 1
\end{bmatrix}_{m\times m}=\mathbf{I}_m
\]</span></p>
<p><span class="math display">\[
E[\ \underline{\boldsymbol\varepsilon}\ ]=\underline{0}_{\ p\times 1} \ \ \ , \ \ \ Var[\ \underline{\boldsymbol\varepsilon}\ ]=E[\ \underline{\boldsymbol\varepsilon}\underline{\boldsymbol\varepsilon}^T\ ]=\mathbf{\Psi}=\begin{bmatrix}
\psi_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \psi_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; &amp; 0 &amp; \psi_p
\end{bmatrix}_{p\times p}
\]</span></p>
<p>además se cumple que: <span class="math inline">\(\underline{\mathbf{f}}\)</span> y <span class="math inline">\(\underline{\boldsymbol{\varepsilon}}\)</span> son independientes, es decir,
<span class="math display">\[
Cov(\underline{\mathbf{f}}\ \ , \ \ \underline{\boldsymbol{\varepsilon}}) = \underset{m\times p}{\mathbf{O}}
\]</span></p>
<p>lo anterior se escribe como sigue:
<span class="math display">\[
\begin{bmatrix} \underline{\mathbf{f}} \\ \underline{\boldsymbol\varepsilon}  \end{bmatrix}_{(m+p)\times 1} \sim N_{m+p} \left( \begin{bmatrix} \underline{\mathbf{0}} \\ -- \\ \underline{\mathbf{0}} \end{bmatrix} \ , \ \begin{bmatrix} \underline{\mathbf{I}}_{\ m} &amp; | &amp; \mathbf{O} \\ -- &amp; &amp; --  \\ \mathbf{O} &amp; | &amp; \mathbf{\Psi} \end{bmatrix}   \right)
\]</span></p>
<p>de donde:
<span class="math display">\[
\underline{\mathbf{f}}= \begin{bmatrix} F_1 \\ F_2 \\ \vdots \\  F_m \end{bmatrix}_{m\times 1} \sim N_m \biggl(\underline{\mathbf{0}} \ , \ \mathbf{I}_m \biggr) \ \ \ \ \ \ , \ \ \ \ \ \underline{\boldsymbol\varepsilon}= \begin{bmatrix} \varepsilon_1 \\ \varepsilon_2 \\ \vdots \\  \varepsilon_p \end{bmatrix}_{p\times 1} \sim N_p \biggl(\underline{\mathbf{0}} \ , \ \mathbf{\Psi} \biggr)
\]</span></p>
<p>De lo anterior usando la propiedad (<a href="prop-nm.html#prop3">3.5.3</a>) de la NM. se tiene que las combinaciones lineales:
<span class="math display">\[
\underline{\mathbf{x}}-\underline{\mu}=\mathbf{L}\underline{\mathbf{f}}+\underline{\boldsymbol\varepsilon}
\]</span>
tienen una distribución:
<span class="math display">\[
(\underline{\mathbf{x}}-\underline{\mu}) \sim N_p\biggl(\ \underline{0} \ \ ,\ \ \mathbf{\Sigma}=\mathbf{LL}^T+\mathbf{\Psi}\ \biggr)
\]</span></p>
<p>Además la distribución conjunta de <span class="math inline">\((\underline{\mathbf{x}}-\underline{\boldsymbol\mu})\)</span> y <span class="math inline">\(\underline{\mathbf{f}}\)</span> es:</p>
<p><span class="math display">\[
\begin{bmatrix} \underline{\mathbf{x}}-\underline{\boldsymbol\mu} \\  \underline{\mathbf{f}} \end{bmatrix}_{(p+m) \times  1} N_{p+m} \biggl(\ \underline{\mathbf{0}}\ \ , \   \  \mathbf{\Sigma}^{\star} \ \biggr)
\]</span></p>
<p>donde:
<span class="math display">\[
\underset{(p+m)\times (p+m)}{\mathbf{\Sigma}^{\star}}=\begin{bmatrix}
\underset{p\times p}{\mathbf{\Sigma}}=\mathbf{LL}^T+\mathbf{\Psi}  &amp;| &amp;  \underset{p\times m}{\mathbf{L}} \\
------- &amp; &amp; ------ \\
\underset{m\times p}{\mathbf{L}^T}   &amp; | &amp;  \mathbf{I}_m
\end{bmatrix}=\begin{bmatrix}
Var\bigl[\underline{\mathbf{x}}\bigr]  &amp;| &amp;  Cov\bigl[\underline{\mathbf{x}}\ , \ \underline{\mathbf{f}}\bigr] \\
------- &amp; &amp; ------ \\
Cov\bigl[\underline{\mathbf{f}} , \ \underline{\mathbf{x}}\bigr]   &amp; | &amp;   Var\bigl[\underline{\mathbf{f}}\bigr]  
\end{bmatrix}
\]</span></p>
<p>y <span class="math inline">\(\underline{\mathbf{0}}\)</span> es un vector de <span class="math inline">\((m+p) \times 1\)</span> ceros.</p>
<p>Usando estos resultados y la propiedad (<a href="prop-nm.html#prop6">3.5.6</a>) de la NM, la distribución condicional de <span class="math inline">\(\underline{\mathbf{f}}\ \biggl| \underline{\mathbf{x}}=\underline{x}\)</span> es normal multivariada,
<span class="math display">\[
\underline{\mathbf{f}}\ \biggl| \underline{\mathbf{x}}=\underline{x} \sim N_m \biggl( \underline{\boldsymbol{\mu}}_{\underline{\mathbf{f}}.\underline{\mathbf{x}}} \ , \ \mathbf{\Sigma}_{\underline{\mathbf{f}}.\underline{\mathbf{x}}} \biggr)
\]</span></p>
<p>con:
<span class="math display" id="eq:esperanza-de-f">\[
\underline{\boldsymbol{\mu}}_{\underline{\mathbf{f}}.\underline{\mathbf{x}}}=\begin{equation}
\underset{m\times 1}{ \underbrace{ E\bigl[\underline{\mathbf{f}}\ \biggl|\  \underline{x}\bigr] } } =\mathbf{L}^T \mathbf{\Sigma}^{-1}(\underline{x} - \underline{\mu})=\mathbf{L}^T (\mathbf{LL}^T+\mathbf{\Psi} )^{-1}(\underline{x} - \underline{\mu})
\tag{7.18}
\end{equation}
\]</span></p>
<p>y matriz de varianzas-covarianzas dada por:
<span class="math display" id="eq:var-de-f">\[
\begin{equation}
\mathbf{\Sigma}_{\underline{\mathbf{f}}.\underline{\mathbf{x}}}=\underset{m\times m}{ \underbrace{ Var\bigl[\underline{\mathbf{f}}\ \biggl|\  \underline{x}]}} =\mathbf{I}_m - \mathbf{L}^T \mathbf{\Sigma}^{-1}\mathbf{L}=\mathbf{I}_m- \mathbf{L}^T (\mathbf{LL}^T+\mathbf{\Psi} )^{-1}\mathbf{L}
\tag{7.19}
\end{equation}
\]</span></p>
<p>Las cantidades:
<span class="math display">\[
\underset{m\times p}{ \underbrace{\mathbf{L}^T (\mathbf{LL}^T+\mathbf{\Psi} )^{-1}} }
\]</span></p>
<p>son <em>los coeficientes de un</em> <strong>Modelo de Regresión Lineal Multivariado</strong> <em>de los factores</em> <span class="math inline">\(\mathbf{f}_j\)</span> <em>sobre las variables</em> <span class="math inline">\(X_k\)</span>, <span class="math inline">\(j=1,2,\ldots,m\)</span>, <span class="math inline">\(k=1,2,\ldots,p\)</span>.</p>
<p><em>La estimación de estos coeficientes producen</em> <strong>Los Factores-Scores</strong> (o Puntuaciones de los Factores) <em>que son análogos a las estimaciones de los valores de las Medias Condicionales en el análisis de Regresión Lineal Multivariado</em>.</p>
<p>Por tanto, dado cualquier vector de observaciones <span class="math inline">\(\underline{\mathbf{x}}_j\)</span>, tomando las estimaciones de Máxima Verosimilitud <span class="math inline">\(\hat{\mathbf{L}}\)</span> y <span class="math inline">\(\hat{\mathbf{\Psi}}\)</span> como los verdaderos valores de <span class="math inline">\(\mathbf{L}\)</span> y <span class="math inline">\(\mathbf{\Psi}\)</span> respectivamente entonces, el <span class="math inline">\(j\)</span>-ésimo vector de Factores-Scores estimado está dado por:</p>
<p><span class="math display" id="eq:factores-scores-f">\[
\begin{equation}
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}=\underset{m\times p}{\underbrace{\hat{\mathbf{L}}^T \hat{\mathbf{\Sigma}}^{-1}}}\ \underset{p\times 1}{\underbrace{(\underline{x}_j-\underline{\overline{\mathbf{x}}})}}=\underbrace{\hat{\mathbf{L}}^T (\hat{\mathbf{L}}\hat{\mathbf{L}}^T+\hat{\mathbf{\Psi}})^{-1}}\ \underbrace{(\underline{x}_j-\underline{\overline{\mathbf{x}}})} \ , \ \ \ \text{para}, j=1,2,\ldots , n
\tag{7.20}
\end{equation}
\]</span></p>
<p><strong>Observaciones</strong>:</p>
<ol style="list-style-type: decimal">
<li>El cálculo de <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> se puede simplificar usando la siguiente identidad matricial:</li>
</ol>
<p><span class="math display">\[
\underset{m\times p}{ \underset{}{ \hat{\mathbf{L}}^T }} \underset{p\times p}{\underbrace{ (\hat{ \mathbf{L}}\hat{\mathbf{L}}^T+\hat{\mathbf{\Psi}} )^{-1}}}=\biggl(\mathbf{I}_m + \underset{m\times m}{\underbrace{ \hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}}}\biggr)}^{-1}\underset{m\times p}{\hat{\mathbf{L}}^T} \underset{p\times p}{\hat{\mathbf{\Psi}}^{-1}}
\]</span></p>
<p>ver ejercicio 9.6 del libro <span class="citation">(<a href="#ref-johnson2007applied">Johnson and Wichern 2007</a>)</span>.</p>
<p>Esta identidad permite comparar los <strong>Factores-Scores de Regresión</strong> con los Factores-Scores generados por <strong>Mínimos Cuadrados Ponderados</strong>.</p>
<p>Sean <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j^R\)</span> los scores generados por el Método de la Regresión y <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j^{LS}\)</span>
los generados por el Método de Mínimos Cuadrados Ponderados entonces, usando la identidad anterior se tiene que:
<span class="math display" id="eq:relacion-factores-scores">\[
\begin{equation}
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j^{LS}}= \biggl(\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}} \biggr)^{-1} \biggl(\mathbf{I}_m+\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}}\biggr) \hat{\underline{\mathbf{f}}}_j^{R}=\biggl(\mathbf{I}_m + \bigl(\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}}\bigr)^{-1}\biggr)\hat{\underline{\mathbf{f}}}_j^R
\tag{7.21}
\end{equation}
\]</span></p>
<p>Para los Estimadores de Máximo Verosímiles se tiene que:
<span class="math display">\[
\underset{m\times m}{\underbrace{(\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}})^{-1}}}=\hat{\mathbf{\Delta}}^{-1} \ \ \ ; \ \ \ \ \ \text{es diagonal}
\]</span></p>
<p>por lo tanto, si los elementos de esta matriz diagonal anterior son cercanos a cero, <strong>el Método de la Regresión y el de Mínimos Cuadrados Ponderado (o generalizado) producirán los mismos Factores-Scores</strong>.</p>
<ol start="2" style="list-style-type: decimal">
<li>En un intento por tratar de reducir los efectos de una (posible) determinación incorrecta del número de factores, algunos calculan los Factores-Scores reemplazando la matriz
<span class="math display">\[
\hat{\mathbf{\Sigma}}=\hat{\mathbf{L}}\hat{\mathbf{L}}^T+\hat{\mathbf{\Psi}}
\]</span></li>
</ol>
<p>por la matriz <span class="math inline">\(\mathbf{S}\)</span> (es decir por la matriz de varianzas covarianzas muestral original), obteniendo lo siguiente:</p>
<p><strong>Factores-Scores obtenidos por el Método de la Regresión</strong></p>
<p>De lo anterior:
<span class="math display" id="eq:factores-scores-reg">\[
\begin{equation}
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}= \underset{m\times p}{\underbrace{ \mathbf{L}^T \mathbf{S}^{-1}}}\  \underset{p\times 1}{\underbrace{(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})}} \ \ \ , \ \ \ \ \ j=1,2,\ldots.n \\
\text{o si se usan variables estandarizadas entonces:} \\
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}=\underset{m\times p}{ \underbrace{\mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{R}^{-1}}}\ \underset{p\times 1}{\underline{\mathbf{z}}_j }\ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\tag{7.22}
\end{equation}
\]</span></p>
<p>donde
<span class="math display">\[
\underline{\mathbf{z}}_j=\mathbf{D}^{-1/2}( \underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}} ) \ \ \ \  \text{y} \ \ \ \ \ \ \hat{\boldsymbol\rho}=\hat{\mathbf{L}}_{\underline{\mathbf{z}}} \hat{\mathbf{L}}_{\underline{\mathbf{z}}}^T +\hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p>Si se usan los factores rotados:
<span class="math display">\[
\underset{p\times 2}{\hat{\mathbf{L}}^{\star}}=\underset{p\times 2}{\hat{\mathbf{L}}}\ \underset{2\times 2}{ \mathbf{T}}
\]</span>
en lugar de las ponderaciones originales, los Factores-Scores de <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j^{\star}\)</span> (rotados) están relacionados con los factores <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> (no-rotados) por medio de:
<span class="math display">\[
\underset{2\times 1}{\hat{\underline{\mathbf{f}}}_j^{\star}}=\underset{2\times 2}{\mathbf{T}^T}\ \underset{2\times 1}{ \hat{\underline{\mathbf{f}}}_j}
\]</span></p></li>
<li><p>Una medida numérica de concordancia entre los Factores-Scores generados por estos dos métodos de cálculos diferentes, esta dada por el <strong>Coeficiente de Correlación Muestral entre los Scores de un Mismo Factor</strong>, por ejemplo, el coeficiente de correlación muestral entre <span class="math inline">\(\mathbf{f}_1^R\)</span> y <span class="math inline">\(\mathbf{f}_1^{LS}\)</span>, es decir, entre <span class="math inline">\(\mathbf{f}_1\)</span>-obtenido por el método de la Regresión y <span class="math inline">\(\mathbf{f}_1\)</span>-obtenido por el Método de Mínimos Cuadrados Ponderados.</p></li>
</ol>
<p>De los métodos presentados, <strong>ninguno se recomienda como uniformemente superior</strong>.</p>
<div class="example">
<p><span id="exm:ejemplo1-afc-regresion-cp" class="example"><strong>Ejemplo 7.11  (Estimación de Factores-Scores (Método de la Regresión y MC-Ponderados)) </strong></span>Para el ejemplo considerado anteriormente sobre datos rendimientos de las acciones de 5 compañías, ver ejemplo (<a href="rotación-de-factores.html#exm:ejemplo3-afc-rotacion">7.10</a>), se calculan ahora los Factores-Scores mediante los dos métodos vistos, es decir, por el <strong>Método de Mínimos Cuadrados Ponderados</strong> y el <strong>Métdodo de la Regresión</strong>.</p>
</div>
<p>Anteriormente, el método de Máxima-Verosimilitud a partir de la matriz de correlación <span class="math inline">\(\mathbf{R}\)</span> produjo las siguientes ponderaciones-rotadas y varianzas específicas estimadas:</p>
<p><span class="math display">\[
\hat{\mathbf{L}}_{\underline{\mathbf{z}}}^{\star}=\begin{bmatrix}
0.763 &amp; 0.024 \\ 0.821 &amp; 0.227 \\ 0.669 &amp; 0.104 \\ 0.118 &amp; 0.993 \\
0.113 &amp; 0.675
\end{bmatrix}_{p\times m} \ \ \ \ \text{y} \ \ \ \ \hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}=\begin{bmatrix}
0.42 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0.27 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0.45 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0.00 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.53
\end{bmatrix}_{p\times p}
\]</span></p>
<p>Para el vector de Observaciones Estandarizadas dado por:
<span class="math display">\[
\underline{\mathbf{z}}= \begin{bmatrix} 0.50 \\ -1.40 \\ -0.20 \\ -0.70 \\ 1.40 \end{bmatrix}_{p\times 1}
\]</span></p>
<p>se calculan los Factores-Scores (o Puntuaciones) para los Factores 1 y 2.</p>
<p><strong>Para el Método de Mínimos Cuadrados Ponderados:</strong></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\mathbf{L}_{\underline{\mathbf{z}}} \right)^{-1}\mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\ \underline{\mathbf{z}}_j =\hat{\mathbf{\Delta}}_{\underline{\mathbf{z}}}^{-1}\mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\ \underline{\mathbf{z}}_j
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j=\begin{bmatrix} 0.401 &amp; 0.652 &amp; 0.27 &amp; -0.196 &amp; 0.014 \\ -0.048 &amp; -0.077  &amp; -0.032 &amp; 1.03 &amp; -0.002  \end{bmatrix} \begin{bmatrix} 0.5 \\ -1.4 \\ -0.2 \\ -0.7 \\ 1.4 \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \begin{bmatrix} -0.61 \\ -0.63 \end{bmatrix}
\]</span></p>
<p><strong>Para el Método de Regresión</strong>:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{R}^{-1}\ \underline{\mathbf{z}}_j
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j=\begin{bmatrix} 0.331 &amp; 0.527 &amp; 0.221 &amp; -0.138 &amp; 0.011 \\ -0.042 &amp; -0.06  &amp; -0.027 &amp; 1.022 &amp; 0  \end{bmatrix} \begin{bmatrix} 0.5 \\ -1.4 \\ -0.2 \\ -0.7 \\ 1.4 \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \begin{bmatrix} -0.5 \\ -0.65 \end{bmatrix}
\]</span></p>
<p><strong>Comentario</strong>. Las puntuaciones de los factores o Factores-Scores con una propiedad intuitiva agradable pueden compararse de manera muy simple. Se pueden agrupa las variables con cargas altas (digamos, mayor que 0.40 en valor absoluto) sobre un factor.</p>
<p><strong>Factores-Scores para los Factores 1 y 2, usando los estimadores MLE</strong>:</p>
<p><strong>Usando variables centradas se tiene que</strong>:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \mathbf{L}^T \mathbf{S}^{-1}(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}}) \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-277">Tabla 7.25: </span>Factores-Scores Datos Centrados
</caption>
<tbody>
<tr>
<td style="text-align:right;">
3.416
</td>
<td style="text-align:right;">
-71.8058
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.397
</td>
<td style="text-align:right;">
8.3014
</td>
</tr>
<tr>
<td style="text-align:right;">
0.824
</td>
<td style="text-align:right;">
-0.1902
</td>
</tr>
<tr>
<td style="text-align:right;">
49.437
</td>
<td style="text-align:right;">
-47.3390
</td>
</tr>
<tr>
<td style="text-align:right;">
-24.232
</td>
<td style="text-align:right;">
30.0134
</td>
</tr>
<tr>
<td style="text-align:right;">
-28.850
</td>
<td style="text-align:right;">
9.8505
</td>
</tr>
<tr>
<td style="text-align:right;">
33.456
</td>
<td style="text-align:right;">
36.5185
</td>
</tr>
<tr>
<td style="text-align:right;">
53.945
</td>
<td style="text-align:right;">
-4.6516
</td>
</tr>
<tr>
<td style="text-align:right;">
-40.726
</td>
<td style="text-align:right;">
-41.1491
</td>
</tr>
<tr>
<td style="text-align:right;">
5.044
</td>
<td style="text-align:right;">
-33.0719
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grafico-factores-ls"></span>
<img src="bookdown-iam_files/figure-html/grafico-factores-ls-1.png" alt="Gráfico de  Factores-Scores 1 y 2 Datos Centrados" width="600px" />
<p class="caption">
Figura 7.6: Gráfico de Factores-Scores 1 y 2 Datos Centrados
</p>
</div>
<p><strong>Factores-Scores para los Factores 1 y 2, usando los estimadores MLE</strong>:</p>
<p><strong>Usando variables estandarizadas se tiene que</strong>:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{R}^{-1}\ \underline{\mathbf{z}}_j \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-280">Tabla 7.26: </span>Factores-Scores Datos Estandarizados
</caption>
<thead>
<tr>
<th style="text-align:right;">
ML2
</th>
<th style="text-align:right;">
ML1
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
0.1654
</td>
<td style="text-align:right;">
-1.8343
</td>
</tr>
<tr>
<td style="text-align:right;">
0.3675
</td>
<td style="text-align:right;">
0.2555
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.3952
</td>
<td style="text-align:right;">
-0.1079
</td>
</tr>
<tr>
<td style="text-align:right;">
0.6252
</td>
<td style="text-align:right;">
-1.2879
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.0600
</td>
<td style="text-align:right;">
0.9495
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.3761
</td>
<td style="text-align:right;">
0.3996
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8026
</td>
<td style="text-align:right;">
0.8956
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8465
</td>
<td style="text-align:right;">
-0.0131
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.9000
</td>
<td style="text-align:right;">
-1.1628
</td>
</tr>
<tr>
<td style="text-align:right;">
0.4288
</td>
<td style="text-align:right;">
-0.9587
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grafico-factores-ls-estand1"></span>
<img src="bookdown-iam_files/figure-html/grafico-factores-ls-estand1-1.png" alt="Gráfico de  Factores-Scores 1 y 2 Datos Estandarizados" width="600px" />
<p class="caption">
Figura 7.7: Gráfico de Factores-Scores 1 y 2 Datos Estandarizados
</p>
</div>
<div class="example">
<p><span id="exm:ejemplo2-afc-regresion" class="example"><strong>Ejemplo 7.12  (Estimación de Factores Scores (Método de la Regresión)) </strong></span>Para el ejemplo considerado anteriormente sobre datos rendimientos de las acciones de 5 compañías, se calcularán ahora los Factores-Scores mediante el <em>Métdodo de la Regresión</em>.</p>
</div>
<p>Anteriormente, <em>El Análisis Factorial mediante el Método de la CP</em>, ver el ejemplo <a href="métodos-de-estimación.html#exm:ejemplo2-afc-metodo-cp">7.4</a>, produjo las siguientes ponderaciones estimadas:
<span class="math display">\[
\widetilde{\mathbf{L}}=\begin{bmatrix}
0.732 &amp; -0.437 \\ 0.831 &amp; -0.280 \\ 0.726 &amp; -0.374 \\ 0.605 &amp; 0.694 \\
0.563 &amp; 0.719
\end{bmatrix}_{p\times m} \ \ \ \ \text{y} \ \ \ \ \widetilde{\mathbf{L}}^{\star}=\widetilde{\mathbf{L}}\mathbf{T}=\begin{bmatrix}
0.852 &amp; 0.030 \\ 0.851 &amp; 0.214 \\ 0.813 &amp; 0.079 \\ 0.133 &amp; 0.911 \\
0.084 &amp; 0.909
\end{bmatrix}_{p\times m}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Para cada factor, tomando <strong>las ponderaciones mayores (en valor absoluto) como iguales</strong> en <span class="math inline">\(\tilde{\mathbf{L}}\)</span> y eliminando las ponderaciones más pequeñas, se crean las siguientes combinaciones lineales como resúmenes de los Factores-Scores:
<span class="math display">\[
\hat{f}_1=x_1+x_2+x_3+x_4+x_5 \ \ \ \text{y} \ \ \ \
\hat{f}_2=x_4+x_5-x_1
\]</span></li>
</ol>
<p>En la práctica estas nuevas variables deberían estandarizarse.</p>
<ol start="2" style="list-style-type: decimal">
<li>Si en lugar de usar <span class="math inline">\(\tilde{\mathbf{L}}\)</span> se usan las ponderaciones rotadas con el criterio varimax, ie. <span class="math inline">\(\tilde{\mathbf{L}}^{\star}\)</span>, los Factores-Scores podrían ser:
<span class="math display">\[
\hat{f}_1=x_1+x_2+x_3
\]</span></li>
</ol>
<p><span class="math display">\[
\hat{f}_2=x_4+x_5
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>La identificación de cargas grandes y pequeñas es en realidad bastante subjetiva. <em>Se prefieren las combinaciones lineales que tengan sentido en el área de investigación</em>.</li>
</ol>
<p><strong>Observaciones</strong>:</p>
<ol style="list-style-type: decimal">
<li><p>Aunque con frecuenta se supone normalidad multivariada para las variables en un Análisis de Factor, en realidad es muy difícil justificar este supuesto cuando el número de variables es muy grande. Algunas veces, las transformaciones sobre las variables vistas anteriormente pueden ayudar a aproximar a la normalidad.</p></li>
<li><p>Se deben examinar los gráficos de los Factores-Scores antes de usarlos en otros análisis. Los Factores-Scores pueden producir toda clase de formas no elípticas, que pueden revelar valores atípicos y la desviación de la no normalidad.</p></li>
</ol>
</div>
</div>
<h3>Bibliografía<a href="bibliografía.html#bibliografía" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bartlett1937" class="csl-entry">
Bartlett, Maurice S. 1937. <span>“The Statistical Conception of Mental Factors.”</span> <em>British Journal of Psychology</em> 28 (1): 97.
</div>
<div id="ref-johnson2007applied" class="csl-entry">
Johnson, Richard A, and Dean W Wichern. 2007. <em>Applied Multivariate Statistical Analysis. 6th</em>. <em>New Jersey, US: Pearson Prentice Hall</em>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rotación-de-factores.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="perspectivas-y-estrategías-para-el-análisis-de-factor.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-iam.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsubsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
