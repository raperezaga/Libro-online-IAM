<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.9 Scores (o Puntuaciones) de los Factores | Chapter 6</title>
  <meta name="description" content="Este libro contine ……" />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="6.9 Scores (o Puntuaciones) de los Factores | Chapter 6" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/imagenes/imagen1.png" />
  <meta property="og:description" content="Este libro contine ……" />
  <meta name="github-repo" content="raperezaga/iam" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.9 Scores (o Puntuaciones) de los Factores | Chapter 6" />
  
  <meta name="twitter:description" content="Este libro contine ……" />
  <meta name="twitter:image" content="/imagenes/imagen1.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rotación-de-factores.html"/>
<link rel="next" href="bibliografía.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preámbulo</a>
<ul>
<li class="chapter" data-level="" data-path="dedicación.html"><a href="dedicación.html"><i class="fa fa-check"></i>Dedicación</a></li>
<li class="chapter" data-level="" data-path="agradecimientos.html"><a href="agradecimientos.html"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="paquetes-usados-en-el-libro.html"><a href="paquetes-usados-en-el-libro.html"><i class="fa fa-check"></i>Paquetes usados en el libro</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="rep-al.html"><a href="rep-al.html"><i class="fa fa-check"></i><b>1</b> Repaso de álgebra lineal</a>
<ul>
<li class="chapter" data-level="1.1" data-path="acb-al.html"><a href="acb-al.html"><i class="fa fa-check"></i><b>1.1</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="acb-al.html"><a href="acb-al.html#matrices"><i class="fa fa-check"></i><b>1.1.1</b> Matrices</a></li>
<li class="chapter" data-level="1.1.2" data-path="acb-al.html"><a href="acb-al.html#vectores"><i class="fa fa-check"></i><b>1.1.2</b> Vectores</a></li>
<li class="chapter" data-level="1.1.3" data-path="acb-al.html"><a href="acb-al.html#operaciones-matrices"><i class="fa fa-check"></i><b>1.1.3</b> Operaciones Matriciales</a></li>
<li class="chapter" data-level="1.1.4" data-path="acb-al.html"><a href="acb-al.html#matrices-especiales"><i class="fa fa-check"></i><b>1.1.4</b> Matrices Especiales</a></li>
<li class="chapter" data-level="1.1.5" data-path="acb-al.html"><a href="acb-al.html#descomp-espectral"><i class="fa fa-check"></i><b>1.1.5</b> Descomposición Espectral de una Matriz (eigen-descomposición)</a></li>
<li class="chapter" data-level="1.1.6" data-path="acb-al.html"><a href="acb-al.html#eigen-descom-msdp"><i class="fa fa-check"></i><b>1.1.6</b> Descomposición Espectral de Matrices Simétricas Definidas (o Semidefinidas) Positivas</a></li>
<li class="chapter" data-level="1.1.7" data-path="acb-al.html"><a href="acb-al.html#traza-determinante-y-rango-de-una-matriz"><i class="fa fa-check"></i><b>1.1.7</b> Traza, Determinante y Rango de una Matriz</a></li>
<li class="chapter" data-level="1.1.8" data-path="acb-al.html"><a href="acb-al.html#formas-cuadraticas"><i class="fa fa-check"></i><b>1.1.8</b> Formas Cuadráticas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="algunas-propiedades-estadísticas-de-la-eigen-descomposición-de-una-matriz.html"><a href="algunas-propiedades-estadísticas-de-la-eigen-descomposición-de-una-matriz.html"><i class="fa fa-check"></i><b>1.2</b> Algunas Propiedades Estadísticas de la Eigen-Descomposición de una Matriz</a></li>
<li class="chapter" data-level="1.3" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html"><i class="fa fa-check"></i><b>1.3</b> Diferenciación con Vectores y Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html#vector-gradiente-para-diferentes-definiciones-de-funderlinex"><i class="fa fa-check"></i><b>1.3.1</b> Vector-Gradiente para diferentes definiciones de <span class="math inline">\(f(\underline{x})\)</span>:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="org_pres_dat.html"><a href="org_pres_dat.html"><i class="fa fa-check"></i><b>2</b> Organización y Presentación de Datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html"><i class="fa fa-check"></i><b>2.1</b> Resumenes Descriptivos</a></li>
<li class="chapter" data-level="2.2" data-path="representación-gráfica-de-observaciones-multivariadas.html"><a href="representación-gráfica-de-observaciones-multivariadas.html"><i class="fa fa-check"></i><b>2.2</b> Representación Gráfica de Observaciones multivariadas</a></li>
<li class="chapter" data-level="2.3" data-path="vectores-y-matrices-aleatorias.html"><a href="vectores-y-matrices-aleatorias.html"><i class="fa fa-check"></i><b>2.3</b> Vectores y Matrices Aleatorias</a></li>
<li class="chapter" data-level="2.4" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html"><i class="fa fa-check"></i><b>2.4</b> Vectores y Matrices Poblacionales Particionados</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-del-vector-de-medias-poblacionales"><i class="fa fa-check"></i><b>2.4.1</b> Particionamiento del Vector de Medias-Poblacionales</a></li>
<li class="chapter" data-level="2.4.2" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-de-la-matriz-de-var-cov-poblacional-mathbfsigma"><i class="fa fa-check"></i><b>2.4.2</b> Particionamiento de la Matriz de Var-Cov Poblacional <span class="math inline">\(\mathbf{\Sigma}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.5</b> Propiedades Sobre la Media y Varianza de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.6" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html"><i class="fa fa-check"></i><b>2.6</b> Vectores y Matrices Muestrales Particionadas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-del-vector-de-medias-muestrales"><i class="fa fa-check"></i><b>2.6.1</b> Particionamiento del Vector de Medias Muestrales</a></li>
<li class="chapter" data-level="2.6.2" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-de-la-matriz-de-var-cov-muestrales"><i class="fa fa-check"></i><b>2.6.2</b> Particionamiento de la Matriz de Var-Cov Muestrales</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="algunas-formas-matriciales-eficientes.html"><a href="algunas-formas-matriciales-eficientes.html"><i class="fa fa-check"></i><b>2.7</b> Algunas formas matriciales Eficientes</a></li>
<li class="chapter" data-level="2.8" data-path="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.8</b> Propiedades Sobre la Media y Varianza Muestral de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.9" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><i class="fa fa-check"></i><b>2.9</b> Varianza Generalizada Muestral y su Interpretación Geométrica</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-1-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.9.1</b> Interpretación Geométrica-1 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.9.2" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-2-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.9.2</b> Interpretación Geométrica-2 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.9.3" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#varianza-generalizada-determinada-por-la-matriz-de-correlación-muestral-mathbfr"><i class="fa fa-check"></i><b>2.9.3</b> Varianza Generalizada Determinada por la Matriz de Correlación Muestral <span class="math inline">\(\mathbf{R}\)</span></a></li>
<li class="chapter" data-level="2.9.4" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#relación-entre-mathbfs-y-mathbfr"><i class="fa fa-check"></i><b>2.9.4</b> Relación entre <span class="math inline">\(|\mathbf{S}|\)</span> y <span class="math inline">\(|\mathbf{R}|\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="varianza-total-muestral.html"><a href="varianza-total-muestral.html"><i class="fa fa-check"></i><b>2.10</b> Varianza Total Muestral</a></li>
<li class="chapter" data-level="2.11" data-path="muestra-aleatoria-de-distribuciones-p-variadas.html"><a href="muestra-aleatoria-de-distribuciones-p-variadas.html"><i class="fa fa-check"></i><b>2.11</b> Muestra Aleatoria de Distribuciones <span class="math inline">\(p\)</span>-Variadas</a></li>
<li class="chapter" data-level="2.12" data-path="distancias.html"><a href="distancias.html"><i class="fa fa-check"></i><b>2.12</b> Distancias</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="distancias.html"><a href="distancias.html#definición-de-algunas-distancias"><i class="fa fa-check"></i><b>2.12.1</b> Definición de Algunas Distancias</a></li>
<li class="chapter" data-level="2.12.2" data-path="distancias.html"><a href="distancias.html#relación-de-la-distancia-de-mahalanobis-con-la-distribución-chi-cuadrado"><i class="fa fa-check"></i><b>2.12.2</b> Relación de la Distancia de Mahalanobis con la Distribución chi-Cuadrado</a></li>
<li class="chapter" data-level="2.12.3" data-path="distancias.html"><a href="distancias.html#ejemplo"><i class="fa fa-check"></i><b>2.12.3</b> Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Normal-Multiv.html"><a href="Normal-Multiv.html"><i class="fa fa-check"></i><b>3</b> Distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.1" data-path="geometria-NM.html"><a href="geometria-NM.html"><i class="fa fa-check"></i><b>3.1</b> Geometría y propiedades de la NM</a></li>
<li class="chapter" data-level="3.2" data-path="normal-univariada.html"><a href="normal-univariada.html"><i class="fa fa-check"></i><b>3.2</b> Normal Univariada</a></li>
<li class="chapter" data-level="3.3" data-path="normal-multivariada.html"><a href="normal-multivariada.html"><i class="fa fa-check"></i><b>3.3</b> Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="normal-multivariada.html"><a href="normal-multivariada.html#algunos-aspectos-geométricos-de-la-nm"><i class="fa fa-check"></i><b>3.3.1</b> Algunos Aspectos Geométricos de la NM</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="prop-nm.html"><a href="prop-nm.html"><i class="fa fa-check"></i><b>3.4</b> Propiedades de la distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="prop-nm.html"><a href="prop-nm.html#prop1"><i class="fa fa-check"></i><b>3.4.1</b> <strong>Propiedad-1:</strong></a></li>
<li class="chapter" data-level="3.4.2" data-path="prop-nm.html"><a href="prop-nm.html#prop2"><i class="fa fa-check"></i><b>3.4.2</b> <strong>Propiedad-2:</strong></a></li>
<li class="chapter" data-level="3.4.3" data-path="prop-nm.html"><a href="prop-nm.html#prop3"><i class="fa fa-check"></i><b>3.4.3</b> <strong>Propiedad-3:</strong></a></li>
<li class="chapter" data-level="3.4.4" data-path="prop-nm.html"><a href="prop-nm.html#prop4"><i class="fa fa-check"></i><b>3.4.4</b> <strong>Propiedad-4:</strong></a></li>
<li class="chapter" data-level="3.4.5" data-path="prop-nm.html"><a href="prop-nm.html#prop5"><i class="fa fa-check"></i><b>3.4.5</b> <strong>Propiedad-5:</strong></a></li>
<li class="chapter" data-level="3.4.6" data-path="prop-nm.html"><a href="prop-nm.html#prop6"><i class="fa fa-check"></i><b>3.4.6</b> <strong>Propiedad-6:</strong></a></li>
<li class="chapter" data-level="3.4.7" data-path="prop-nm.html"><a href="prop-nm.html#prop7"><i class="fa fa-check"></i><b>3.4.7</b> <strong>Propiedad-7:</strong></a></li>
<li class="chapter" data-level="3.4.8" data-path="prop-nm.html"><a href="prop-nm.html#prop8"><i class="fa fa-check"></i><b>3.4.8</b> <strong>Propiedad-8:</strong></a></li>
<li class="chapter" data-level="3.4.9" data-path="prop-nm.html"><a href="prop-nm.html#prop9"><i class="fa fa-check"></i><b>3.4.9</b> <strong>Propiedad-9:</strong></a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.5</b> Evaluación del Supuesto de Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-a-nivel-marginal-ie.-normalidad-univariada"><i class="fa fa-check"></i><b>3.5.1</b> Evaluación a nivel marginal (ie. Normalidad Univariada)</a></li>
<li class="chapter" data-level="3.5.2" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-de-la-normalidad-bi-variada"><i class="fa fa-check"></i><b>3.5.2</b> Evaluación de la Normalidad Bi-variada</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="detección-de-observaciones-atípicas.html"><a href="detección-de-observaciones-atípicas.html"><i class="fa fa-check"></i><b>3.6</b> Detección de Observaciones Atípicas</a></li>
<li class="chapter" data-level="3.7" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.7</b> Transformaciones para Acercar a la Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#familia-de-transformaciones-de-potencia-de-box-y-cox-1964"><i class="fa fa-check"></i><b>3.7.1</b> Familia de Transformaciones de Potencia de Box y Cox (1964)</a></li>
<li class="chapter" data-level="3.7.2" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#transformaciones-para-el-caso-multivariado"><i class="fa fa-check"></i><b>3.7.2</b> Transformaciones para el Caso Multivariado:</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html"><i class="fa fa-check"></i><b>3.8</b> Muestra Aleatoria Normal <span class="math inline">\(p\)</span>-Variada</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#estimadores-de-máx-ver-de-una-normal-multivariada"><i class="fa fa-check"></i><b>3.8.1</b> Estimadores de Máx-Ver de una Normal-Multivariada</a></li>
<li class="chapter" data-level="3.8.2" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#distribución-muestral-de-overlineunderlinemathbfx-y-mathbfs_n"><i class="fa fa-check"></i><b>3.8.2</b> Distribución Muestral de <span class="math inline">\(\overline{\underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\mathbf{S}_n\)</span></a></li>
<li class="chapter" data-level="3.8.3" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#comportamiento-de-underlineoverlinemathbfx_p-y-mathbfs-para-tamaños-muestrales-grandes"><i class="fa fa-check"></i><b>3.8.3</b> Comportamiento de <span class="math inline">\(\underline{\overline{\mathbf{x}}}_p\)</span> y <span class="math inline">\(\mathbf{S}\)</span> para Tamaños Muestrales Grandes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferen-estad.html"><a href="inferen-estad.html"><i class="fa fa-check"></i><b>4</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="inferencia-estadística-para-la-media-mu-caso-univariado.html"><a href="inferencia-estadística-para-la-media-mu-caso-univariado.html"><i class="fa fa-check"></i><b>4.2</b> Inferencia Estadística para la Media (<span class="math inline">\(\mu\)</span>)-caso univariado</a></li>
<li class="chapter" data-level="4.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><i class="fa fa-check"></i><b>4.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-desconocida-normal"><i class="fa fa-check"></i><b>4.3.1</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Desconocida (Normal)</a></li>
<li class="chapter" data-level="4.3.2" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-conocida-población-normal"><i class="fa fa-check"></i><b>4.3.2</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Conocida (Población: Normal)</a></li>
<li class="chapter" data-level="4.3.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-en-muestra-grande"><i class="fa fa-check"></i><b>4.3.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> en Muestra Grande</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><i class="fa fa-check"></i><b>4.4</b> PH para Igualdad de Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_1=\underline{\boldsymbol{\mu}}_2\)</span></a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html#caso-1.-mathbfsigma_1mathbfsigma_2mathbfsigma-conocida"><i class="fa fa-check"></i><b>4.4.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.4.2" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html#caso-2.-mathbfsigma_1mathbfsigma_2mathbfsigma-desconocida"><i class="fa fa-check"></i><b>4.4.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.4.3" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_1underlineboldsymbolmu_2.html#caso-3.-mathbfsigma_1neq-mathbfsigma_2-desconocida"><i class="fa fa-check"></i><b>4.4.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_1\neq \mathbf{\Sigma}_2\)</span>-Desconocida</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><i class="fa fa-check"></i><b>4.5</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_1\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_2\)</span>,   para muestras grandes</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html#caso-1.-mathbfsigma_1mathbfsigma_2mathbfsigma-conocida-1"><i class="fa fa-check"></i><b>4.5.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.5.2" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html#caso-2.-mathbfsigma_1mathbfsigma_2mathbfsigma-desconocida-1"><i class="fa fa-check"></i><b>4.5.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.5.3" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-para-muestras-grandes.html#caso-3.-mathbfsigma_1-neq-mathbfsigma_2-desconocidas"><i class="fa fa-check"></i><b>4.5.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_1 \neq \mathbf{\Sigma}_2\)</span>-Desconocidas</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_1-y-underlineboldsymbolmu_2-observaciones-pareadas.html"><i class="fa fa-check"></i><b>4.6</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_1\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_2\)</span>,      Observaciones Pareadas</a></li>
<li class="chapter" data-level="4.7" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><i class="fa fa-check"></i><b>4.7</b> PH Acerca de Contrastes del Vector de Medias Poblacional <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>, de una <span class="math inline">\(N_p(\underline{\boldsymbol{\mu}} \ , \ \mathbf{\Sigma} )\)</span></a></li>
<li class="chapter" data-level="4.8" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html"><i class="fa fa-check"></i><b>4.8</b> Inferencia para la Matriz de Varianzas Covarianza</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#pruba-de-razón-de-verosimilitud"><i class="fa fa-check"></i><b>4.8.1</b> Pruba de Razón de Verosimilitud</a></li>
<li class="chapter" data-level="4.8.2" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#prueba-de-bartlet"><i class="fa fa-check"></i><b>4.8.2</b> Prueba de Bartlet</a></li>
<li class="chapter" data-level="4.8.3" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#dos-o-más-matrices-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.3</b> Dos o más Matrices de Varianzas Covarianzas</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><i class="fa fa-check"></i><b>4.9</b> Regiones de Confianza y Comparaciones Simultáneas entre las Componentes del Vector de Medias <span class="math inline">\(\underline{\mu}\)</span></a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#construcción-de-una-región-de-confianza-para-underlinemu-cuando-la-población-tiene-distribución-n_punderlinemumathbfsigma-con-underlinemu-y-mathbfsigma-desconocidos"><i class="fa fa-check"></i><b>4.9.1</b> Construcción de una Región de Confianza para <span class="math inline">\(\underline{\mu}\)</span> Cuando la Población tiene Distribución <span class="math inline">\(N_p(\underline{\mu},\mathbf{\Sigma})\)</span>, con <span class="math inline">\(\underline{\mu}\)</span> y <span class="math inline">\(\mathbf{\Sigma}\)</span> desconocidos</a></li>
<li class="chapter" data-level="4.9.2" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#región-de-confianza-para-el-caso-de-p2-elipse-de-confianza"><i class="fa fa-check"></i><b>4.9.2</b> Región de Confianza para el Caso de <span class="math inline">\(p=2\)</span> (Elipse de Confianza)</a></li>
<li class="chapter" data-level="4.9.3" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#intervalos-de-confianza-simultáneos-para-las-componentes-del-vector-de-medias-underlinemu"><i class="fa fa-check"></i><b>4.9.3</b> Intervalos de Confianza Simultáneos para las Componentes del Vector de Medias <span class="math inline">\(\underline{\mu}\)</span></a></li>
<li class="chapter" data-level="4.9.4" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#ic-t2-simultáneos-para-diferencias-de-medias"><i class="fa fa-check"></i><b>4.9.4</b> IC <span class="math inline">\(T^2\)</span> Simultáneos para Diferencias de Medias</a></li>
<li class="chapter" data-level="4.9.5" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#IC-Bonferroni"><i class="fa fa-check"></i><b>4.9.5</b> Método de Bonferroni para Comparaciones Múltiples</a></li>
<li class="chapter" data-level="4.9.6" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#intervalos-de-confianza-simultáneos-chi2-caso-n-grande"><i class="fa fa-check"></i><b>4.9.6</b> Intervalos de Confianza Simultáneos <span class="math inline">\(\chi^2\)</span> (caso n-Grande)</a></li>
<li class="chapter" data-level="4.9.7" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlinemu.html#ic-simultáneos-para-n-grande-usando-la-normal-estándar-z_alpha"><i class="fa fa-check"></i><b>4.9.7</b> IC Simultáneos para n-Grande Usando la Normal Estándar <span class="math inline">\(Z_\alpha\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ACP.html"><a href="ACP.html"><i class="fa fa-check"></i><b>5</b> Análisis de Componentes Principales (ACP)</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introducción-1.html"><a href="introducción-1.html"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="interpretaciones-geométricas-y-algebraícas-del-acp.html"><a href="interpretaciones-geométricas-y-algebraícas-del-acp.html"><i class="fa fa-check"></i><b>5.2</b> Interpretaciones Geométricas y Algebraícas del ACP</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="interpretaciones-geométricas-y-algebraícas-del-acp.html"><a href="interpretaciones-geométricas-y-algebraícas-del-acp.html#interpretación-geométrica-del-acp-mediante-un-ejemplo-simple"><i class="fa fa-check"></i><b>5.2.1</b> Interpretación Geométrica del ACP Mediante un Ejemplo Simple</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html"><i class="fa fa-check"></i><b>5.3</b> Mas de dos Ejes</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#min-cuadrados"><i class="fa fa-check"></i><b>5.3.1</b> Ajuste de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="5.3.2" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#relación-entre-los-sub-espacios-de-mathbbrp-y-de-mathbbrn"><i class="fa fa-check"></i><b>5.3.2</b> Relación entre los Sub-espacios de <span class="math inline">\(\mathbb{R}^p\)</span> y de <span class="math inline">\(\mathbb{R}^n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="componentes-principales-en-análisis-de-regresión.html"><a href="componentes-principales-en-análisis-de-regresión.html"><i class="fa fa-check"></i><b>5.4</b> Componentes Principales en Análisis de Regresión</a></li>
<li class="chapter" data-level="5.5" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html"><i class="fa fa-check"></i><b>5.5</b> Componentes Principales Poblacionales</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#definicón-de-las-cps-poblacionales"><i class="fa fa-check"></i><b>5.5.1</b> Definicón de las CPs Poblacionales</a></li>
<li class="chapter" data-level="5.5.2" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#determinación-de-las-cps-poblacionales"><i class="fa fa-check"></i><b>5.5.2</b> Determinación de las CPs Poblacionales</a></li>
<li class="chapter" data-level="5.5.3" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-derivadas-de-una-normal-multivariada"><i class="fa fa-check"></i><b>5.5.3</b> Componentes Principales Derivadas de una Normal Multivariada</a></li>
<li class="chapter" data-level="5.5.4" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-usando-variables-estandarizadas"><i class="fa fa-check"></i><b>5.5.4</b> Componentes Principales usando Variables Estandarizadas</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><i class="fa fa-check"></i><b>5.6</b> Componentes Principales para Matrices de Var-Cov <span class="math inline">\(\mathbf{\Sigma}\)</span> con Estructuras Especiales</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#variables-no-correlacionadas"><i class="fa fa-check"></i><b>5.6.1</b> Variables No-Correlacionadas</a></li>
<li class="chapter" data-level="5.6.2" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#var-correlacionadas"><i class="fa fa-check"></i><b>5.6.2</b> Variables Altamente Correlacionadas</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="componentes-principales-muestrales.html"><a href="componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>5.7</b> Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="5.8" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html"><i class="fa fa-check"></i><b>5.8</b> Algunos Ejemplos de ACP</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo1"><i class="fa fa-check"></i><b>5.8.1</b> Ejemplo-1</a></li>
<li class="chapter" data-level="5.8.2" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo-2"><i class="fa fa-check"></i><b>5.8.2</b> Ejemplo-2</a></li>
<li class="chapter" data-level="5.8.3" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo-3"><i class="fa fa-check"></i><b>5.8.3</b> Ejemplo-3</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="cómo-elegir-el-número-de-componentes-principales.html"><a href="cómo-elegir-el-número-de-componentes-principales.html"><i class="fa fa-check"></i><b>5.9</b> Cómo elegir el número de Componentes Principales?</a></li>
<li class="chapter" data-level="5.10" data-path="interpretación-de-las-componentes-principales-muestrales.html"><a href="interpretación-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>5.10</b> Interpretación de las Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="5.11" data-path="estandarización-de-las-componentes-principales-muestrales.html"><a href="estandarización-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>5.11</b> Estandarización de las Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="5.12" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html"><i class="fa fa-check"></i><b>5.12</b> Gráficas en un Análisis de Componentes Principales</a>
<ul>
<li class="chapter" data-level="5.12.1" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html#graficos-de-las-cps"><i class="fa fa-check"></i><b>5.12.1</b> Graficos de las CPS</a></li>
<li class="chapter" data-level="5.12.2" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html#el-gráfico-biplot"><i class="fa fa-check"></i><b>5.12.2</b> El gráfico biplot:</a></li>
</ul></li>
<li class="chapter" data-level="5.13" data-path="propiedades-de-hatlambda_i-y-underlinehatmathbfe_i-en-muestras-grandes.html"><a href="propiedades-de-hatlambda_i-y-underlinehatmathbfe_i-en-muestras-grandes.html"><i class="fa fa-check"></i><b>5.13</b> Propiedades de <span class="math inline">\(\hat{\lambda}_i\)</span> y <span class="math inline">\(\underline{\hat{\mathbf{e}}}_i\)</span> en Muestras Grandes</a></li>
<li class="chapter" data-level="5.14" data-path="prueba-de-hipótesis-para-estructura-de-correlación-igual.html"><a href="prueba-de-hipótesis-para-estructura-de-correlación-igual.html"><i class="fa fa-check"></i><b>5.14</b> Prueba de Hipótesis para Estructura de Correlación Igual</a></li>
<li class="chapter" data-level="5.15" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html"><i class="fa fa-check"></i><b>5.15</b> Ejemplos Finales</a>
<ul>
<li class="chapter" data-level="5.15.1" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-1"><i class="fa fa-check"></i><b>5.15.1</b> Ejemplo-1</a></li>
<li class="chapter" data-level="5.15.2" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-acp-con-individuos-y-variables-suplementarias"><i class="fa fa-check"></i><b>5.15.2</b> Ejemplo ACP con Individuos y Variables Suplementarias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="affc.html"><a href="affc.html"><i class="fa fa-check"></i><b>6</b> Análisis Factorial de Factores Comunes</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducción-2.html"><a href="introducción-2.html"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="tipos-de-factores.html"><a href="tipos-de-factores.html"><i class="fa fa-check"></i><b>6.2</b> Tipos de Factores</a></li>
<li class="chapter" data-level="6.3" data-path="motivación-del-análisis-factorial.html"><a href="motivación-del-análisis-factorial.html"><i class="fa fa-check"></i><b>6.3</b> Motivación del Análisis Factorial</a></li>
<li class="chapter" data-level="6.4" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html"><i class="fa fa-check"></i><b>6.4</b> Enfoques del AF</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#métodos-para-realizar-la-extracción-de-los-factores"><i class="fa fa-check"></i><b>6.4.1</b> Métodos para realizar la extracción de los factores</a></li>
<li class="chapter" data-level="6.4.2" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#rotación-de-ejes"><i class="fa fa-check"></i><b>6.4.2</b> Rotación de Ejes</a></li>
<li class="chapter" data-level="6.4.3" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#puntuaciones-o-scores-de-los-sujetos-en-los-factores-extraídos"><i class="fa fa-check"></i><b>6.4.3</b> Puntuaciones o Scores de los Sujetos en los Factores Extraídos</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html"><i class="fa fa-check"></i><b>6.5</b> El Modelo de Factor Ortogonal</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html#mas-propiedades-del-afc"><i class="fa fa-check"></i><b>6.5.1</b> Mas Propiedades del AFC</a></li>
<li class="chapter" data-level="6.5.2" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html#ejemplos"><i class="fa fa-check"></i><b>6.5.2</b> Ejemplos</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html"><i class="fa fa-check"></i><b>6.6</b> Métodos de Estimación</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#el-método-de-la-componente-principal"><i class="fa fa-check"></i><b>6.6.1</b> El Método de la Componente Principal</a></li>
<li class="chapter" data-level="6.6.2" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#una-aproximación-modificada-la-solución-del-factor-principal"><i class="fa fa-check"></i><b>6.6.2</b> Una Aproximación Modificada (La Solución del Factor Principal)</a></li>
<li class="chapter" data-level="6.6.3" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#el-método-de-máxima-verosimilitud"><i class="fa fa-check"></i><b>6.6.3</b> El Método de Máxima Verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="prueba-para-el-número-de-factores-muestra-grande..html"><a href="prueba-para-el-número-de-factores-muestra-grande..html"><i class="fa fa-check"></i><b>6.7</b> Prueba para el Número de Factores (Muestra Grande).</a></li>
<li class="chapter" data-level="6.8" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html"><i class="fa fa-check"></i><b>6.8</b> Rotación de Factores</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#rotaciones-cuando-m2-factores"><i class="fa fa-check"></i><b>6.8.1</b> Rotaciones cuando <span class="math inline">\(m=2\)</span>-Factores</a></li>
<li class="chapter" data-level="6.8.2" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#criterio-varimáx"><i class="fa fa-check"></i><b>6.8.2</b> Criterio Varimáx:</a></li>
<li class="chapter" data-level="6.8.3" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#rotaciones-oblicuas"><i class="fa fa-check"></i><b>6.8.3</b> Rotaciones Oblicuas</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="scores-o-puntuaciones-de-los-factores.html"><a href="scores-o-puntuaciones-de-los-factores.html"><i class="fa fa-check"></i><b>6.9</b> Scores (o Puntuaciones) de los Factores</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="scores-o-puntuaciones-de-los-factores.html"><a href="scores-o-puntuaciones-de-los-factores.html#método-de-los-mínimos-cuadrados-ponderados"><i class="fa fa-check"></i><b>6.9.1</b> Método de los Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="6.9.2" data-path="scores-o-puntuaciones-de-los-factores.html"><a href="scores-o-puntuaciones-de-los-factores.html#el-método-de-la-regresión"><i class="fa fa-check"></i><b>6.9.2</b> El Método de la Regresión</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Chapter 6</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="scores-o-puntuaciones-de-los-factores" class="section level2 hasAnchor" number="6.9">
<h2><span class="header-section-number">6.9</span> Scores (o Puntuaciones) de los Factores<a href="scores-o-puntuaciones-de-los-factores.html#scores-o-puntuaciones-de-los-factores" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En el análisis de factor, el interés generalmente se centra en los parámetros del modelo ( es decir, las matrices <span class="math inline">\(\mathbf{L}\)</span> y <span class="math inline">\(\mathbf{\Psi}\)</span>). Sin embargo, los valores estimados de los factores comunes, <strong>llamados scores o puntuaciones</strong> de los factores, también pueden ser de utilidad. Estas cantidades son usadas frecuentemente para propósitos de diagnóstico del modelo y como insumos para análisis posteriores.</p>
<p>Dado los <span class="math inline">\(m\)</span>-factores,
<span class="math display">\[
\underline{\mathbf{f}}= \begin{bmatrix} F_{1} \\ F_{2} \\ \vdots \\ F_{m} \end{bmatrix}_{m\times 1} \ \ \ \ \ , \ \ \ \ \ \underline{\mathbf{f}}_j= \begin{bmatrix} f_{j1} \\ f_{j2} \\ \vdots \\ f_{jm} \end{bmatrix}_{m\times 1} \ \ \ \ \ , \ \ \ \ \ \hat{\underline{\mathbf{f}}}_j= \begin{bmatrix} \hat{f}_{j1} \\ \hat{f}_{j2} \\ \vdots \\ \hat{f}_{jm} \end{bmatrix}_{m\times 1} \ \ \ j=1,2,\ldots,n
\]</span></p>
<p><span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> Los scores de los factores no son estimaciones de parámetros desconocidos en el sentido usual. En realidad, son estimaciones para los valores de los vectores aleatorios no observables <span class="math inline">\(\underline{\mathbf{f}}_j\)</span>, <span class="math inline">\(j=1, 2, \ldots, n\)</span>. Es decir, <span class="math inline">\(\underline{\mathbf{f}}_j\)</span> contiene los puntajes obtenidos por el <span class="math inline">\(j\)</span>-ésimo caso (u observación) en los <span class="math inline">\(m\)</span> factores y <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> contiene las resepctivas estimaciones de los valores de <span class="math inline">\(\underline{\mathbf{f}}_j\)</span>.</p>
<p>La estimación de estas cantidades se complica por el hecho de que las cantidades no observadas <span class="math inline">\(\underline{\mathbf{f}}_j\)</span> y <span class="math inline">\(\underline{\boldsymbol{\varepsilon}}_j\)</span> superan en número a los valores observados <span class="math inline">\(\underline{\mathbf{x}}_j\)</span>.</p>
<p>A continuación se presentarán dos aproximaciones, que tienen dos elementos en común:</p>
<ol style="list-style-type: decimal">
<li><p>Tratan las ponderaciones estimadas <span class="math inline">\(\hat{l}_{ij}\)</span> y las varianzas específicas estimadas <span class="math inline">\(\hat{\psi}_i\)</span>, como si fueran las verdaderas.</p></li>
<li><p>Usan transformaciones lineales de los datos originales, ya
sea centrados o estandarizados. Para estimar las puntuaciones de los factores <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span>, generalmente, se usan <em>las ponderaciones estimadas rotadas en lugar de las ponderaciones estimadas originales</em>.</p></li>
</ol>
<p>Las fórmulas dadas a continuación no cambian cuando las ponderaciones no rotadas son sustituidas por las rotadas.</p>
<div id="método-de-los-mínimos-cuadrados-ponderados" class="section level3 hasAnchor" number="6.9.1">
<h3><span class="header-section-number">6.9.1</span> Método de los Mínimos Cuadrados Ponderados<a href="scores-o-puntuaciones-de-los-factores.html#método-de-los-mínimos-cuadrados-ponderados" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suponga que el vector <span class="math inline">\(\underline{\boldsymbol\mu}\)</span>, las ponderaciones de los factores <span class="math inline">\(\mathbf{L}\)</span> y las varianzas específicas <span class="math inline">\(\mathbf{\Psi}\)</span> son conocidas en el modelo de factor:</p>
<p><span class="math display">\[
\underline{\mathbf{x}}_{p\times 1}-\underline{\boldsymbol\mu}_{p\times 1}=\mathbf{L}_{p\times m} \underline{\mathbf{f}}_{m \times 1}+\underline{\varepsilon}_{p\times 1}
\]</span></p>
<p>El modelo anterior puede ser considerado como un <strong>modelo de regresión donde los factores específicos son considerados como los errores</strong>.</p>
<p>Como,
<span class="math display">\[
Var[\varepsilon_i]=\hat{\psi}_i \ , \ \  i=1, 2, \ldots, p
\]</span></p>
<p>Bartlett en <span class="citation">(<a href="#ref-bartlett1937" role="doc-biblioref">1937</a>)</span>, sugirió usar mínimos cuadrados ponderados <strong>para estimar los valores de los factores comunes</strong>.</p>
<p>La suma cuadrática de errores ponderada por el recíproco de sus varianzas esta dada por:
<span class="math display">\[
Q(\underline{\mathbf{f}})=\sum_{i=1}^p \ \frac{\varepsilon_i^2}{\psi_i}=\underline{\boldsymbol{\varepsilon}}^t\ \mathbf{\Psi}^{-1} \ \underline{\boldsymbol{\varepsilon}}= \biggl(\underline{\mathbf{x}}-\underline{\boldsymbol\mu}- \mathbf{L}\ \underline{\mathbf{f}} \biggr)^T\mathbf{\Psi}^{-1}\ \biggl(\underline{\mathbf{x}}-\underline{\boldsymbol\mu}- \mathbf{L}\ \underline{\mathbf{f}} \biggr)
\]</span></p>
<p>La solución de <strong>Mínimos Cuadrados Ponderados</strong> es aquel vector <span class="math inline">\(\hat{\underline{\mathbf{f}}}\)</span> que minimiza a <span class="math inline">\(Q(\underline{\mathbf{f}})\)</span> y dicha solución está dada por:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}= \left( \mathbf{L}^T \mathbf{\Psi}^{-1}\mathbf{L} \right)^{-1}\mathbf{L}^T \mathbf{\Psi}^{-1}(\underline{\mathbf{x}}-\underline{\boldsymbol\mu})
\]</span></p>
<p>Ahora, <strong>usando las estimaciones</strong>:
<span class="math display">\[
\hat{\mathbf{L}} \ , \ \ \hat{\mathbf{\Psi}} \ \ \ \text{y} \ \ \ \hat{\underline{\boldsymbol\mu}}=\underline{\overline{\mathbf{x}}}
\]</span></p>
<p><strong>como los verdaderos valores</strong> entonces se tiene que, <strong>los scores o puntuaciones para el <span class="math inline">\(j\)</span>-caso u observación</strong> son:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \mathbf{L}^T \mathbf{\Psi}^{-1}\mathbf{L} \right)^{-1}\mathbf{L}^T \mathbf{\Psi}^{-1}(\underline{\mathbf{x}}_j-\underline{\boldsymbol\mu})
\]</span></p>
<p>Ahora, cuando <span class="math inline">\(\hat{\mathbf{L}}\)</span> y <span class="math inline">\(\hat{\mathbf{\Psi}}\)</span> son determinados por máxima verosimilitud, estos estimadores deben cumplir la condición de unicidad de que:
<span class="math display">\[
\hat{\mathbf{L}}^T \hat{ \mathbf{\Psi}}^{-1} \hat{ \mathbf{L} } =\hat{\mathbf{\Delta}}
\]</span></p>
<p>sea una matriz diagonal.</p>
<div id="scores-de-los-factores-obtenidos-por-mínimos-cuadrados-ponderados-usando-estimaciones-de-máxima-verosimilitud" class="section level4 hasAnchor" number="6.9.1.1">
<h4><span class="header-section-number">6.9.1.1</span> Scores de los factores obtenidos por Mínimos Cuadrados Ponderados usando estimaciones de Máxima Verosimilitud<a href="scores-o-puntuaciones-de-los-factores.html#scores-de-los-factores-obtenidos-por-mínimos-cuadrados-ponderados-usando-estimaciones-de-máxima-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>De lo anterior:
<span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \mathbf{L}^T \mathbf{\Psi}^{-1}\mathbf{L} \right)^{-1}\mathbf{L}^T \mathbf{\Psi}^{-1}(\underline{\mathbf{x}}_j-\underline{\boldsymbol\mu})\\
\ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \  \ \  =\hat{\mathbf{\Delta}}^{-1}\mathbf{L}^T \mathbf{\Psi}^{-1}(\underline{\mathbf{x}}_j-\underline{\boldsymbol\mu}) \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<p><strong>o si se usan variables estandarizadas entonces</strong>:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\mathbf{L}_{\underline{\mathbf{z}}} \right)^{-1}\mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\ \underline{\mathbf{z}}_j\\
\ \ \ \ \ \ \ \ \ \ \ \  \ \ \ \ \ \  \ \  =\hat{\mathbf{\Delta}}_{\underline{\mathbf{z}}}^{-1}\mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\ \underline{\mathbf{z}}_j \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<p>donde
<span class="math display">\[
\underline{\mathbf{z}}_j=\mathbf{D}^{-1/2}( \underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}} ) \ \ \ \  \text{y} \ \ \ \ \ \ \hat{\rho}=\hat{\mathbf{L}}_{\underline{\mathbf{z}}} \hat{\mathbf{L}}_{\underline{\mathbf{z}}}^T +\hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}
\]</span></p>
<p>Los scores de los factores así generados, tienen media muestral cero y covarianzas muestrales cero.</p>
</div>
<div id="scores-de-los-factores-obtenidos-por-mínimos-cuadrados-ordinarios-usando-estimaciones-mediante-el-método-las-cp" class="section level4 hasAnchor" number="6.9.1.2">
<h4><span class="header-section-number">6.9.1.2</span> Scores de los factores obtenidos por Mínimos Cuadrados Ordinarios usando estimaciones mediante el método las CP<a href="scores-o-puntuaciones-de-los-factores.html#scores-de-los-factores-obtenidos-por-mínimos-cuadrados-ordinarios-usando-estimaciones-mediante-el-método-las-cp" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si las ponderaciones de los factores son calculadas por medio del <strong>método de componente principal</strong>, se acostumbra a generar los scores de los factores usando el procedimiento de <strong>mínimos cuadrados ordinarios</strong> ( no ponderados).</p>
<p><em>Implícitamente se supone que los <span class="math inline">\(\hat{\psi}_i\)</span> son iguales o aproximadamente iguales</em>.</p>
<p>En este caso, <strong>los scores de los factores</strong> son:
<span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \hat{ \mathbf{L}}^T \hat{ \mathbf{L} } \right)^{-1} \hat{ \mathbf{L}}^T (\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})
\]</span></p>
<p>o
<span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \hat{ \mathbf{L}}_{\underline{\mathbf{z}}}^T \hat{ \mathbf{L} }_{\underline{\mathbf{z}}} \right)^{-1} \hat{ \mathbf{L}}_{\underline{\mathbf{z}}}^T \underline{\mathbf{z}}_j
\]</span></p>
<p>para datos estandarizados.</p>
<p>Como
<span class="math display">\[
\hat{\mathbf{L}}=\begin{bmatrix}
\sqrt{\hat{\lambda}_1}\underline{\hat{\mathbf{e}}}_1 &amp; | &amp; \sqrt{\hat{\lambda}_2}\underline{\hat{\mathbf{e}}}_2 &amp; | &amp; \cdots &amp; | &amp; \sqrt{\hat{\lambda}_m}\underline{\hat{\mathbf{e}}}_m
\end{bmatrix}_{p\times m}
\]</span></p>
<p>luego,
<span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \hat{ \mathbf{L}}^T \hat{ \mathbf{L} } \right)^{-1} \hat{ \mathbf{L}}^T (\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})=\begin{bmatrix}
\frac{1}{\sqrt{\hat{\lambda}_1}}\underline{\hat{\mathbf{e}}}_1^T(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})  \\
\frac{1}{\sqrt{\hat{\lambda}_2}}\underline{\hat{\mathbf{e}}}_2^T(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})  \\
\vdots \\
\frac{1}{\sqrt{\hat{\lambda}_m}}\underline{\hat{\mathbf{e}}}_m^T(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}})  \\
\end{bmatrix}
\]</span></p>
<p>Los scores de los factores así generados, tienen vector de medias muestral cero y matriz de varianzas covarianzas muestral la <span class="math inline">\(\mathbf{I}\)</span>, es decir:
<span class="math display">\[
\overline{\underline{\mathbf{f}}}=\frac{1}{n}\sum_{j=1}^n\  \hat{\underline{\mathbf{f}}}_j = \underline{\mathbf{0}}
\]</span>
y
<span class="math display">\[
\mathbf{S}=\frac{1}{n-1}\sum_{j=1}^n\  \hat{\underline{\mathbf{f}}}_j\ \hat{\underline{\mathbf{f}}}_j^t = \mathbf{I}
\]</span></p>
<p><em>Comparando con el Análisis de Componentes Principales</em>, <strong>los scores no son más que las <span class="math inline">\(m\)</span> componentes principales (escaladas) evaluadas en</strong> <span class="math inline">\(\underline{\mathbf{x}}_j\)</span>.</p>
</div>
</div>
<div id="el-método-de-la-regresión" class="section level3 hasAnchor" number="6.9.2">
<h3><span class="header-section-number">6.9.2</span> El Método de la Regresión<a href="scores-o-puntuaciones-de-los-factores.html#el-método-de-la-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Considerando el modelo de factor original:
<span class="math display">\[
\underline{\mathbf{x}}-\underline{\mu}=\mathbf{L}\underline{\mathbf{f}}+\underline{\boldsymbol\varepsilon}
\]</span></p>
<p>inicialmente tratamos a la matriz de ponderaciones <span class="math inline">\(\mathbf{L}\)</span> y a la matriz de varianza específica <span class="math inline">\(\mathbf{\Psi}\)</span> como se fueran conocidas.</p>
<p>Cuando los factores comunes <span class="math inline">\(\underline{\mathbf{f}}\)</span> y los factores específicos (o errores) <span class="math inline">\(\underline{\boldsymbol\varepsilon}\)</span> tienen una distribución conjunta normal multivariada con vectores de media y matrices de covarianza dadas por:</p>
<p><span class="math display">\[
E[\underline{\mathbf{f}}]=\underline{0}_{\ m\times 1} \ \ \ , \ \ \ \ Var[\underline{\mathbf{f}}]=E[\underline{\mathbf{f}}\underline{\mathbf{f}}^T]=\begin{bmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; &amp; 0  &amp; 1
\end{bmatrix}_{m\times m}=\mathbf{I}_m
\]</span></p>
<p><span class="math display">\[
E[\ \underline{\boldsymbol\varepsilon}\ ]=\underline{0}_{\ p\times 1} \ \ \ , \ \ \ Var[\ \underline{\boldsymbol\varepsilon}\ ]=E[\ \underline{\boldsymbol\varepsilon}\underline{\boldsymbol\varepsilon}^T\ ]=\mathbf{\Psi}=\begin{bmatrix}
\psi_1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \psi_2 &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; &amp; 0 &amp; \psi_p
\end{bmatrix}_{p\times p}
\]</span></p>
<p>es decir,
<span class="math display">\[
\underline{\mathbf{f}}= \begin{bmatrix} F_1 \\ F_2 \\ \vdots \\  F_m \end{bmatrix}_{m\times 1} \sim N_m \biggl(\underline{\mathbf{0}} \ , \ \mathbf{I}_m \biggr) \ \ \ \ \ \ , \ \ \ \ \ \underline{\boldsymbol\varepsilon}= \begin{bmatrix} \varepsilon_1 \\ \varepsilon_2 \\ \vdots \\  \varepsilon_p \end{bmatrix}_{p\times 1} \sim N_p \biggl(\underline{\mathbf{0}} \ , \ \mathbf{\Psi} \biggr)
\]</span></p>
<p>y además recuerde que, <span class="math inline">\(\underline{\mathbf{f}}\)</span> y <span class="math inline">\(\underline{\boldsymbol{\varepsilon}}\)</span> son independientes, es decir,
<span class="math display">\[
Cov(\underline{\mathbf{f}}\ \ , \ \ \underline{\boldsymbol{\varepsilon}}) = \underset{m\times p}{\mathbf{O}}
\]</span></p>
<p>Las combinaciones lineales:
<span class="math display">\[
\underline{\mathbf{x}}-\underline{\mu}=\mathbf{L}\underline{\mathbf{f}}+\underline{\boldsymbol\varepsilon}
\]</span>
tienen una distribución:
<span class="math display">\[
(\underline{\mathbf{x}}-\underline{\mu}) \sim N_p\biggl(\ \underline{0} \ \ ,\ \ \mathbf{LL}^T+\mathbf{\Psi}\ \biggr)
\]</span></p>
<p>Además la distribución conjunta de <span class="math inline">\((\underline{\mathbf{x}}-\underline{\boldsymbol\mu})\)</span> y <span class="math inline">\(\underline{\mathbf{f}}\)</span> es:</p>
<p><span class="math display">\[
\begin{bmatrix} \underline{\mathbf{x}}-\underline{\boldsymbol\mu} \\  \underline{\mathbf{f}} \end{bmatrix}_{(p+m) \times  1} N_{p+m} \biggl(\ \underline{\mathbf{0}}\ \ , \   \  \mathbf{\Sigma}^{\star} \ \biggr)
\]</span></p>
<p>donde:
<span class="math display">\[
\underset{(p+m)\times (p+m)}{\mathbf{\Sigma}^{\star}}=\begin{bmatrix}
\underset{p\times p}{\mathbf{\Sigma}}=\mathbf{LL}^T+\mathbf{\Psi}  &amp;| &amp;  \underset{p\times m}{\mathbf{L}} \\
------- &amp; &amp; ------ \\
\underset{m\times p}{\mathbf{L}^T}   &amp; | &amp;  \mathbf{I}_m
\end{bmatrix}_{(p+m) \times (p+m)}
\]</span></p>
<p>y <span class="math inline">\(\underline{\mathbf{0}}\)</span> es un vector de <span class="math inline">\((m+p) \times 1\)</span> ceros.</p>
<p>Usando estos resultados, la distribución condicional de <span class="math inline">\(\underline{\mathbf{f}}\ | \underline{\mathbf{x}}\)</span> es normal multivariada con:</p>
<p><span class="math display">\[
\underset{m\times 1}{ E\bigl[\underline{\mathbf{f}}\ |\  \underline{x}\bigr] }=\mathbf{L}^T \mathbf{\Sigma}^{-1}(\underline{x} - \underline{\mu})=\mathbf{L}^T (\mathbf{LL}^T+\mathbf{\Psi} )^{-1}(\underline{x} - \underline{\mu})
\]</span></p>
<p>y matriz de varianzas-covarianzas dada por:
<span class="math display">\[
\underset{m\times m}{Var\bigl[\underline{\mathbf{f}}\ |\  \underline{x}]}=\mathbf{I}_m - \mathbf{L}^T \mathbf{\Sigma}^{-1}\mathbf{L}=\mathbf{I}_m- \mathbf{L}^T (\mathbf{LL}^T+\mathbf{\Psi} )^{-1}\mathbf{L}
\]</span></p>
<p>Las cantidades:
<span class="math display">\[
\underset{m\times p}{ \underbrace{\mathbf{L}^T (\mathbf{LL}^T+\mathbf{\Psi} )^{-1}} }
\]</span></p>
<p>son <strong>los coeficientes de una regresión multivariada de los factores</strong> <span class="math inline">\(F_j\)</span> <strong>sobre las variables</strong> <span class="math inline">\(X_k\)</span>, <span class="math inline">\(j=1,2,\ldots,m\)</span>, <span class="math inline">\(k=1,2,\ldots,p\)</span>.</p>
<p><em>La estimación de estos coeficientes producen scores para los factores (o Factores Scores) que son análogos a las estimaciones de los valores de las medias condicionales en el análisis de regresión multivariada</em>.</p>
<p>Por tanto, dado cualquier vector de observaciones <span class="math inline">\(\underline{\mathbf{x}}_j\)</span>, tomando las estimaciones máximo verosímiles <span class="math inline">\(\hat{\mathbf{L}}\)</span> y <span class="math inline">\(\hat{\mathbf{\Psi}}\)</span> como los verdaderos valores de <span class="math inline">\(\mathbf{L}\)</span> y <span class="math inline">\(\mathbf{\Psi}\)</span> resepctivamente entonces, el <span class="math inline">\(j\)</span>-ésimo vector de factores Scores estimado está dado por:</p>
<p><span class="math display">\[
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}=\hat{\mathbf{L}}^T \hat{\mathbf{\Sigma}}^{-1}(\underline{x}_j-\underline{\overline{\mathbf{x}}})=\hat{\mathbf{L}}^T (\hat{\mathbf{L}}\hat{\mathbf{L}}^T+\hat{\mathbf{\Psi}})^{-1}(\underline{x}_j-\underline{\overline{\mathbf{x}}}) \ , \ \ \ \text{para}, j=1,2,\ldots , n
\]</span></p>
<p><strong>Observaciones</strong>:</p>
<ol style="list-style-type: decimal">
<li>El cálculo de <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> se puede simplificar usando la siguiente identidad matricial:</li>
</ol>
<p><span class="math display">\[
\underset{m\times p}{\hat{\mathbf{L}}^T} \underset{p\times p}{ (\hat{ \mathbf{L}}\hat{\mathbf{L}}^T+\hat{\mathbf{\Psi}} )^{-1}}=(\mathbf{I}_m + \underset{m\times m}{ \hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}})}^{-1}\underset{m\times p}{\hat{\mathbf{L}}^T} \underset{p\times p}{\hat{\mathbf{\Psi}}^{-1}}
\]</span></p>
<p>ver ejercicio 9.6 del libro <span class="citation">(<a href="#ref-johnson2007applied" role="doc-biblioref">Johnson and Wichern 2007</a>)</span>.</p>
<p>Esta identidad nos permite comparar los Scores anteriores de <em>regresión</em> con los generados por <em>mínimos cuadrados ponderados</em>.</p>
<p>Sean <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j^R\)</span> los scores generados por el método de la regresión y <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j^{LS}\)</span>
los generados por mínimos cuadrados ponderados entonces, usando la identidad anterior se tiene que:</p>
<p><span class="math display">\[
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j^{LS}}=(\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}})^{-1}(\mathbf{I}_m+\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}})\hat{\underline{\mathbf{f}}}_j^{R}=\left(\mathbf{I}_m+(\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}})^{-1}\right)\hat{\underline{\mathbf{f}}}_j^R
\]</span></p>
<p>Para los estimadores máximo verosímiles como,
<span class="math display">\[
\underset{m\times m}{\underbrace{(\hat{\mathbf{L}}^T\hat{\mathbf{\Psi}}^{-1}\hat{\mathbf{L}})^{-1}}}=\hat{\mathbf{\Delta}}^{-1}
\]</span></p>
<p>Por lo tanto, si los elementos de esta matriz diagonal son cercanos a cero, <strong>el método de la regresión y el de mínimos cuadrados ponderado (o generalizado) producirán los mismos factores Scores</strong>.</p>
<ol start="2" style="list-style-type: decimal">
<li>En un intento por tratar de reducir los efectos de una (posible) determinación incorrecta del número de factores, algunos calculan los factores-Scores reemplazando la matriz
<span class="math display">\[
\hat{\mathbf{\Sigma}}=\hat{\mathbf{L}}\hat{\mathbf{L}}^T+\hat{\mathbf{\Psi}}
\]</span></li>
</ol>
<p>por la matriz <span class="math inline">\(\mathbf{S}\)</span> (es decir por la matriz de varianzas covarianzas muestral original), obteniendo lo siguiente:</p>
<p><strong>Factores-Scores obtenidos por el Método de la Regresión</strong></p>
<p>De lo anterior:
<span class="math display">\[
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}= \mathbf{L}^T \mathbf{S}^{-1}(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}}) \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<p><strong>o si se usan variables estandarizadas entonces</strong>:</p>
<p><span class="math display">\[
\underset{m\times 1}{\hat{\underline{\mathbf{f}}}_j}= \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{R}^{-1}\ \underline{\mathbf{z}}_j \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<p>donde
<span class="math display">\[
\underline{\mathbf{z}}_j=\mathbf{D}^{-1/2}( \underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}} ) \ \ \ \  \text{y} \ \ \ \ \ \ \hat{\rho}=\hat{\mathbf{L}}_{\underline{\mathbf{z}}} \hat{\mathbf{L}}_{\underline{\mathbf{z}}}^T +\hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p>Si se usan los factores rotados
<span class="math display">\[
\underset{p\times 2}{\hat{\mathbf{L}}^{\star}}=\underset{p\times 2}{\hat{\mathbf{L}}}\ \underset{2\times 2}{ \mathbf{T}}
\]</span>
en lugar de las ponderaciones originales, los Factores-Scores de <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j^{\star}\)</span> (rotados) están relacionados con los factores <span class="math inline">\(\hat{\underline{\mathbf{f}}}_j\)</span> (no-rotados) por medio de:
<span class="math display">\[
\underset{2\times 1}{\hat{\underline{\mathbf{f}}}_j^{\star}}=\underset{2\times 2}{\mathbf{T}^T}\ \underset{2\times 1}{ \hat{\underline{\mathbf{f}}}_j}
\]</span></p></li>
<li><p>Una medida numérica de concordancia entre los Factores-Scores generados por estos dos métodos diferentes de cálculos esta dada por el <em>Coeficiente de Correlación Muestral entre los Scores de un mismo factor</em>.</p></li>
</ol>
<p>De los métodos presentados, <strong>ninguno se recomienda como uniformemente superior</strong>.</p>
<div class="example">
<p><span id="exm:ejemplo1-afc-regresion-cp" class="example"><strong>Ejemplo 6.10  (Estimación de Factores-Scores (Método de la Regresión y MC-Ponderados)) </strong></span>Para el ejemplo considerado anteriormente sobre datos rendimientos de las acciones de 5 compañías, se calcularán los Factores-Scores mediante los dos métodos vistos, es decir, por el <em>Método de Mínimos Cuadrados Ponderados</em> y el <em>Métdodo de la Regresión</em>.</p>
</div>
<p>Anteriormente, el método de Máxima-Verosimilitud a partir de la matriz de correlación <span class="math inline">\(\mathbf{R}\)</span> produjo las siguientes ponderaciones-rotadas y varianzas específicas estimadas:</p>
<p><span class="math display">\[
\hat{\mathbf{L}}_{\underline{\mathbf{z}}}^{\star}=\begin{bmatrix}
0.763 &amp; 0.024 \\ 0.821 &amp; 0.227 \\ 0.669 &amp; 0.104 \\ 0.118 &amp; 0.993 \\
0.113 &amp; 0.675
\end{bmatrix}_{p\times m} \ \ \ \ \text{y} \ \ \ \ \hat{\mathbf{\Psi}}_{\underline{\mathbf{z}}}=\begin{bmatrix}
0.42 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0.27 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0.45 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0.00 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0.53
\end{bmatrix}_{p\times p}
\]</span></p>
<p>El vector de Observaciones Estandarizadas dado por:
<span class="math display">\[
\underline{\mathbf{z}}= \begin{bmatrix} 0.50 \\ -1.40 \\ -0.20 \\ -0.70 \\ 1.40 \end{bmatrix}_{p\times 1}
\]</span></p>
<p>produce los siguientes Scores sobre los Factores 1 y 2.</p>
<p><strong>Para el Método de Mínimos Cuadrados Ponderados:</strong></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \left( \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\mathbf{L}_{\underline{\mathbf{z}}} \right)^{-1}\mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\ \underline{\mathbf{z}}_j =\hat{\mathbf{\Delta}}_{\underline{\mathbf{z}}}^{-1}\mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{\Psi}_{\underline{\mathbf{z}}}^{-1}\ \underline{\mathbf{z}}_j
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j=\begin{bmatrix} 0.401 &amp; 0.652 &amp; 0.27 &amp; -0.196 &amp; 0.014 \\ -0.048 &amp; -0.077  &amp; -0.032 &amp; 1.03 &amp; -0.002  \end{bmatrix} \begin{bmatrix} 0.5 \\ -1.4 \\ -0.2 \\ -0.7 \\ 1.4 \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \begin{bmatrix} -0.61 \\ -0.63 \end{bmatrix}
\]</span></p>
<p><strong>Para el Método de Regresión</strong>:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{R}^{-1}\ \underline{\mathbf{z}}_j
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j=\begin{bmatrix} 0.331 &amp; 0.527 &amp; 0.221 &amp; -0.138 &amp; 0.011 \\ -0.042 &amp; -0.06  &amp; -0.027 &amp; 1.022 &amp; 0  \end{bmatrix} \begin{bmatrix} 0.5 \\ -1.4 \\ -0.2 \\ -0.7 \\ 1.4 \end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \begin{bmatrix} -0.5 \\ -0.65 \end{bmatrix}
\]</span></p>
<p><strong>Comentario</strong>. Las puntuaciones de los factores o Factores-Scores con una propiedad intuitiva bastante agradable pueden compararse estructurado de manera muy simple. Agrupa las variables con cargas altas (digamos, mayor que 0.40 en valor absoluto) sobre un factor.</p>
<p><strong>Factores-Scores para los Factores 1 y 2, usando los estimadores MLE</strong>:</p>
<p><strong>Usando variables centradas se tiene que</strong>:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \mathbf{L}^T \mathbf{S}^{-1}(\underline{\mathbf{x}}_j-\underline{\overline{\mathbf{x}}}) \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-4">Tabla 6.2: </span>Factores-Scores Datos Centrados
</caption>
<tbody>
<tr>
<td style="text-align:right;">
3.4162903
</td>
<td style="text-align:right;">
-71.8057920
</td>
</tr>
<tr>
<td style="text-align:right;">
-1.3973936
</td>
<td style="text-align:right;">
8.3013835
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8240083
</td>
<td style="text-align:right;">
-0.1901986
</td>
</tr>
<tr>
<td style="text-align:right;">
49.4372148
</td>
<td style="text-align:right;">
-47.3389938
</td>
</tr>
<tr>
<td style="text-align:right;">
-24.2322078
</td>
<td style="text-align:right;">
30.0133514
</td>
</tr>
<tr>
<td style="text-align:right;">
-28.8496485
</td>
<td style="text-align:right;">
9.8505341
</td>
</tr>
<tr>
<td style="text-align:right;">
33.4563518
</td>
<td style="text-align:right;">
36.5185303
</td>
</tr>
<tr>
<td style="text-align:right;">
53.9452101
</td>
<td style="text-align:right;">
-4.6516117
</td>
</tr>
<tr>
<td style="text-align:right;">
-40.7258493
</td>
<td style="text-align:right;">
-41.1491392
</td>
</tr>
<tr>
<td style="text-align:right;">
5.0437738
</td>
<td style="text-align:right;">
-33.0719175
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grafico-factores-ls"></span>
<img src="bookdown-iam_files/figure-html/grafico-factores-ls-1.png" alt="Gráfico de  Factores-Socres 1 y 2 Datos Centrados" width="600px" />
<p class="caption">
Figura 6.3: Gráfico de Factores-Socres 1 y 2 Datos Centrados
</p>
</div>
<p><strong>Factores-Scores para los Factores 1 y 2, usando los estimadores MLE</strong>:</p>
<p><strong>Usando variables estandarizadas se tiene que</strong>:</p>
<p><span class="math display">\[
\hat{\underline{\mathbf{f}}}_j= \mathbf{L}_{\underline{\mathbf{z}}}^T \mathbf{R}^{-1}\ \underline{\mathbf{z}}_j \ \ \ , \ \ \ \ \ j=1,2,\ldots.n
\]</span></p>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-5">Tabla 6.3: </span>Factores-Scores Datos Estandarizados
</caption>
<tbody>
<tr>
<td style="text-align:right;">
0.1571664
</td>
<td style="text-align:right;">
-1.8476175
</td>
</tr>
<tr>
<td style="text-align:right;">
0.3690041
</td>
<td style="text-align:right;">
0.2528012
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.3950174
</td>
<td style="text-align:right;">
-0.1042523
</td>
</tr>
<tr>
<td style="text-align:right;">
0.6184621
</td>
<td style="text-align:right;">
-1.2975653
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.0547505
</td>
<td style="text-align:right;">
0.9484055
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.3762159
</td>
<td style="text-align:right;">
0.4052832
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8065007
</td>
<td style="text-align:right;">
0.8967162
</td>
</tr>
<tr>
<td style="text-align:right;">
0.8436178
</td>
<td style="text-align:right;">
-0.0180080
</td>
</tr>
<tr>
<td style="text-align:right;">
-0.9037402
</td>
<td style="text-align:right;">
-1.1624819
</td>
</tr>
<tr>
<td style="text-align:right;">
0.4249359
</td>
<td style="text-align:right;">
-0.9647232
</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:grafico-factores-ls-estand"></span>
<img src="bookdown-iam_files/figure-html/grafico-factores-ls-estand-1.png" alt="Gráfico de  Factores-Socres 1 y 2 Datos Estandarizados" width="600px" />
<p class="caption">
Figura 6.4: Gráfico de Factores-Socres 1 y 2 Datos Estandarizados
</p>
</div>
<div class="example">
<p><span id="exm:ejemplo2-afc-regresion" class="example"><strong>Ejemplo 6.11  (Estimación de Factores Scores (Método de la Regresión)) </strong></span>Para el ejemplo considerado anteriormente sobre datos rendimientos de las acciones de 5 compañías, se calcularán los Factores-Scores mediante el <em>Métdodo de la Regresión</em>.</p>
</div>
<p>Anteriormente, el método de la componente principal produjo las siguientes ponderaciones estimadas:</p>
<p><span class="math display">\[
\tilde{\mathbf{L}}=\begin{bmatrix}
0.732 &amp; -0.437 \\ 0.831 &amp; -0.280 \\ 0.726 &amp; -0.374 \\ 0.605 &amp; 0.694 \\
0.563 &amp; 0.719
\end{bmatrix} \ \ \ \ \text{y} \ \ \ \ \tilde{\mathbf{L}}^{\star}=\tilde{\mathbf{L}}\mathbf{T}=\begin{bmatrix}
0.852 &amp; 0.030 \\ 0.851 &amp; 0.214 \\ 0.813 &amp; 0.079 \\ 0.133 &amp; 0.911 \\
0.084 &amp; 0.909
\end{bmatrix}
\]</span></p>
<ol style="list-style-type: decimal">
<li>Para cada factor, tomando las mayores ponderaciones en <span class="math inline">\(\tilde{\mathbf{L}}\)</span> y eliminando las ponderaciones más pequeñas, se crean las siguientes combinaciones lineales:
<span class="math display">\[
\hat{f}_1=x_1+x_2+x_3+x_4+x_5 \ \ \ \text{y} \ \ \ \
\hat{f}_2=x_4+x_5-x_1
\]</span></li>
</ol>
<p>Como un resumen de los factores. En la práctica estas variables se estandarizan.</p>
<ol start="2" style="list-style-type: decimal">
<li>Si en lugar de usar <span class="math inline">\(\tilde{\mathbf{L}}\)</span> se usan las ponderaciones rotadas con el criterio varimax, ie. <span class="math inline">\(\tilde{\mathbf{L}}^{\star}\)</span>, los scores de los factores serían:
<span class="math display">\[
\hat{f}_1=x_1+x_2+x_3
\]</span></li>
</ol>
<p><span class="math display">\[
\hat{f}_2=x_4+x_5
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>La identificación de ponderaciones grandes y pequeñas es en realidad bastante subjetiva. Se prefieren las combinaciones lineales que tengan sentido en el área de investigación.</li>
</ol>
<p><strong>Observaciones</strong>:</p>
<ol style="list-style-type: decimal">
<li>Aunque con frecuenta se supone normalidad multivariada para las variables en un análisis de factor, en realidad es muy difícil justificar este supuesto cuando el número de variables es muy grande.</li>
</ol>
<p>Algunas veces, las transformaciones sobre las variables vistas anteriormente pueden ayudar a aproximar a la normalidad.</p>
<ol start="2" style="list-style-type: decimal">
<li>Se deben examinar los gráficos de los scores de los factores antes de usarlos en otros análisis.</li>
</ol>
<p>Los scores de los factores pueden producir toda clase de formas no elípticas, que pueden revelar valores atípicos y la desviación de la no normalidad.</p>

</div>
</div>
<!-- </div> -->
<h3>Bibliografía<a href="bibliografía.html#bibliografía" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bartlett1937" class="csl-entry">
Bartlett, Maurice S. 1937. <span>“The Statistical Conception of Mental Factors.”</span> <em>British Journal of Psychology</em> 28 (1): 97.
</div>
<div id="ref-johnson2007applied" class="csl-entry">
Johnson, Richard A, and Dean W Wichern. 2007. <em>Applied Multivariate Statistical Analysis. 6th</em>. <em>New Jersey, US: Pearson Prentice Hall</em>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rotación-de-factores.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliografía.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-iam.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsubsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
