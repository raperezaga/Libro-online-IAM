<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.9 Regiones de Confianza y Comparaciones Simultáneas entre las Componentes del Vector de Medias \(\underline{\boldsymbol \mu}\) | Chapter 10</title>
  <meta name="description" content="Este libro contine ……" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="4.9 Regiones de Confianza y Comparaciones Simultáneas entre las Componentes del Vector de Medias \(\underline{\boldsymbol \mu}\) | Chapter 10" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="/imagenes/imagen1.png" />
  <meta property="og:description" content="Este libro contine ……" />
  <meta name="github-repo" content="raperezaga/iam" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.9 Regiones de Confianza y Comparaciones Simultáneas entre las Componentes del Vector de Medias \(\underline{\boldsymbol \mu}\) | Chapter 10" />
  
  <meta name="twitter:description" content="Este libro contine ……" />
  <meta name="twitter:image" content="/imagenes/imagen1.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inferencia-para-la-matriz-de-varianzas-covarianza.html"/>
<link rel="next" href="mrlm.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preámbulo</a>
<ul>
<li class="chapter" data-level="" data-path="descripción.html"><a href="descripción.html"><i class="fa fa-check"></i>Descripción</a></li>
<li class="chapter" data-level="" data-path="acerca-del-autor.html"><a href="acerca-del-autor.html"><i class="fa fa-check"></i>Acerca del Autor</a></li>
<li class="chapter" data-level="" data-path="dedicación.html"><a href="dedicación.html"><i class="fa fa-check"></i>Dedicación</a></li>
<li class="chapter" data-level="" data-path="agradecimientos.html"><a href="agradecimientos.html"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="paquetes-usados-en-el-libro.html"><a href="paquetes-usados-en-el-libro.html"><i class="fa fa-check"></i>Paquetes usados en el libro</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="rep-al.html"><a href="rep-al.html"><i class="fa fa-check"></i><b>1</b> Repaso de álgebra lineal</a>
<ul>
<li class="chapter" data-level="1.1" data-path="acb-al.html"><a href="acb-al.html"><i class="fa fa-check"></i><b>1.1</b> Algunos conceptos básicos</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="acb-al.html"><a href="acb-al.html#matrices"><i class="fa fa-check"></i><b>1.1.1</b> Matrices</a></li>
<li class="chapter" data-level="1.1.2" data-path="acb-al.html"><a href="acb-al.html#vectores"><i class="fa fa-check"></i><b>1.1.2</b> Vectores</a></li>
<li class="chapter" data-level="1.1.3" data-path="acb-al.html"><a href="acb-al.html#operaciones-matrices"><i class="fa fa-check"></i><b>1.1.3</b> Operaciones Matriciales</a></li>
<li class="chapter" data-level="1.1.4" data-path="acb-al.html"><a href="acb-al.html#matrices-especiales"><i class="fa fa-check"></i><b>1.1.4</b> Matrices Especiales</a></li>
<li class="chapter" data-level="1.1.5" data-path="acb-al.html"><a href="acb-al.html#descomp-espectral"><i class="fa fa-check"></i><b>1.1.5</b> Descomposición Espectral de una Matriz (eigen-descomposición)</a></li>
<li class="chapter" data-level="1.1.6" data-path="acb-al.html"><a href="acb-al.html#diagonalización-de-una-matriz"><i class="fa fa-check"></i><b>1.1.6</b> Diagonalización de una Matriz</a></li>
<li class="chapter" data-level="1.1.7" data-path="acb-al.html"><a href="acb-al.html#diagonalización-ortogonal"><i class="fa fa-check"></i><b>1.1.7</b> Diagonalización Ortogonal</a></li>
<li class="chapter" data-level="1.1.8" data-path="acb-al.html"><a href="acb-al.html#diagonalizacion-inversa"><i class="fa fa-check"></i><b>1.1.8</b> Diagonalización de la Inversa de una Matriz</a></li>
<li class="chapter" data-level="1.1.9" data-path="acb-al.html"><a href="acb-al.html#diagonalización-de-la-matriz-raíz-cuadrada"><i class="fa fa-check"></i><b>1.1.9</b> Diagonalización de la Matriz Raíz Cuadrada</a></li>
<li class="chapter" data-level="1.1.10" data-path="acb-al.html"><a href="acb-al.html#traza-determinante-y-rango-de-una-matriz"><i class="fa fa-check"></i><b>1.1.10</b> Traza, Determinante y Rango de una Matriz</a></li>
<li class="chapter" data-level="1.1.11" data-path="acb-al.html"><a href="acb-al.html#formas-cuadraticas"><i class="fa fa-check"></i><b>1.1.11</b> Formas Cuadráticas</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="algunas-propiedades-estadísticas-de-la-descomposición-de-una-matriz-en-valores-y-vectores-propios.html"><a href="algunas-propiedades-estadísticas-de-la-descomposición-de-una-matriz-en-valores-y-vectores-propios.html"><i class="fa fa-check"></i><b>1.2</b> Algunas Propiedades Estadísticas de la Descomposición de una Matriz en Valores y Vectores Propios</a></li>
<li class="chapter" data-level="1.3" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html"><i class="fa fa-check"></i><b>1.3</b> Diferenciación con Vectores y Matrices</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="diferenc_vectores.html"><a href="diferenc_vectores.html#vector-gradiente-para-diferentes-definiciones-de-funderlinemathbfx"><i class="fa fa-check"></i><b>1.3.1</b> Vector-Gradiente para diferentes definiciones de <span class="math inline">\(f(\underline{\mathbf{x}})\)</span>:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="org_pres_dat.html"><a href="org_pres_dat.html"><i class="fa fa-check"></i><b>2</b> Organización y Presentación de Datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html"><i class="fa fa-check"></i><b>2.1</b> Resumenes Descriptivos</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#matriz-de-datos"><i class="fa fa-check"></i><b>2.1.1</b> Matriz de Datos</a></li>
<li class="chapter" data-level="2.1.2" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#estadísticos-descriptivos"><i class="fa fa-check"></i><b>2.1.2</b> Estadísticos descriptivos</a></li>
<li class="chapter" data-level="2.1.3" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#algunas-notaciones"><i class="fa fa-check"></i><b>2.1.3</b> Algunas Notaciones</a></li>
<li class="chapter" data-level="2.1.4" data-path="resumenes-descriptivos.html"><a href="resumenes-descriptivos.html#representación-gráfica-de-observaciones-multivariadas"><i class="fa fa-check"></i><b>2.1.4</b> Representación Gráfica de Observaciones multivariadas</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="vectores-y-matrices-aleatorias.html"><a href="vectores-y-matrices-aleatorias.html"><i class="fa fa-check"></i><b>2.2</b> Vectores y Matrices Aleatorias</a></li>
<li class="chapter" data-level="2.3" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html"><i class="fa fa-check"></i><b>2.3</b> Vectores y Matrices Poblacionales Particionados</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-del-vector-de-medias-poblacionales"><i class="fa fa-check"></i><b>2.3.1</b> Particionamiento del Vector de Medias-Poblacionales</a></li>
<li class="chapter" data-level="2.3.2" data-path="vectores-y-matrices-poblacionales-particionados.html"><a href="vectores-y-matrices-poblacionales-particionados.html#particionamiento-de-la-matriz-de-var-cov-poblacional-mathbfsigma"><i class="fa fa-check"></i><b>2.3.2</b> Particionamiento de la Matriz de Var-Cov Poblacional <span class="math inline">\(\mathbf{\Sigma}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.4</b> Propiedades Sobre la Media y Varianza de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.5" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html"><i class="fa fa-check"></i><b>2.5</b> Vectores y Matrices Muestrales Particionadas</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-del-vector-de-medias-muestrales"><i class="fa fa-check"></i><b>2.5.1</b> Particionamiento del Vector de Medias Muestrales</a></li>
<li class="chapter" data-level="2.5.2" data-path="vectores-y-matrices-muestrales-particionadas.html"><a href="vectores-y-matrices-muestrales-particionadas.html#particionamiento-de-la-matriz-de-var-cov-muestrales"><i class="fa fa-check"></i><b>2.5.2</b> Particionamiento de la Matriz de Var-Cov Muestrales</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="algunas-formas-matriciales-eficientes.html"><a href="algunas-formas-matriciales-eficientes.html"><i class="fa fa-check"></i><b>2.6</b> Algunas formas matriciales Eficientes</a></li>
<li class="chapter" data-level="2.7" data-path="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><a href="propiedades-sobre-la-media-y-varianza-muestral-de-combinaciones-lineales.html"><i class="fa fa-check"></i><b>2.7</b> Propiedades Sobre la Media y Varianza Muestral de Combinaciones Lineales</a></li>
<li class="chapter" data-level="2.8" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><i class="fa fa-check"></i><b>2.8</b> Varianza Generalizada Muestral y su Interpretación Geométrica</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-1-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.8.1</b> Interpretación Geométrica-1 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.8.2" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#interpretación-geométrica-2-de-la-varianza-generalizada"><i class="fa fa-check"></i><b>2.8.2</b> Interpretación Geométrica-2 de la Varianza Generalizada</a></li>
<li class="chapter" data-level="2.8.3" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#varianza-generalizada-determinada-por-la-matriz-de-correlación-muestral-mathbfr"><i class="fa fa-check"></i><b>2.8.3</b> Varianza Generalizada Determinada por la Matriz de Correlación Muestral <span class="math inline">\(\mathbf{R}\)</span></a></li>
<li class="chapter" data-level="2.8.4" data-path="varianza-generalizada-muestral-y-su-interpretación-geométrica.html"><a href="varianza-generalizada-muestral-y-su-interpretación-geométrica.html#relación-entre-mathbfs-y-mathbfr"><i class="fa fa-check"></i><b>2.8.4</b> Relación entre <span class="math inline">\(|\mathbf{S}|\)</span> y <span class="math inline">\(|\mathbf{R}|\)</span></a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="varianza-total-muestral.html"><a href="varianza-total-muestral.html"><i class="fa fa-check"></i><b>2.9</b> Varianza Total Muestral</a></li>
<li class="chapter" data-level="2.10" data-path="muestra-aleatoria-de-distribuciones-p-variadas.html"><a href="muestra-aleatoria-de-distribuciones-p-variadas.html"><i class="fa fa-check"></i><b>2.10</b> Muestra Aleatoria de Distribuciones <span class="math inline">\(p\)</span>-Variadas</a></li>
<li class="chapter" data-level="2.11" data-path="distancias.html"><a href="distancias.html"><i class="fa fa-check"></i><b>2.11</b> Distancias</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="distancias.html"><a href="distancias.html#dist_euclidea"><i class="fa fa-check"></i><b>2.11.1</b> Definición de Algunas Distancias</a></li>
<li class="chapter" data-level="2.11.2" data-path="distancias.html"><a href="distancias.html#relación-de-la-distancia-de-mahalanobis-con-la-distribución-chi-cuadrado"><i class="fa fa-check"></i><b>2.11.2</b> Relación de la Distancia de Mahalanobis con la Distribución chi-Cuadrado</a></li>
<li class="chapter" data-level="2.11.3" data-path="distancias.html"><a href="distancias.html#ejemplo"><i class="fa fa-check"></i><b>2.11.3</b> Ejemplo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="Normal-Multiv.html"><a href="Normal-Multiv.html"><i class="fa fa-check"></i><b>3</b> Distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.1" data-path="geometria-NM.html"><a href="geometria-NM.html"><i class="fa fa-check"></i><b>3.1</b> Geometría y propiedades de la NM</a></li>
<li class="chapter" data-level="3.2" data-path="normal-univariada.html"><a href="normal-univariada.html"><i class="fa fa-check"></i><b>3.2</b> Normal Univariada</a></li>
<li class="chapter" data-level="3.3" data-path="normal-multivariada.html"><a href="normal-multivariada.html"><i class="fa fa-check"></i><b>3.3</b> Normal Multivariada</a></li>
<li class="chapter" data-level="3.4" data-path="algunos-aspectos-geométricos-de-la-nm.html"><a href="algunos-aspectos-geométricos-de-la-nm.html"><i class="fa fa-check"></i><b>3.4</b> Algunos Aspectos Geométricos de la NM</a></li>
<li class="chapter" data-level="3.5" data-path="prop-nm.html"><a href="prop-nm.html"><i class="fa fa-check"></i><b>3.5</b> Propiedades de la distribución Normal Multivariada</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="prop-nm.html"><a href="prop-nm.html#prop1"><i class="fa fa-check"></i><b>3.5.1</b> <strong>Propiedad-1:</strong></a></li>
<li class="chapter" data-level="3.5.2" data-path="prop-nm.html"><a href="prop-nm.html#prop2"><i class="fa fa-check"></i><b>3.5.2</b> <strong>Propiedad-2:</strong></a></li>
<li class="chapter" data-level="3.5.3" data-path="prop-nm.html"><a href="prop-nm.html#prop3"><i class="fa fa-check"></i><b>3.5.3</b> <strong>Propiedad-3:</strong></a></li>
<li class="chapter" data-level="3.5.4" data-path="prop-nm.html"><a href="prop-nm.html#prop4"><i class="fa fa-check"></i><b>3.5.4</b> <strong>Propiedad-4:</strong></a></li>
<li class="chapter" data-level="3.5.5" data-path="prop-nm.html"><a href="prop-nm.html#prop5"><i class="fa fa-check"></i><b>3.5.5</b> <strong>Propiedad-5:</strong></a></li>
<li class="chapter" data-level="3.5.6" data-path="prop-nm.html"><a href="prop-nm.html#prop6"><i class="fa fa-check"></i><b>3.5.6</b> <strong>Propiedad-6:</strong></a></li>
<li class="chapter" data-level="3.5.7" data-path="prop-nm.html"><a href="prop-nm.html#prop7"><i class="fa fa-check"></i><b>3.5.7</b> <strong>Propiedad-7:</strong></a></li>
<li class="chapter" data-level="3.5.8" data-path="prop-nm.html"><a href="prop-nm.html#prop8"><i class="fa fa-check"></i><b>3.5.8</b> <strong>Propiedad-8:</strong></a></li>
<li class="chapter" data-level="3.5.9" data-path="prop-nm.html"><a href="prop-nm.html#prop9"><i class="fa fa-check"></i><b>3.5.9</b> <strong>Propiedad-9:</strong></a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.6</b> Evaluación del Supuesto de Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-a-nivel-marginal-ie.-normalidad-univariada"><i class="fa fa-check"></i><b>3.6.1</b> Evaluación a nivel marginal (ie. Normalidad Univariada)</a></li>
<li class="chapter" data-level="3.6.2" data-path="evaluación-del-supuesto-de-normalidad-multivariada.html"><a href="evaluación-del-supuesto-de-normalidad-multivariada.html#evaluación-de-la-normalidad-bi-variada"><i class="fa fa-check"></i><b>3.6.2</b> Evaluación de la Normalidad Bi-variada</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="detección-de-observaciones-atípicas.html"><a href="detección-de-observaciones-atípicas.html"><i class="fa fa-check"></i><b>3.7</b> Detección de Observaciones Atípicas</a></li>
<li class="chapter" data-level="3.8" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><i class="fa fa-check"></i><b>3.8</b> Transformaciones para Acercar a la Normalidad Multivariada</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#familia-de-transformaciones-de-potencia-de-box-y-cox-1964"><i class="fa fa-check"></i><b>3.8.1</b> Familia de Transformaciones de Potencia de Box y Cox (1964)</a></li>
<li class="chapter" data-level="3.8.2" data-path="transformaciones-para-acercar-a-la-normalidad-multivariada.html"><a href="transformaciones-para-acercar-a-la-normalidad-multivariada.html#transformaciones-para-el-caso-multivariado"><i class="fa fa-check"></i><b>3.8.2</b> Transformaciones para el Caso Multivariado:</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html"><i class="fa fa-check"></i><b>3.9</b> Muestra Aleatoria Normal <span class="math inline">\(p\)</span>-Variada</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#estimadores-de-máx-ver-de-una-normal-multivariada"><i class="fa fa-check"></i><b>3.9.1</b> Estimadores de Máx-Ver de una Normal-Multivariada</a></li>
<li class="chapter" data-level="3.9.2" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#distribución-muestral-de-overlineunderlinemathbfx-y-mathbfs_n"><i class="fa fa-check"></i><b>3.9.2</b> Distribución Muestral de <span class="math inline">\(\overline{\underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\mathbf{S}_n\)</span></a></li>
<li class="chapter" data-level="3.9.3" data-path="muestra-aleatoria-normal-p-variada.html"><a href="muestra-aleatoria-normal-p-variada.html#comportamiento-de-underlineoverlinemathbfx_p-y-mathbfs-para-tamaños-muestrales-grandes"><i class="fa fa-check"></i><b>3.9.3</b> Comportamiento de <span class="math inline">\(\underline{\overline{\mathbf{x}}}_p\)</span> y <span class="math inline">\(\mathbf{S}\)</span> para Tamaños Muestrales Grandes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferen-estad.html"><a href="inferen-estad.html"><i class="fa fa-check"></i><b>4</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="4.1" data-path="introducción.html"><a href="introducción.html"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="inferencia-estadística-para-la-media-mu-caso-univariado.html"><a href="inferencia-estadística-para-la-media-mu-caso-univariado.html"><i class="fa fa-check"></i><b>4.2</b> Inferencia Estadística para la Media (<span class="math inline">\(\mu\)</span>)-caso univariado</a></li>
<li class="chapter" data-level="4.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><i class="fa fa-check"></i><b>4.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span></a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-desconocida-normal"><i class="fa fa-check"></i><b>4.3.1</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Desconocida (Normal)</a></li>
<li class="chapter" data-level="4.3.2" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-cuando-mathbfsigma-es-conocida-población-normal"><i class="fa fa-check"></i><b>4.3.2</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> cuando <span class="math inline">\(\mathbf{\Sigma}\)</span> es Conocida (Población: Normal)</a></li>
<li class="chapter" data-level="4.3.3" data-path="pruebas-de-hipótesis-para-underlineboldsymbolmu.html"><a href="pruebas-de-hipótesis-para-underlineboldsymbolmu.html#pruebas-de-hipótesis-para-underlineboldsymbolmu-en-muestra-grande"><i class="fa fa-check"></i><b>4.3.3</b> Pruebas de Hipótesis para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> en Muestra Grande</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><i class="fa fa-check"></i><b>4.4</b> PH Acerca de Contrastes del Vector de Medias Poblacional <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>, de una <span class="math inline">\(N_p(\underline{\boldsymbol{\mu}} \ , \ \mathbf{\Sigma} )\)</span></a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html#ph-de-contrastes-para-el-caso-de-pnm"><i class="fa fa-check"></i><b>4.4.1</b> PH de Contrastes para el Caso de PNM</a></li>
<li class="chapter" data-level="4.4.2" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html#ph-de-contrastes-en-en-caso-de-n-grande"><i class="fa fa-check"></i><b>4.4.2</b> PH de Contrastes en en caso de <span class="math inline">\(n\)</span>-Grande</a></li>
<li class="chapter" data-level="4.4.3" data-path="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html"><a href="ph-acerca-de-contrastes-del-vector-de-medias-poblacional-underlineboldsymbolmu-de-una-n_punderlineboldsymbolmu-mathbfsigma.html#prueba-de-hipótesis-para-igualdad-de-medias"><i class="fa fa-check"></i><b>4.4.3</b> Prueba de hipótesis para igualdad de medias</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><i class="fa fa-check"></i><b>4.5</b> PH para Igualdad de Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{x}}}=\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{y}}}\)</span></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html#caso-1.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-conocida"><i class="fa fa-check"></i><b>4.5.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.5.2" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html#caso-2.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-desconocida"><i class="fa fa-check"></i><b>4.5.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.5.3" data-path="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html"><a href="ph-para-igualdad-de-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfxunderlineboldsymbolmu_-underlinemathbfy.html#caso-3.-mathbfsigma_-underlinemathbfxneq-mathbfsigma_-underlinemathbfy-desconocida"><i class="fa fa-check"></i><b>4.5.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}\neq \mathbf{\Sigma}_{\ \underline{\mathbf{y}}}\)</span>-Desconocida</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><i class="fa fa-check"></i><b>4.6</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{y}}}\)</span>,   para muestras grandes</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html#caso-1.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-conocida-1"><i class="fa fa-check"></i><b>4.6.1</b> Caso-1. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Conocida</a></li>
<li class="chapter" data-level="4.6.2" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html#caso-2.-mathbfsigma_-underlinemathbfxmathbfsigma_-underlinemathbfymathbfsigma-desconocida-1"><i class="fa fa-check"></i><b>4.6.2</b> Caso-2. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}}=\mathbf{\Sigma}_{\ \underline{\mathbf{y}}}=\mathbf{\Sigma}\)</span>-Desconocida</a></li>
<li class="chapter" data-level="4.6.3" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-para-muestras-grandes.html#caso-3.-mathbfsigma_-underlinemathbfx-neq-mathbfsigma_-underlinemathbfy-desconocidas"><i class="fa fa-check"></i><b>4.6.3</b> Caso-3. <span class="math inline">\(\mathbf{\Sigma}_{\ \underline{\mathbf{x}}} \neq \mathbf{\Sigma}_{\ \underline{\mathbf{y}}}\)</span>-Desconocidas</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><i class="fa fa-check"></i><b>4.7</b> Pruebas de Hipótesis Acerca de dos Vectores de Medias Poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{x}}}\)</span> y <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ \underline{\mathbf{y}}}\)</span>,      Observaciones Pareadas</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#caso-univariado"><i class="fa fa-check"></i><b>4.7.1</b> Caso Univariado</a></li>
<li class="chapter" data-level="4.7.2" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#caso-multivariado"><i class="fa fa-check"></i><b>4.7.2</b> Caso Multivariado</a></li>
<li class="chapter" data-level="4.7.3" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#uso-de-contrastes-para-la-comparación-de-medias-en-muestras-pareadas"><i class="fa fa-check"></i><b>4.7.3</b> Uso de Contrastes para la Comparación de Medias en Muestras Pareadas</a></li>
<li class="chapter" data-level="4.7.4" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#un-diseño-de-medidas-repetidas-para-comparar-tratamientos"><i class="fa fa-check"></i><b>4.7.4</b> Un Diseño de Medidas Repetidas para Comparar Tratamientos</a></li>
<li class="chapter" data-level="4.7.5" data-path="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html"><a href="pruebas-de-hipótesis-acerca-de-dos-vectores-de-medias-poblacionales-underlineboldsymbolmu_-underlinemathbfx-y-underlineboldsymbolmu_-underlinemathbfy-observaciones-pareadas.html#análisis-de-perfiles"><i class="fa fa-check"></i><b>4.7.5</b> Análisis de Perfiles</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html"><i class="fa fa-check"></i><b>4.8</b> Inferencia para la Matriz de Varianzas Covarianza</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#prueva-de-rv-sigma"><i class="fa fa-check"></i><b>4.8.1</b> Pruba de Razón de Verosimilitud</a></li>
<li class="chapter" data-level="4.8.2" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#prueba-de-bartlet"><i class="fa fa-check"></i><b>4.8.2</b> Prueba de Bartlet</a></li>
<li class="chapter" data-level="4.8.3" data-path="inferencia-para-la-matriz-de-varianzas-covarianza.html"><a href="inferencia-para-la-matriz-de-varianzas-covarianza.html#dos-o-más-matrices-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.3</b> Dos o más Matrices de Varianzas Covarianzas</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><i class="fa fa-check"></i><b>4.9</b> Regiones de Confianza y Comparaciones Simultáneas entre las Componentes del Vector de Medias <span class="math inline">\(\underline{\boldsymbol \mu}\)</span></a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#construcción-de-una-región-de-confianza-para-underlineboldsymbol-mu-cuando-la-población-tiene-distribución-n_punderlineboldsymbol-mumathbfsigma-con-underlineboldsymbol-mu-y-mathbfsigma-desconocidos"><i class="fa fa-check"></i><b>4.9.1</b> Construcción de una Región de Confianza para <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> Cuando la Población tiene Distribución <span class="math inline">\(N_p(\underline{\boldsymbol \mu},\mathbf{\Sigma})\)</span>, con <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> y <span class="math inline">\(\mathbf{\Sigma}\)</span> desconocidos</a></li>
<li class="chapter" data-level="4.9.2" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#región-de-confianza-para-el-caso-de-p2-elipse-de-confianza"><i class="fa fa-check"></i><b>4.9.2</b> Región de Confianza para el Caso de <span class="math inline">\(p=2\)</span> (Elipse de Confianza)</a></li>
<li class="chapter" data-level="4.9.3" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#intervalos-de-confianza-simultáneos-para-las-componentes-del-vector-de-medias-underlineboldsymbol-mu"><i class="fa fa-check"></i><b>4.9.3</b> Intervalos de Confianza Simultáneos para las Componentes del Vector de Medias <span class="math inline">\(\underline{\boldsymbol \mu}\)</span></a></li>
<li class="chapter" data-level="4.9.4" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#ic-t2-simultáneos-para-diferencias-de-medias"><i class="fa fa-check"></i><b>4.9.4</b> IC <span class="math inline">\(T^2\)</span> Simultáneos para Diferencias de Medias</a></li>
<li class="chapter" data-level="4.9.5" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#IC-Bonferroni"><i class="fa fa-check"></i><b>4.9.5</b> Método de Bonferroni para Comparaciones Múltiples</a></li>
<li class="chapter" data-level="4.9.6" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#intervalos-de-confianza-simultáneos-chi2-caso-n-grande"><i class="fa fa-check"></i><b>4.9.6</b> Intervalos de Confianza Simultáneos <span class="math inline">\(\chi^2\)</span> (caso n-Grande)</a></li>
<li class="chapter" data-level="4.9.7" data-path="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html"><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#ic-simultáneos-para-n-grande-usando-la-normal-estándar-z_alpha"><i class="fa fa-check"></i><b>4.9.7</b> IC Simultáneos para n-Grande Usando la Normal Estándar <span class="math inline">\(Z_\alpha\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="mrlm.html"><a href="mrlm.html"><i class="fa fa-check"></i><b>5</b> Modelos de Regresión Lineal Multivariados</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introducción-2.html"><a href="introducción-2.html"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="rlm.html"><a href="rlm.html"><i class="fa fa-check"></i><b>5.2</b> Modelo de Regresión Lineal Múltiple (RLM)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="rlm.html"><a href="rlm.html#estimación-de-mínimos-cuadrados"><i class="fa fa-check"></i><b>5.2.1</b> Estimación de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="5.2.2" data-path="rlm.html"><a href="rlm.html#inferencias-acerca-del-modelo-de-regresión-lineal-múltiple"><i class="fa fa-check"></i><b>5.2.2</b> Inferencias Acerca del Modelo de Regresión Lineal Múltiple</a></li>
<li class="chapter" data-level="5.2.3" data-path="rlm.html"><a href="rlm.html#inferencias-a-partir-de-la-función-de-regresión-estimada"><i class="fa fa-check"></i><b>5.2.3</b> Inferencias A partir de la Función de Regresión Estimada</a></li>
<li class="chapter" data-level="5.2.4" data-path="rlm.html"><a href="rlm.html#validación-de-los-supuestos-del-modelo-y-otros-aspectos-del-la-regresión"><i class="fa fa-check"></i><b>5.2.4</b> Validación de los Supuestos del Modelo y Otros Aspectos del la Regresión</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="mrl-multiv.html"><a href="mrl-multiv.html"><i class="fa fa-check"></i><b>5.3</b> Modelo de Regresión Lineal Multivariado (RL-Multivariado)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="mrl-multiv.html"><a href="mrl-multiv.html#algunas-notaciones-1"><i class="fa fa-check"></i><b>5.3.1</b> Algunas Notaciones</a></li>
<li class="chapter" data-level="5.3.2" data-path="mrl-multiv.html"><a href="mrl-multiv.html#mrl-multivariado-en-forma-matricial"><i class="fa fa-check"></i><b>5.3.2</b> MRL-Multivariado en forma Matricial</a></li>
<li class="chapter" data-level="5.3.3" data-path="mrl-multiv.html"><a href="mrl-multiv.html#m-mrl-múltiples"><i class="fa fa-check"></i><b>5.3.3</b> <span class="math inline">\(m\)</span>-MRL-Múltiples</a></li>
<li class="chapter" data-level="5.3.4" data-path="mrl-multiv.html"><a href="mrl-multiv.html#estimador-de-mínimos-cuadrados-de-los-parámetros"><i class="fa fa-check"></i><b>5.3.4</b> Estimador de Mínimos Cuadrados de los Parámetros</a></li>
<li class="chapter" data-level="5.3.5" data-path="mrl-multiv.html"><a href="mrl-multiv.html#propiedades-de-estimadores-de-mínimos-cuadrados-del-mrl-multivariado"><i class="fa fa-check"></i><b>5.3.5</b> Propiedades de Estimadores de Mínimos Cuadrados del MRL-Multivariado</a></li>
<li class="chapter" data-level="5.3.6" data-path="mrl-multiv.html"><a href="mrl-multiv.html#prv-mrl-multivariado"><i class="fa fa-check"></i><b>5.3.6</b> Prueba de Razón de Verosimilitud para Parámetros de Regresión en MRL-Multivariados</a></li>
<li class="chapter" data-level="5.3.7" data-path="mrl-multiv.html"><a href="mrl-multiv.html#otras-pruebas-estadísticas-multivariadas"><i class="fa fa-check"></i><b>5.3.7</b> Otras Pruebas Estadísticas Multivariadas</a></li>
<li class="chapter" data-level="5.3.8" data-path="mrl-multiv.html"><a href="mrl-multiv.html#predicciones-a-partir-de-un-modelo-de-regresión-múltiple-multivariado"><i class="fa fa-check"></i><b>5.3.8</b> Predicciones A Partir de un Modelo de Regresión Múltiple Multivariado</a></li>
<li class="chapter" data-level="5.3.9" data-path="mrl-multiv.html"><a href="mrl-multiv.html#el-concepto-de-regresión-lineal"><i class="fa fa-check"></i><b>5.3.9</b> El Concepto de Regresión Lineal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ACP.html"><a href="ACP.html"><i class="fa fa-check"></i><b>6</b> Análisis de Componentes Principales (ACP)</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducción-3.html"><a href="introducción-3.html"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="interpretaciones-geométricas-y-algebraícas-del-acp.html"><a href="interpretaciones-geométricas-y-algebraícas-del-acp.html"><i class="fa fa-check"></i><b>6.2</b> Interpretaciones Geométricas y Algebraícas del ACP</a></li>
<li class="chapter" data-level="6.3" data-path="interpretación-geométrica-del-acp-mediante-un-ejemplo-simple-p2.html"><a href="interpretación-geométrica-del-acp-mediante-un-ejemplo-simple-p2.html"><i class="fa fa-check"></i><b>6.3</b> Interpretación Geométrica del ACP Mediante un Ejemplo Simple <span class="math inline">\(p=2\)</span></a></li>
<li class="chapter" data-level="6.4" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html"><i class="fa fa-check"></i><b>6.4</b> Mas de dos Ejes</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#min-cuadrados"><i class="fa fa-check"></i><b>6.4.1</b> Ajuste de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="6.4.2" data-path="mas-de-dos-ejes.html"><a href="mas-de-dos-ejes.html#relación-entre-los-sub-espacios-de-mathbbrp-y-de-mathbbrn"><i class="fa fa-check"></i><b>6.4.2</b> Relación entre los Sub-espacios de <span class="math inline">\(\mathbb{R}^p\)</span> y de <span class="math inline">\(\mathbb{R}^n\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="componentes-principales-en-análisis-de-regresión.html"><a href="componentes-principales-en-análisis-de-regresión.html"><i class="fa fa-check"></i><b>6.5</b> Componentes Principales en Análisis de Regresión</a></li>
<li class="chapter" data-level="6.6" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html"><i class="fa fa-check"></i><b>6.6</b> Componentes Principales Poblacionales</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#definicón-de-las-cps-poblacionales"><i class="fa fa-check"></i><b>6.6.1</b> Definicón de las CPs Poblacionales</a></li>
<li class="chapter" data-level="6.6.2" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#determinación-de-las-cps-poblacionales"><i class="fa fa-check"></i><b>6.6.2</b> Determinación de las CPs Poblacionales</a></li>
<li class="chapter" data-level="6.6.3" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-derivadas-de-una-normal-multivariada"><i class="fa fa-check"></i><b>6.6.3</b> Componentes Principales Derivadas de una Normal Multivariada</a></li>
<li class="chapter" data-level="6.6.4" data-path="componentes-principales-poblacionales.html"><a href="componentes-principales-poblacionales.html#componentes-principales-usando-variables-estandarizadas"><i class="fa fa-check"></i><b>6.6.4</b> Componentes Principales usando Variables Estandarizadas</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><i class="fa fa-check"></i><b>6.7</b> Componentes Principales para Matrices de Var-Cov <span class="math inline">\(\mathbf{\Sigma}\)</span> con Estructuras Especiales</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#variables-no-correlacionadas"><i class="fa fa-check"></i><b>6.7.1</b> Variables No-Correlacionadas</a></li>
<li class="chapter" data-level="6.7.2" data-path="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html"><a href="componentes-principales-para-matrices-de-var-cov-mathbfsigma-con-estructuras-especiales.html#var-correlacionadas"><i class="fa fa-check"></i><b>6.7.2</b> Variables Altamente Correlacionadas</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="componentes-principales-muestrales.html"><a href="componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>6.8</b> Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="6.9" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html"><i class="fa fa-check"></i><b>6.9</b> Algunos Ejemplos de ACP</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo1"><i class="fa fa-check"></i><b>6.9.1</b> Ejemplo-1</a></li>
<li class="chapter" data-level="6.9.2" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo-2"><i class="fa fa-check"></i><b>6.9.2</b> Ejemplo-2</a></li>
<li class="chapter" data-level="6.9.3" data-path="algunos-ejemplos-de-acp.html"><a href="algunos-ejemplos-de-acp.html#ejemplo-3"><i class="fa fa-check"></i><b>6.9.3</b> Ejemplo-3</a></li>
</ul></li>
<li class="chapter" data-level="6.10" data-path="cómo-elegir-el-número-de-componentes-principales.html"><a href="cómo-elegir-el-número-de-componentes-principales.html"><i class="fa fa-check"></i><b>6.10</b> Cómo elegir el número de Componentes Principales?</a></li>
<li class="chapter" data-level="6.11" data-path="interpretación-de-las-componentes-principales-muestrales.html"><a href="interpretación-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>6.11</b> Interpretación de las Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="6.12" data-path="estandarización-de-las-componentes-principales-muestrales.html"><a href="estandarización-de-las-componentes-principales-muestrales.html"><i class="fa fa-check"></i><b>6.12</b> Estandarización de las Componentes Principales Muestrales</a></li>
<li class="chapter" data-level="6.13" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html"><i class="fa fa-check"></i><b>6.13</b> Gráficas en un Análisis de Componentes Principales</a>
<ul>
<li class="chapter" data-level="6.13.1" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html#graficos-de-las-cps"><i class="fa fa-check"></i><b>6.13.1</b> Graficos de las CPS</a></li>
<li class="chapter" data-level="6.13.2" data-path="gráficas-en-un-análisis-de-componentes-principales.html"><a href="gráficas-en-un-análisis-de-componentes-principales.html#el-gráfico-biplot"><i class="fa fa-check"></i><b>6.13.2</b> El gráfico biplot:</a></li>
</ul></li>
<li class="chapter" data-level="6.14" data-path="propiedades-de-hatlambda_i-y-underlinehatmathbfe_i-en-muestras-grandes.html"><a href="propiedades-de-hatlambda_i-y-underlinehatmathbfe_i-en-muestras-grandes.html"><i class="fa fa-check"></i><b>6.14</b> Propiedades de <span class="math inline">\(\hat{\lambda}_i\)</span> y <span class="math inline">\(\underline{\hat{\mathbf{e}}}_i\)</span> en Muestras Grandes</a></li>
<li class="chapter" data-level="6.15" data-path="prueba-de-hipótesis-para-estructura-de-correlación-igual.html"><a href="prueba-de-hipótesis-para-estructura-de-correlación-igual.html"><i class="fa fa-check"></i><b>6.15</b> Prueba de Hipótesis para Estructura de Correlación Igual</a></li>
<li class="chapter" data-level="6.16" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html"><i class="fa fa-check"></i><b>6.16</b> Ejemplos Finales</a>
<ul>
<li class="chapter" data-level="6.16.1" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-1"><i class="fa fa-check"></i><b>6.16.1</b> Ejemplo-1</a></li>
<li class="chapter" data-level="6.16.2" data-path="ejemplos-finales.html"><a href="ejemplos-finales.html#ejemplo-acp-con-individuos-y-variables-suplementarias"><i class="fa fa-check"></i><b>6.16.2</b> Ejemplo ACP con Individuos y Variables Suplementarias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="affc.html"><a href="affc.html"><i class="fa fa-check"></i><b>7</b> Análisis Factorial de Factores Comunes</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introducción-4.html"><a href="introducción-4.html"><i class="fa fa-check"></i><b>7.1</b> Introducción</a></li>
<li class="chapter" data-level="7.2" data-path="tipos-de-factores.html"><a href="tipos-de-factores.html"><i class="fa fa-check"></i><b>7.2</b> Tipos de Factores</a></li>
<li class="chapter" data-level="7.3" data-path="motivación-del-análisis-factorial.html"><a href="motivación-del-análisis-factorial.html"><i class="fa fa-check"></i><b>7.3</b> Motivación del Análisis Factorial</a></li>
<li class="chapter" data-level="7.4" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html"><i class="fa fa-check"></i><b>7.4</b> Enfoques del AF</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#métodos-para-realizar-la-extracción-de-los-factores"><i class="fa fa-check"></i><b>7.4.1</b> Métodos para realizar la extracción de los factores</a></li>
<li class="chapter" data-level="7.4.2" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#rotación-de-ejes"><i class="fa fa-check"></i><b>7.4.2</b> Rotación de Ejes</a></li>
<li class="chapter" data-level="7.4.3" data-path="enfoques-del-af.html"><a href="enfoques-del-af.html#puntuaciones-o-scores-de-los-sujetos-en-los-factores-extraídos"><i class="fa fa-check"></i><b>7.4.3</b> Puntuaciones o Scores de los Sujetos en los Factores Extraídos</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html"><i class="fa fa-check"></i><b>7.5</b> El Modelo de Factor Ortogonal</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html#estructura-de-covarianzas-del-modelo-de-factor-ortogonal"><i class="fa fa-check"></i><b>7.5.1</b> Estructura de Covarianzas del Modelo de Factor Ortogonal</a></li>
<li class="chapter" data-level="7.5.2" data-path="el-modelo-de-factor-ortogonal.html"><a href="el-modelo-de-factor-ortogonal.html#ejemplos"><i class="fa fa-check"></i><b>7.5.2</b> Ejemplos</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html"><i class="fa fa-check"></i><b>7.6</b> Métodos de Estimación</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#metodo-cp"><i class="fa fa-check"></i><b>7.6.1</b> El Método de la Componente Principal</a></li>
<li class="chapter" data-level="7.6.2" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#metodo-pa"><i class="fa fa-check"></i><b>7.6.2</b> Una Aproximación Modificada (La Solución del Factor Principal o de las CP-Iteradas o de Ejes Principales-PA)</a></li>
<li class="chapter" data-level="7.6.3" data-path="métodos-de-estimación.html"><a href="métodos-de-estimación.html#metodo-mle"><i class="fa fa-check"></i><b>7.6.3</b> El Método de Máxima Verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="prueba-para-el-número-de-factores-muestra-grande..html"><a href="prueba-para-el-número-de-factores-muestra-grande..html"><i class="fa fa-check"></i><b>7.7</b> Prueba para el Número de Factores (Muestra Grande).</a></li>
<li class="chapter" data-level="7.8" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html"><i class="fa fa-check"></i><b>7.8</b> Rotación de Factores</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#rotaciones-cuando-m2-factores"><i class="fa fa-check"></i><b>7.8.1</b> Rotaciones cuando <span class="math inline">\(m=2\)</span>-Factores</a></li>
<li class="chapter" data-level="7.8.2" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#criterio-varimáx"><i class="fa fa-check"></i><b>7.8.2</b> Criterio Varimáx:</a></li>
<li class="chapter" data-level="7.8.3" data-path="rotación-de-factores.html"><a href="rotación-de-factores.html#rotaciones-oblicuas"><i class="fa fa-check"></i><b>7.8.3</b> Rotaciones Oblicuas</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="factores-scores-o-puntuaciones-de-los-factores.html"><a href="factores-scores-o-puntuaciones-de-los-factores.html"><i class="fa fa-check"></i><b>7.9</b> Factores-Scores (o Puntuaciones) de los Factores</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="factores-scores-o-puntuaciones-de-los-factores.html"><a href="factores-scores-o-puntuaciones-de-los-factores.html#método-de-los-mínimos-cuadrados-ponderados"><i class="fa fa-check"></i><b>7.9.1</b> Método de los Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="7.9.2" data-path="factores-scores-o-puntuaciones-de-los-factores.html"><a href="factores-scores-o-puntuaciones-de-los-factores.html#el-método-de-la-regresión"><i class="fa fa-check"></i><b>7.9.2</b> El Método de la Regresión</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="perspectivas-y-estrategías-para-el-análisis-de-factor.html"><a href="perspectivas-y-estrategías-para-el-análisis-de-factor.html"><i class="fa fa-check"></i><b>7.10</b> Perspectivas y Estrategías para el Análisis de Factor</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="avm.html"><a href="avm.html"><i class="fa fa-check"></i><b>8</b> Análisis de Varianza Multivariado (MANOVA)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="introducción-5.html"><a href="introducción-5.html"><i class="fa fa-check"></i><b>8.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="introducción-5.html"><a href="introducción-5.html#suposiciones-del-manova"><i class="fa fa-check"></i><b>8.1.1</b> Suposiciones del MANOVA</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>8.2</b> Análisis de Varianza Univariado (ANOVA)</a></li>
<li class="chapter" data-level="8.3" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>8.3</b> Análisis de Varianza Multivariado (MANOVA)</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="manova.html"><a href="manova.html#modelo-manova-para-comparar-g-vectores-de-medias-poblacionales"><i class="fa fa-check"></i><b>8.3.1</b> Modelo MANOVA para comparar <span class="math inline">\(g\)</span>-Vectores de Medias Poblacionales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="adiscriminante.html"><a href="adiscriminante.html"><i class="fa fa-check"></i><b>9</b> Análisis Discriminante y Clasificación</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introducción-6.html"><a href="introducción-6.html"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html"><a href="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.2</b> Separación y Clasificación para el caso de dos poblaciones</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html"><a href="separación-y-clasificación-para-el-caso-de-dos-poblaciones.html#clasificación-de-dos-poblaciones"><i class="fa fa-check"></i><b>9.2.1</b> Clasificación de dos Poblaciones</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.3</b> Regla de Discriminación para dos Poblaciones</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html#costo-esperado-de-mal-clasificación"><i class="fa fa-check"></i><b>9.3.1</b> Costo Esperado de Mal Clasificación</a></li>
<li class="chapter" data-level="9.3.2" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html#probabilidad-total-de-mal-clasificación"><i class="fa fa-check"></i><b>9.3.2</b> Probabilidad Total de Mal Clasificación</a></li>
<li class="chapter" data-level="9.3.3" data-path="regla-de-discriminación-para-dos-poblaciones.html"><a href="regla-de-discriminación-para-dos-poblaciones.html#regla-de-clasificación-de-bayes"><i class="fa fa-check"></i><b>9.3.3</b> Regla de Clasificación de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="dos-pob-nm.html"><a href="dos-pob-nm.html"><i class="fa fa-check"></i><b>9.4</b> Clasificación con Dos Poblaciones Normales Multivariadas</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="dos-pob-nm.html"><a href="dos-pob-nm.html#clasificación-con-dos-poblaciones-normales-donde-mathbfsigma_1mathbfsigma_2mathbfsigma"><i class="fa fa-check"></i><b>9.4.1</b> Clasificación con dos Poblaciones Normales donde <span class="math inline">\(\mathbf{\Sigma}_1=\mathbf{\Sigma}_2=\mathbf{\Sigma}\)</span></a></li>
<li class="chapter" data-level="9.4.2" data-path="dos-pob-nm.html"><a href="dos-pob-nm.html#clasificación-con-dos-poblaciones-normales-donde-mathbfsigma_1neq-mathbfsigma_2"><i class="fa fa-check"></i><b>9.4.2</b> Clasificación con dos Poblaciones Normales donde <span class="math inline">\(\mathbf{\Sigma}_1\neq \mathbf{\Sigma}_2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html"><i class="fa fa-check"></i><b>9.5</b> Evaluación de las Funciones de Clasificación</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-óptimo-teo"><i class="fa fa-check"></i><b>9.5.1</b> Tasa de Error Óptimo (TEO)</a></li>
<li class="chapter" data-level="9.5.2" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-actual"><i class="fa fa-check"></i><b>9.5.2</b> Tasa de Error Actual</a></li>
<li class="chapter" data-level="9.5.3" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-aparente-teap"><i class="fa fa-check"></i><b>9.5.3</b> Tasa de Error Aparente (TEAP)</a></li>
<li class="chapter" data-level="9.5.4" data-path="evaluación-de-las-funciones-de-clasificación.html"><a href="evaluación-de-las-funciones-de-clasificación.html#tasa-de-error-actual-esperada"><i class="fa fa-check"></i><b>9.5.4</b> Tasa de Error Actual Esperada</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html"><a href="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.6</b> Clasificación con Varias Poblaciones (Es decir Más de dos Poblaciones)</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html"><a href="clasificación-con-varias-poblaciones-es-decir-más-de-dos-poblaciones.html#costo-esperado-de-mal-clasificación-ecm"><i class="fa fa-check"></i><b>9.6.1</b> Costo Esperado de Mal Clasificación (ECM)</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><i class="fa fa-check"></i><b>9.7</b> Clasificación con Poblaciones Normales y más de dos Poblaciones</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html#un-clasificador-equivalente-para-el-caso-de-matrices-de-var-cov-iguales"><i class="fa fa-check"></i><b>9.7.1</b> Un Clasificador Equivalente para el Caso de Matrices de Var-Cov Iguales</a></li>
<li class="chapter" data-level="9.7.2" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html#comparación-dos-a-dos-de-los-scores-de-la-función-de-clasificación-lineal"><i class="fa fa-check"></i><b>9.7.2</b> Comparación Dos a Dos de los Scores de la Función de Clasificación Lineal</a></li>
<li class="chapter" data-level="9.7.3" data-path="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html"><a href="clasificación-con-poblaciones-normales-y-más-de-dos-poblaciones.html#tasa-de-error-actual-esperada-aer-estimada"><i class="fa fa-check"></i><b>9.7.3</b> Tasa de Error Actual Esperada (AER) Estimada</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><i class="fa fa-check"></i><b>9.8</b> Método de Fisher Para Discriminar Entre Varias Poblaciones</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html#uso-de-la-función-de-discriminación-de-fisher-para-clasificación"><i class="fa fa-check"></i><b>9.8.1</b> Uso de la Función de Discriminación de Fisher Para Clasificación</a></li>
<li class="chapter" data-level="9.8.2" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html#relación-entre-la-regla-de-clasificación-de-fisher-y-las-funciones-de-discriminación-de-la-teoría-normal"><i class="fa fa-check"></i><b>9.8.2</b> Relación entre la Regla de Clasificación de Fisher y las Funciones de Discriminación de la Teoría Normal</a></li>
<li class="chapter" data-level="9.8.3" data-path="método-de-fisher-para-discriminar-entre-varias-poblaciones.html"><a href="método-de-fisher-para-discriminar-entre-varias-poblaciones.html#regla-de-clasificación-de-fisher-basado-en-discriminantes-muestrales"><i class="fa fa-check"></i><b>9.8.3</b> Regla de Clasificación de Fisher Basado en Discriminantes Muestrales</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html"><i class="fa fa-check"></i><b>9.9</b> Regresión Logística y Clasificación</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#el-modelo-logit"><i class="fa fa-check"></i><b>9.9.1</b> El Modelo Logit</a></li>
<li class="chapter" data-level="9.9.2" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#análisis-de-regresión-logística"><i class="fa fa-check"></i><b>9.9.2</b> Análisis de Regresión Logística</a></li>
<li class="chapter" data-level="9.9.3" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#regresión-logística-con-respuestas-binomiales"><i class="fa fa-check"></i><b>9.9.3</b> Regresión Logística con Respuestas Binomiales</a></li>
<li class="chapter" data-level="9.9.4" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#chequeo-del-modelo"><i class="fa fa-check"></i><b>9.9.4</b> Chequeo del Modelo</a></li>
<li class="chapter" data-level="9.9.5" data-path="regresión-logística-y-clasificación.html"><a href="regresión-logística-y-clasificación.html#prueba-de-residuales-y-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>9.9.5</b> Prueba de Residuales y de Bondad de Ajuste</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="acluster.html"><a href="acluster.html"><i class="fa fa-check"></i><b>10</b> Análisis de Agrupamiento o Cluster</a>
<ul>
<li class="chapter" data-level="10.1" data-path="introducción-7.html"><a href="introducción-7.html"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="consideraciones-iniciales.html"><a href="consideraciones-iniciales.html"><i class="fa fa-check"></i><b>10.2</b> Consideraciones Iniciales</a></li>
<li class="chapter" data-level="10.3" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html"><i class="fa fa-check"></i><b>10.3</b> Medidas de Similaridad entre Pares de Observaciones</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html#medidas-de-distancia"><i class="fa fa-check"></i><b>10.3.1</b> Medidas de Distancia</a></li>
<li class="chapter" data-level="10.3.2" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html#coeficientes-de-correlación-entre-casos"><i class="fa fa-check"></i><b>10.3.2</b> Coeficientes de Correlación (entre casos)</a></li>
<li class="chapter" data-level="10.3.3" data-path="medidas-de-similaridad-entre-pares-de-observaciones.html"><a href="medidas-de-similaridad-entre-pares-de-observaciones.html#coeficientes-binarios-de-asociación-o-similaridad-entre-observaciones"><i class="fa fa-check"></i><b>10.3.3</b> Coeficientes Binarios de Asociación o Similaridad Entre Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="medidas-de-similaridad-o-asociación-para-pares-de-variables.html"><a href="medidas-de-similaridad-o-asociación-para-pares-de-variables.html"><i class="fa fa-check"></i><b>10.4</b> Medidas de Similaridad o Asociación para Pares de Variables</a></li>
<li class="chapter" data-level="10.5" data-path="métodos-jerárquicos-de-agrupamiento.html"><a href="métodos-jerárquicos-de-agrupamiento.html"><i class="fa fa-check"></i><b>10.5</b> Métodos Jerárquicos de Agrupamiento</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="métodos-jerárquicos-de-agrupamiento.html"><a href="métodos-jerárquicos-de-agrupamiento.html#métodos-jerarquicos-de-enlaces-para-agupamientos-aglomerativos"><i class="fa fa-check"></i><b>10.5.1</b> Métodos Jerarquicos de Enlaces para Agupamientos Aglomerativos</a></li>
<li class="chapter" data-level="10.5.2" data-path="métodos-jerárquicos-de-agrupamiento.html"><a href="métodos-jerárquicos-de-agrupamiento.html#métodos-jerarquicos-de-agrupamientos-desaglomerativos"><i class="fa fa-check"></i><b>10.5.2</b> Métodos Jerarquicos de Agrupamientos Desaglomerativos</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><a href="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><i class="fa fa-check"></i><b>10.6</b> Métodos NO-Jerárquicos de Partición o Agrupamiento</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><a href="métodos-no-jerárquicos-de-partición-o-agrupamiento.html#pasos-o-etapas-de-un-método-de-clasificación-no-jararquico"><i class="fa fa-check"></i><b>10.6.1</b> Pasos o etapas de un Método de Clasificación No-Jararquico</a></li>
<li class="chapter" data-level="10.6.2" data-path="métodos-no-jerárquicos-de-partición-o-agrupamiento.html"><a href="métodos-no-jerárquicos-de-partición-o-agrupamiento.html#método-de-las-k-medias-o-k-means"><i class="fa fa-check"></i><b>10.6.2</b> Método de las <span class="math inline">\(k\)</span>-Medias o <span class="math inline">\(k\)</span>-means</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="cómo-determinar-el-número-apropiado-de-conglomerados.html"><a href="cómo-determinar-el-número-apropiado-de-conglomerados.html"><i class="fa fa-check"></i><b>10.7</b> Cómo determinar el número apropiado de conglomerados?</a></li>
<li class="chapter" data-level="10.8" data-path="agrupamientos-basados-en-modelos-estadísticos.html"><a href="agrupamientos-basados-en-modelos-estadísticos.html"><i class="fa fa-check"></i><b>10.8</b> Agrupamientos Basados en Modelos Estadísticos</a></li>
<li class="chapter" data-level="10.9" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html"><i class="fa fa-check"></i><b>10.9</b> Escalamiento Multidimensional</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#el-algoritmo-básico"><i class="fa fa-check"></i><b>10.9.1</b> El Algoritmo Básico</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html"><i class="fa fa-check"></i><b>10.10</b> Análisis de Correspondencia</a>
<ul>
<li class="chapter" data-level="10.10.1" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html#desarrollo-algebraíco-del-análsisi-de-correspondencia"><i class="fa fa-check"></i><b>10.10.1</b> Desarrollo Algebraíco del Análsisi de Correspondencia</a></li>
<li class="chapter" data-level="10.10.2" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html#análisis-de-correspondencia-como-un-problema-de-mínimos-cuadrados-ponderado"><i class="fa fa-check"></i><b>10.10.2</b> Análisis de Correspondencia como un Problema de Mínimos Cuadrados Ponderado</a></li>
<li class="chapter" data-level="10.10.3" data-path="análisis-de-correspondencia.html"><a href="análisis-de-correspondencia.html#análisis-de-correspondencia-medinate-el-método-de-aproximación-de-perfiles"><i class="fa fa-check"></i><b>10.10.3</b> Análisis de Correspondencia Medinate el Método de Aproximación de Perfiles</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html"><a href="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html"><i class="fa fa-check"></i><b>10.11</b> Biplots para la Visualización de Unidades Muestrales y Variables</a>
<ul>
<li class="chapter" data-level="10.11.1" data-path="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html"><a href="biplots-para-la-visualización-de-unidades-muestrales-y-variables.html#construcción-de-un-biplot"><i class="fa fa-check"></i><b>10.11.1</b> Construcción de un Biplot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Chapter 10</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu" class="section level2 hasAnchor" number="4.9">
<h2><span class="header-section-number">4.9</span> Regiones de Confianza y Comparaciones Simultáneas entre las Componentes del Vector de Medias <span class="math inline">\(\underline{\boldsymbol \mu}\)</span><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Extensión del concepto de intervalo de confianza univariado para un parámetro al caso de una región de
confianza multivariada.</p>
<p>Considere el vector <span class="math inline">\(\underline{\theta}\)</span> de parámetros desconocidos de una población, y sea <span class="math inline">\(\Theta\)</span> su espacio
paramétrico.</p>
<p>Una región de confianza para <span class="math inline">\(\underline{\theta}\)</span> es un conjunto
que contiene los posibles valores de <span class="math inline">\(\Theta\)</span>.</p>
<p>Esta región está determinada por los datos, y será denotada por <span class="math inline">\(R(\mathbf{X})\)</span> , donde
<span class="math display">\[
\mathbf{X}_{n\times p}=\begin{bmatrix}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{bmatrix}=
\begin{bmatrix}
\underline{\mathbf{x}}_{\ 1} \\ \underline{\mathbf{x}}_{\ 2} \\ \vdots \\ \underline{\mathbf{x}}_{\ n}
\end{bmatrix}=
\begin{bmatrix}
\underline{\mathbf{x}}^{(1)} &amp; \underline{\mathbf{x}}^{(2)} &amp; \cdots &amp; \underline{\mathbf{x}}^{(n)}
\end{bmatrix} \ \ , \ \ \text{es la matriz de datos}
\]</span>
Se dice que <span class="math inline">\(R(\mathbf{X})\)</span> es una región con <span class="math inline">\((1-\alpha)\%\)</span> de confianza para <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> si, antes de obtener la muestra se tiene que:</p>
<p><span class="math display">\[
P\biggl[R(\mathbf{X})-\text{Contenga al verdadero valor de} \ \   \underline{\theta}\biggr]=1-\alpha
\]</span></p>
<div id="construcción-de-una-región-de-confianza-para-underlineboldsymbol-mu-cuando-la-población-tiene-distribución-n_punderlineboldsymbol-mumathbfsigma-con-underlineboldsymbol-mu-y-mathbfsigma-desconocidos" class="section level3 hasAnchor" number="4.9.1">
<h3><span class="header-section-number">4.9.1</span> Construcción de una Región de Confianza para <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> Cuando la Población tiene Distribución <span class="math inline">\(N_p(\underline{\boldsymbol \mu},\mathbf{\Sigma})\)</span>, con <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> y <span class="math inline">\(\mathbf{\Sigma}\)</span> desconocidos<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#construcción-de-una-región-de-confianza-para-underlineboldsymbol-mu-cuando-la-población-tiene-distribución-n_punderlineboldsymbol-mumathbfsigma-con-underlineboldsymbol-mu-y-mathbfsigma-desconocidos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bajo normalidad multivariada se tiene que:
<span class="math display">\[
T^2=n\ (\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})\sim \frac{(n-1)p}{(n-p)}F_{p\ ,\ n-p},
\]</span></p>
<p>luego, se tiene que antes de obtener la muestra,
<span class="math display">\[
P\left[T^2=n(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq \frac{(n-1)p}{(n-p)}F_{\alpha; p,n-p}\right]=1-\alpha.
\]</span>
Lo anterior quiere decir que:</p>
<p>el vector de media <span class="math inline">\(\underline{\overline{\mathbf{x}}}\)</span> está dentro de una distancia dada por:   <span class="math inline">\(\sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p,n-p}}\)</span>   del vector <span class="math inline">\(\mathbf{\underline{\boldsymbol \mu}}\)</span> con probabilidad de (<span class="math inline">\(1-\alpha\)</span>).</p>
<div class="definition">
<p><span id="def:def-region-conf" class="definition"><strong>Definición 4.1  (Región de Confianza) </strong></span>Una región de confianza del <span class="math inline">\((1-\alpha)100\%\)</span> para el vector de medias poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span> de una población normal <span class="math inline">\(p\)</span>-dimensional, es el conjunto de todos los vectores <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> que satisfacen:</p>
</div>
<p><span class="math display">\[
T^2=n\ (\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq \frac{(n-1)p}{(n-p)}F_{\alpha\ ;\  p\ ,\ n-p}
\]</span></p>
<p>es decir, es el conjunto de todos los vectores <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> que satisfacen:
<span class="math display">\[
T^2=n(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq c^2 \ \ , \ \ \ \text{con:} \ \ \ \ \ \ c^2=\frac{(n-1)p}{(n-p)}F_{\alpha; p,n-p}.
\]</span></p>
<p>Geométricamente la región de confianza, es un <strong>elipsoide</strong> centrado en <span class="math inline">\(\underline{\overline{\mathbf{x}}}\)</span>, (elipse en el caso de <span class="math inline">\(p=2\)</span>).</p>
<p>Para determinar si algún vector particular, <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ 0}\)</span> caé dentro de la región de confianza (ie. si <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ 0}\)</span> es un valor plausible o viable para <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>), se necesita calcular la distancia cuadrada generalizada dada por:</p>
<p><span class="math display">\[
T_{\ 0}^2=n\ (\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}_{\ 0})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}_{\ 0})
\]</span></p>
<p>y compararla con el número percentil de la distribución <span class="math inline">\(F\)</span>-snedecor:
<span class="math display">\[
c^2=\frac{(n-1)p}{(n-p)}F_{\alpha; p,n-p},
\]</span></p>
<p><strong>si dicha distancia cuadrática es mayor que</strong> <span class="math inline">\(c^2\)</span>, entonces <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ 0}\)</span> <strong>no estará en la región de confianza</strong>.</p>
<p>Debido a que lo anterior, es el análogo a probar:
<span class="math display">\[
\begin{cases}
H_{\ 0}\ : \ \underline{\boldsymbol{\mu}} = \underline{\boldsymbol{\mu}}_{\ 0} \\ \\
H_a\ : \ \underline{\boldsymbol{\mu}} \neq \underline{\boldsymbol{\mu}}_{\ 0} \\
\end{cases}
\]</span></p>
<p>se observa que la región de confianza consiste de todos aquellos vectores <span class="math inline">\(\underline{\boldsymbol{\mu}}_{\ 0}\)</span> para los cuales la prueba <span class="math inline">\(T^2\)</span>-de Hotelling no rechaza a <span class="math inline">\(H_{\ 0}\)</span> en favor de <span class="math inline">\(H_a\)</span> a un nivel de significancia de <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div id="región-de-confianza-para-el-caso-de-p2-elipse-de-confianza" class="section level3 hasAnchor" number="4.9.2">
<h3><span class="header-section-number">4.9.2</span> Región de Confianza para el Caso de <span class="math inline">\(p=2\)</span> (Elipse de Confianza)<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#región-de-confianza-para-el-caso-de-p2-elipse-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para el caso <span class="math inline">\(p=2\)</span>, los ejes de la Región de Confianza o Elipse de Confianza y sus respectivas longitudes relativas, son determinados a partir de los eigen-valores y eigen-vectores de <span class="math inline">\(\mathbf{S}\)</span>.</p>
<p>La desigualdad dada por,
<span class="math display">\[
n(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq c^2
\]</span></p>
<p>equivale a:
<span class="math display">\[
(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq \frac{c^2}{n}
\]</span></p>
<p>cuya gráfica para <span class="math inline">\(p=2\)</span>, representa una elipse con la siguientes características.</p>
<p>Las semi-longitudes de los ejes de la elipse de confianza, están dadas por:
<span class="math display">\[
\sqrt{\lambda_i}\frac{c}{\sqrt{n}}=\frac{\sqrt{\lambda_i}}{\sqrt{n}}\sqrt{\dfrac{(n-1)p}{n-p}F_{\alpha; \ p, n-p}} \ \ \ ,\ \ \  i=1,2
\]</span></p>
<p>unidades medidas a lo largo de los eigen-vectores de <span class="math inline">\(\mathbf{S}\)</span>, <span class="math inline">\(\mathbf{e}_i\)</span>.</p>
<p>Iniciando en el centro <span class="math inline">\(\underline{\overline{\mathbf{x}}}\)</span>, las direcciones de los ejes de la elipse de confianza son:
<span class="math display">\[
\pm \sqrt{\lambda_i}\frac{c}{\sqrt{n}}\ \mathbf{e}_i= \ \ \pm \ \ \frac{\sqrt{\lambda_i}}{\sqrt{n}}\sqrt{\dfrac{(n-1)p}{n-p}F_{\alpha; \ p, n-p}}\ \  \mathbf{e}_i \ \ \ ,\ \ \  i=1,2
\]</span>
con <span class="math inline">\(\mathbf{S}\mathbf{e}_i= \lambda_i \mathbf{e}_i\)</span> para <span class="math inline">\(i=1,2,\ldots,p\)</span>.</p>
<p>El cociente entre las longitudes de los ejes de la elipse (o entre los <span class="math inline">\(\lambda_i\)</span>’s) ayudan a identificar las longitudes relativas de cada par de ejes.</p>
<p><span class="math display">\[
\frac{2\sqrt{\lambda_1}\frac{c}{\sqrt{n}}}{2\sqrt{\lambda_2}\frac{c}{\sqrt{n}}}=
\frac{\sqrt{\lambda_1}}{\sqrt{\lambda_2}}=s
\]</span></p>
<p>lo que indica que, el eje mayor tiene una longitud que es <span class="math inline">\(s\)</span>-veces la del eje menor.</p>
<div class="example">
<p><span id="exm:ejemplo1-region-confianza" class="example"><strong>Ejemplo 4.26  (Ejemplo-1 Región de Confianza) </strong></span>Considere los <span class="math inline">\(n=42\)</span> datos del ejemplo <a href="evaluación-del-supuesto-de-normalidad-multivariada.html#exm:ejemplo2-qqplot">3.12</a> de radiación de hornos microondas usados anteriormente:</p>
</div>
<table>
<caption>
<span id="tab:unnamed-chunk-74">Tabla 4.22: </span>Datos de Radiación
</caption>
<thead>
<tr>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.03
</td>
<td style="text-align:center;">
0.05
</td>
</tr>
<tr>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.05
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.15
</td>
</tr>
<tr>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.30
</td>
</tr>
<tr>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.15
</td>
</tr>
<tr>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
0.28
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.07
</td>
<td style="text-align:center;">
0.07
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.11
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.30
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.45
</td>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.25
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.20
</td>
</tr>
<tr>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.04
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.40
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.33
</td>
</tr>
<tr>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.40
</td>
<td style="text-align:center;">
0.32
</td>
</tr>
<tr>
<td style="text-align:center;">
0.40
</td>
<td style="text-align:center;">
0.60
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
</tbody>
</table>
<p>donde:</p>
<p><span class="math display">\[
X_1=\sqrt[4]{\text{Radiación medida con puerta cerrada} }
\]</span>
<span class="math display">\[
X_2=\sqrt[4]{\text{Radiación medida con puerta Abierta} }
\]</span></p>
<p>Para los <span class="math inline">\(n=42\)</span> pares de datos <span class="math inline">\((x_1 , x_2)\)</span> se tienen los siguientes resúmenes descriptivos:
<span class="math display">\[
\underline{\overline{\mathbf{x}}}=\begin{bmatrix}
0.564 \\ 0.603
\end{bmatrix} , \ \ \ \ \ \mathbf{S}=\begin{bmatrix}
0.0144 &amp; 0.0117 \\ 0.0117 &amp; 0.0146
\end{bmatrix} \ \ \ \text{y} \ \ \ \mathbf{S}^{-1}=\begin{bmatrix}
203.018 &amp; -163.391 \\ -163.391 &amp; 200.228
\end{bmatrix}
\]</span></p>
<p>Con estas cantidades, la elipse del <span class="math inline">\(95\%\)</span> de confianza para <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> contiene todos los vectores <span class="math inline">\(\underline{\boldsymbol{\mu}}=(\mu_1,\mu_2)\)</span> que satisfacen:
<span class="math display">\[
T^2=n\ (\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq c^2
\]</span></p>
<p><span class="math display">\[
\begin{align*}
42\begin{bmatrix}
0.564-\mu_1 \\ 0.603-\mu_2
\end{bmatrix}^t\begin{bmatrix}
203.018 &amp; -163.391 \\ -163.391 &amp; 200.228
\end{bmatrix}\begin{bmatrix}
0.564-\mu_1 \\ 0.603-\mu_2
\end{bmatrix}  &amp; \leq  \frac{41(2)}{40}F_{0.05;2,40}\\
&amp; =\frac{41(2)}{40}3.23 \\ &amp;=6.62
\end{align*}
\]</span></p>
<p>o equivalentemente:
<span class="math display">\[
42(203.018)(0.564-\mu_1)^2+42(200.228)(0.603-\mu_2)^2  -84(163.391)(0.564-\mu_1)(0.603-\mu_2)
\leq 6.62
\]</span></p>
<p><span class="math display">\[
\begin{bmatrix}
0.564-\mu_1 \\ 0.603-\mu_2
\end{bmatrix}^t\begin{bmatrix}
203.018 &amp; -163.391 \\ -163.391 &amp; 200.228
\end{bmatrix}\begin{bmatrix}
0.564-\mu_1 \\ 0.603-\mu_2
\end{bmatrix}  \leq  \frac{6.62}{42}=0.1576
\]</span></p>
<p>es decir:
<span class="math display">\[
(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq k^2=0.1576
\]</span></p>
<p>¿<strong>Cae el vector:</strong><br />
<span class="math display">\[
\underline{\boldsymbol \mu}=\begin{bmatrix}
0.562 \\ \\ 0.589
\end{bmatrix}
\]</span></p>
<p><strong>dentro de la elipse del <span class="math inline">\(95\%\)</span> de confianza</strong>?</p>
<p>Utilizando la elipse anterior donde se reemplazan los valores de <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span> por los valores dados en <span class="math inline">\(\underline{\boldsymbol \mu}\)</span>, se obtiene:</p>
<p><span class="math display">\[
1.30&lt;6.62
\]</span></p>
<p>y por lo tanto el vector
<span class="math display">\[
\underline{\boldsymbol \mu}=\begin{bmatrix}
0.562 \\ \\ 0.589
\end{bmatrix}
\]</span>
si cae dentro de la región de confianza del <span class="math inline">\(95\%\)</span>.</p>
<p><strong>Equivalentemente, en la prueba de:</strong>
<span class="math display">\[
H_{\ 0} \ \ : \ \ \underline{\boldsymbol \mu}=\begin{bmatrix}
0.562 \\ \\ 0.589
\end{bmatrix} \ \ \ \text{contra:} \ \ \ H_1 \ \ : \ \ \underline{\boldsymbol \mu} \neq \begin{bmatrix}
0.562 \\ \\ 0.589
\end{bmatrix}
\]</span></p>
<p>un nivel de significancia de <span class="math inline">\(\alpha = 0.05\)</span>, no se rechaza <span class="math inline">\(H_{\ 0}\)</span>.</p>
<p><strong>Ahora pasemos a graficar la Región de Confianza Obtenida</strong></p>
<p>El centro de la elipse es:
<span class="math display">\[
\underline{\overline{\mathbf{x}}}= \begin{bmatrix}
0.564 \\ \\ 0.603
\end{bmatrix}
\]</span>
y las semi-longitudes de los ejes mayor y menor son, respectivamente,
<span class="math display">\[
\frac{\sqrt{\lambda_1}}{\sqrt{n}}\sqrt{\dfrac{(n-1)p}{n-p}F_{1-\alpha; \ p, n-p}}=\frac{\sqrt{\lambda_1}}{\sqrt{42}}\sqrt{\dfrac{(42-1)2}{42-2}F_{1-0.05; \ 2, 40}}
=\frac{\sqrt{0.026}}{\sqrt{42}}\sqrt{\dfrac{(41)2}{40}3.2317}=0.064
\]</span></p>
<p>y
<span class="math display">\[
\frac{\sqrt{\lambda_2}}{\sqrt{n}}\sqrt{\dfrac{(n-1)p}{n-p}F_{1-\alpha; \ p, n-p}}=\frac{\sqrt{\lambda_2}}{\sqrt{42}}\sqrt{\dfrac{(42-1)2}{42-2}F_{1-0.05; \ 2, 40}}
=\frac{\sqrt{0.002}}{\sqrt{42}}\sqrt{\dfrac{(41)2}{40}3.2317}=0.018
\]</span></p>
<p>Los ejes caen a lo largo de:
<span class="math display">\[
\underline{\mathbf{e}}_1=\begin{bmatrix}
0.704 \\ \\ 0.710
\end{bmatrix} \ \ \ \text{y} \ \ \ \underline{\mathbf{e}}_1=\begin{bmatrix}
-0.710 \\ \\ 0.704
\end{bmatrix}
\]</span>
cuando estos vectores son graficados desde el origen: <span class="math inline">\(\underline{\overline{\mathbf{x}}}= \begin{bmatrix} 0.564 \\ \\ 0.603 \end{bmatrix}\)</span>.</p>
<p>Ahora, una indicación de la elongación de la elipse de confianza está dada por el cociente entre las longitudes del eje mayor y del eje menor, ie.
<span class="math display">\[
\frac{2\sqrt{\lambda_1}\sqrt{\dfrac{(n-1)p}{(n-p)n}F_{\alpha; \ p, n-p}}}{2\sqrt{\lambda_2}\sqrt{\dfrac{(n-1)p}{(n-p)n}F_{\alpha; \ p, n-p}}}=\frac{\sqrt{\lambda_1}}{\sqrt{\lambda_2}}=\frac{\sqrt{0.026}}{\sqrt{0.002}}=\frac{0.161}{0.045}=3.6
\]</span></p>
<p>Lo que indica que el eje mayor es <span class="math inline">\(3.6\)</span> veces el eje menor.</p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<div class="example">
<p><span id="exm:ejemplo2-region-confianza" class="example"><strong>Ejemplo 4.27  (Ejemplo-2 Región de Confianza) </strong></span>Ahora grafiquemos elipses de confianza a partir de datos generados de una Normal Bivariada con ciertos parámetros.</p>
</div>
<p>Por ejemplo para:
<span class="math display">\[
\underline{\overline{\mathbf{x}}}=\begin{bmatrix}
0.564 \\ 0.603
\end{bmatrix}  \ \ \ \ \ \text{y} \ \ \ \ \ \  \mathbf{S}=\begin{bmatrix}
0.0144 &amp; 0.0117 \\ 0.0117 &amp; 0.0146
\end{bmatrix}
\]</span></p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
</div>
<div id="intervalos-de-confianza-simultáneos-para-las-componentes-del-vector-de-medias-underlineboldsymbol-mu" class="section level3 hasAnchor" number="4.9.3">
<h3><span class="header-section-number">4.9.3</span> Intervalos de Confianza Simultáneos para las Componentes del Vector de Medias <span class="math inline">\(\underline{\boldsymbol \mu}\)</span><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#intervalos-de-confianza-simultáneos-para-las-componentes-del-vector-de-medias-underlineboldsymbol-mu" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Mientras que las regiones de confianza proporcionan un
conocimiento conjunto sobre los valores plausibles para <span class="math inline">\(\underline{\boldsymbol \mu}\)</span>, generalmente las conclusiones de un estudio también incluyen afirmaciones sobre las componentes individuales del vector de medias.</p>
<p>Para hacer esto, necesitamos construir intervalos individuales para cada componente del vector de media de forma tal que simultáneamente cada uno de ellos contenga a sus medias bajo una probabilidad especificada.</p>
<p>Esta clase de intervalos son llamados <strong>Intervalos de Confianza Simultáneos</strong>.</p>
<p>Al hacer lo anterior, se adopta la actitud de que toda las afirmaciones de confianza separadas o individuales deben ser simultáneamente ciertas con una alta probabilidad especificada de antemano.</p>
<div id="intervalos-de-confianza-simultáneos-basados-en-la-estadística-t2-de-hotelling" class="section level4 hasAnchor" number="4.9.3.1">
<h4><span class="header-section-number">4.9.3.1</span> Intervalos de Confianza Simultáneos Basados en la Estadística <span class="math inline">\(T^2\)</span>-de Hotelling<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#intervalos-de-confianza-simultáneos-basados-en-la-estadística-t2-de-hotelling" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Se inicia considerando afirmaciones de confianza simultáneas que están íntimamente relacionadas con la región de confianza basada en la estadística <span class="math inline">\(T^2\)</span>-de Hotelling.</p>
<p>Sea <span class="math inline">\(\underline{\mathbf{x}}\sim N_p (\underline{\boldsymbol{\mu}}\ , \ \mathbf{\Sigma} )\)</span>, para el cual se tiene la muestra de datos:
<span class="math display">\[
\mathbf{X}_{n\times p}=\begin{bmatrix}
x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; &amp; \vdots \\
x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{bmatrix}=
\begin{bmatrix}
\underline{\mathbf{x}}_{\ 1} \\ \underline{\mathbf{x}}_{\ 2} \\ \vdots \\ \underline{\mathbf{x}}_{\ n}
\end{bmatrix}=
\begin{bmatrix}
\underline{\mathbf{x}}^{(1)} &amp; \underline{\mathbf{x}}^{(2)} &amp; \cdots &amp; \underline{\mathbf{x}}^{(n)}
\end{bmatrix} \ \ , \ \ \text{es la matriz de datos}
\]</span></p>
<p>y considere la c.l dada por:
<span class="math display">\[
Z=a_1X_1+a_2X_2+\cdots+a_pX_p= \underline{a}^t \underline{\mathbf{x}}
\]</span></p>
<p>Claramente, se tiene que:
<span class="math display">\[
\mu_Z=E[Z]=\underline{a}^t \underline{\boldsymbol{\mu}} \ \ \ \ \text{y} \ \ \ \sigma_Z^2=Var[Z]=\underline{a}^t \mathbf{\Sigma} \underline{a}
\]</span></p>
<p>Además, por la propiedad <a href="prop-nm.html#prop2">3.5.2</a> de la NM, se tiene que:
<span class="math display">\[
Z \sim N\biggl(\underline{a}^t \underline{\boldsymbol{\mu}}\  , \ \underline{a}^t \mathbf{\Sigma} \underline{a} \biggr)
\]</span></p>
<p>Si se tiene disponible una m.a <span class="math inline">\(\underline{\mathbf{x}}_1,\underline{\mathbf{x}}_2,\ldots,\underline{\mathbf{x}}_n\)</span> de la distribución <span class="math inline">\(N_p (\underline{\boldsymbol{\mu}} \ , \ \mathbf{\Sigma})\)</span>, se tendrá también una m.a correspondiente a la variable <span class="math inline">\(Z\)</span>, tomando las respectivas combinaciones lineales, ie.
<span class="math display">\[
Z_j=\underline{a}^t \mathbf{x}_j=a_1x_{j1}+a_2x_{j2}+\cdots +a_px_{jp} \ , \ \ \ \text{para} \ \ j=1,2,\ldots,n.
\]</span></p>
<p>La media y la varianza muestral de los valores observados de la variable <span class="math inline">\(Z\)</span>´s dados por: <span class="math inline">\(Z_1,Z_2,\ldots,Z_n\)</span>, están dados por:
<span class="math display">\[
\overline{Z}=\frac{1}{n}\sum_{j=1}^n\ Z_j=\underline{a}^t\underline{\overline{\mathbf{x}}} \  \ \ \text{y} \ \ \ S_Z^2=\frac{1}{n-1}\sum_{j=1}^n (Z_j-\overline{Z})^2=\underline{a}^t \mathbf{S} \underline{a}
\]</span></p>
<p>donde, <span class="math inline">\(\underline{\overline{\mathbf{x}}}\)</span> y <span class="math inline">\(\mathbf{S}\)</span> son el vector de medias muestrales y la matriz de Var-Cov muestrales de las <span class="math inline">\(\underline{\mathbf{x}}_i\)</span>, para <span class="math inline">\(i=1,2,\ldots,n\)</span>.</p>
<p>Los Intervalos de Confianza Simultáneos pueden ser desarrollados considerando los Intervalos de Confianza de <span class="math inline">\(\underline{a}^t\underline{\boldsymbol{\mu}}\)</span>, para cualesquier elección de <span class="math inline">\(\underline{a}\)</span>.</p>
<p>Para <span class="math inline">\(\underline{a}\)</span>-fijo y <span class="math inline">\(\sigma_Z^2\)</span>-desconocida, Un I.C del <span class="math inline">\((1-\alpha)100\%\)</span> para <span class="math inline">\(\mu_Z=\underline{a}^t\underline{\boldsymbol{\mu}}\)</span> basado en la estadística <span class="math inline">\(t\)</span>-de Student:</p>
<p><span class="math display">\[
t=\frac{\overline{Z}-\mu_Z}{S_Z/\sqrt{n}}=\frac{\sqrt{n}(\underline{a}^t\underline{\overline{\mathbf{x}}}
-\underline{a}^t\underline{\boldsymbol{\mu}})}{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}
\]</span></p>
<p>esta dado por:
<span class="math display">\[
\overline{Z}-t_{\alpha/2\ ;\ n-1} \frac{S_Z}{\sqrt{n}} \leq \mu_Z \leq
\overline{Z}+t_{\alpha/2\ ;\ n-1} \frac{S_Z}{\sqrt{n}}
\]</span></p>
<p>o equivalentemente:
<span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}-t_{\alpha/2\ ;\ n-1} \frac{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}{\sqrt{n}} \leq \mu_Z \leq
\underline{a}^t\underline{\overline{\mathbf{x}}}+t_{\alpha/2\ ;\ n-1} \frac{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}{\sqrt{n}}
\]</span></p>
<p>ie.
<span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \ \pm \ \ t_{\alpha/2\ ;\ n-1} \frac{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}{\sqrt{n}}
\]</span></p>
<p>El intervalo anterior puede ser interpretado como una afirmación acerca de las componentes del vector de medias poblacionales <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>, mediante el sigueinte procedimiento.</p>
<p><strong>Por ejemplo</strong>, con
<span class="math display">\[
\underline{a}=\begin{bmatrix}
1 \\ 0 \\ \vdots \\ 0
\end{bmatrix}\ , \ \ \text{se tiene que:} \ \  \mu_Z=\underline{a}^t\underline{\boldsymbol{\mu}}=\mu_1, \ \ \]</span></p>
<p><span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \ \pm\ \  t_{\alpha/2\ ;\ n-1} \frac{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}{\sqrt{n}} \ \ \ \ \Longleftrightarrow \ \ \ \ \overline{X}_1\ \ \pm \ \  t_{\alpha/2\ ;\ n-1} \frac{\sqrt{S_{11}}}{n}
\]</span></p>
<p>el anterior I.C es el intervalo de confianza usual para la media poblacional normal <span class="math inline">\(\mu_Z=\underline{a}^t\underline{\boldsymbol{\mu}}=\mu_1\)</span>, en donde se tiene que: <span class="math inline">\(\underline{a}^t\underline{\overline{\mathbf{x}}}=\overline{X}_1\)</span> y <span class="math inline">\(\underline{a}^t \mathbf{S} \underline{a}=S_{11}=Var[X_1]\)</span>.</p>
<p>De la misma forma, eligiendo un adecuado vector de constantes <span class="math inline">\(\underline{a}\)</span> se pueden construir los intervalos de confianza para todas las componentes <span class="math inline">\(\mu_i\)</span> del vector <span class="math inline">\(\underline{\boldsymbol \mu}\)</span>.</p>
<p>Sin embargo <strong>la confianza</strong> <span class="math inline">\(1-\alpha\)</span>-asociada a cada intervalo de confianza <strong>es individual</strong> y <strong>no conjunta</strong>, y lo que se quiere es asociar <strong>una confianza “ colectiva” </strong> del <span class="math inline">\(1-\alpha\)</span> a todos los intervalos de confianza que pueden ser generados por las diferentes elecciones de <span class="math inline">\(\underline{a}\)</span>.</p>
<p><strong>¿ Cómo asociar un coeficiente de confianza “ coletivo”   del <span class="math inline">\((1-\alpha)\)</span> para los I.C que pueden ser generados mediante todas las elecciones de <span class="math inline">\(\underline{a}\)</span> ?</strong></p>
<p>Para lograr lo anterior, se debe pagar un precio:</p>
<p><strong>los intervalos simultáneos son más amplios (es decir, menos precisos) que el intervalo de confianza individual para una sola elección de <span class="math inline">\(\underline{a}\)</span></strong>.</p>
<div class="theorem">
<p><span id="thm:teorema-ics-t2" class="theorem"><strong>Teorema 4.1  (IC Simultáneos T2 de Hotelling) </strong></span>Sea <span class="math inline">\(\underline{\mathbf{x}}_1,\underline{\mathbf{x}}_2,\ldots,\underline{\mathbf{x}}_n\)</span> un m.a de una población <span class="math inline">\(N_p(\underline{\boldsymbol{\mu}} \ , \ \mathbf{\Sigma} )\)</span>, con <span class="math inline">\(\mathbf{\Sigma}\)</span>-definida positiva, entonces, simultáneamente para todo <span class="math inline">\(\underline{a}\)</span>, el I.C dado por:</p>
</div>
<p><span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \ \pm\ \ \underbrace{ \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha\ ;\ p\ ,\ n-p} }  } \frac{ \sqrt{ \underline{a}^t \mathbf{S} \underline{a}}}{ \sqrt{n} }
\]</span></p>
<p>A diferencia de:
<span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \ \pm\ \ \underbrace{ t_{\alpha/2\ ;\ n-1}  }\frac{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}{\sqrt{n}}
\]</span></p>
<p>contendrá a <span class="math inline">\(\underline{a}^t \underline{\boldsymbol{\mu}}\)</span> con probabilidad de <span class="math inline">\((1-\alpha)\)</span>.</p>
<p>A estos I.C simultáneos, se les llaman <strong>Intervalos</strong>-<span class="math inline">\(T^2\)</span>, ya que la probabilidad de cobertura de dichos intervalos se determina con la distribución <span class="math inline">\(T^2\)</span>-de Hotelling.</p>
<div class="proof">
<p><span id="unlabeled-div-15" class="proof"><em>Demostración</em> (Justificación del Teorema Anterior). </span>Dado un conjunto de datos <span class="math inline">\(\underline{\mathbf{x}}_1,\underline{\mathbf{x}}_2,\ldots,\underline{\mathbf{x}}_n\)</span>, y una elección específica de <span class="math inline">\(\underline{a}\)</span>, el intervalo de confianza para <span class="math inline">\(\underline{a}^t\underline{\boldsymbol \mu}\)</span> es aquel conjunto de valores que satisfacen:</p>
</div>
<p><span class="math display">\[
\left|t \right|=\left| \frac{\sqrt{n}\left(\underline{a}^t \underline{\overline{\mathbf{x}}} - \underline{a}^t \underline{\boldsymbol \mu} \right) }{\sqrt{ \underline{a}^t\mathbf{S} \underline{a} }  } \right| \leq t_{\alpha/2\ ; \ n-1}
\]</span></p>
<p>o equivalentemente,</p>
<p><span class="math display">\[
t^2=\left( \frac{\sqrt{n}\left(\underline{a}^t \underline{\overline{\mathbf{x}}} - \underline{a}^t \underline{\boldsymbol \mu} \right) }{\sqrt{ \underline{a}^t\mathbf{S} \underline{a} } } \right)^2 =  \frac{n\left(\underline{a}^t (\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu}) \right)^2 }{  \underline{a}^t\mathbf{S} \underline{a}}     \leq t_{\alpha/2\ ; \ n-1}^2
\]</span></p>
<p>Cuando los intervalos son desarrollados para muchas elecciones de <span class="math inline">\(\underline{a}\)</span>, parece razonable esperar que la constante para el intervalo individual, <span class="math inline">\(t_{\alpha/2\ ; \ n-1}^2\)</span>, sea reemplazada por un valor <span class="math inline">\(c^2\)</span> mayor que produzca la confianza simultánea deseada.</p>
<p>Sea
<span class="math display">\[
t^2(\underline{a})= \frac{ n \left(\underline{a}^t (\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu}) \right)^2}{\underline{a}^t\mathbf{S} \underline{a}}
\]</span></p>
<p>usando esta notación entonces, el problema se reduce a <strong>obtener un valor de</strong> <span class="math inline">\(c^2\)</span> <strong>tal que</strong>:</p>
<p><span class="math display">\[
P\bigg[t^2(\underline{a}) \leq c^2 \biggr]=1-\alpha \ , \ \ \ \forall \ \ \underline{a}\in \mathbb{R}^p \ \ \ \ \Longleftrightarrow \ \ \ \ \ \ P \left[\frac{ n \left(\underline{a}^t (\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu}) \right)^2}{\underline{a}^t\mathbf{S} \underline{a}} \leq c^2 \right]=1-\alpha \ , \ \ \ \forall \ \ \underline{a}\in \mathbb{R}^p
\]</span></p>
<p>Esto es equivalente a <strong>obtener un valor</strong> <span class="math inline">\(c^2\)</span> <strong>tal que</strong>:
<span class="math display">\[
P\biggl[\text{max}_{\underline{a}} \ t^2(\underline{a}) \leq c^2 \biggr]=1-\alpha \ \ \ \ \ \ \ \Longleftrightarrow \ \ \ \ \ \ P \left[\text{max}_{\ \ \underline{a}} \left(  \frac{  n \left(\underline{a}^t (\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu}) \right)^2}{\underline{a}^t\mathbf{S} \underline{a}} \right) \leq c^2 \right]=1-\alpha \ , \ \ \ \forall \ \ \underline{a}\in \mathbb{R}^p
\]</span></p>
<p>Para hallar dicho valor de <span class="math inline">\(c^2\)</span>-se utiliza el siguiente resultado, (ver el teorema <a href="#thm:maximizacion-fc"><strong>??</strong></a> del capítulo uno),</p>
<div class="lemma">
<p><span id="lem:lema1-ics" class="lemma"><strong>Lema 4.1  (Lema-1 ICS) </strong></span>Sea <span class="math inline">\(\mathbf{B}\)</span> una matriz definida positiva y <span class="math inline">\(\underline{d}\)</span> un vector dado cualquiera, entonces para un vector <span class="math inline">\(\underline{\mathbf{x}}_{p\times 1}\)</span> se cumple que:</p>
</div>
<p><span class="math display">\[
\text{max}_{\ \ \underline{\mathbf{x}}}  \left[ \frac{ ( \underline{\mathbf{x}}^t \underline{d})^2}{ \underline{\mathbf{x}}^t \mathbf{B} \underline{\mathbf{x}}  } \right]= \underline{d}^t \mathbf{B}^{-1}\underline{d}
\]</span></p>
<p>y el máximo se obtiene cuando: <span class="math inline">\(\underline{\mathbf{x}}=k \mathbf{B}^{-1}\underline{d}\)</span>, con <span class="math inline">\(k\in \mathbb{R}\)</span> y <span class="math inline">\(k\neq 0\)</span>.</p>
<p>Aplicando este teorema con: <span class="math inline">\(\underline{\mathbf{x}}=\underline{a}\)</span>  , <span class="math inline">\(\underline{d}=( \overline{\mathbf{x}} - \underline{\boldsymbol \mu})\)</span>  y  <span class="math inline">\(\mathbf{B}=\mathbf{S}\)</span>, se obtiene que:</p>
<p><span class="math display">\[
\begin{align*}
\text{max}_{\ \ \underline{a}} \ t^2(\underline{a}) &amp;= \text{max}_{\ \ \underline{a}}\left[ \frac{ n \left(\underline{a}^t (\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu}) \right)^2}{\underline{a}^t\mathbf{S} \underline{a}} \right] \\ \\
&amp;=n \left[ \text{max}_{\underline{a}} \left( \frac{ \left(\underline{a}^t (\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu}) \right)^2}{\underline{a}^t\mathbf{S} \underline{a}} \right) \right]\\ \\
&amp;=n (\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu})^t \mathbf{S}^{-1}(\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu}) \\ \\
&amp;=T^2
\end{align*}
\]</span></p>
<p>y el máximo ocurre en un <span class="math inline">\(\underline{a}\)</span>-que es proporcional a: <span class="math inline">\(\mathbf{S}^{-1}(\underline{\overline{\mathbf{x}}} - \underline{\boldsymbol \mu})\)</span>.</p>
<p><strong>Usando el resultado de que</strong>:
<span class="math display">\[
T^2=n(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})\sim \frac{(n-1)p}{(n-p)}F_{p\ ,\ n-p},
\]</span></p>
<p>se tiene que antes de obtener la muestra se cumple que:
<span class="math display">\[
P\left[n(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}})^t\mathbf{S}^ {-1}(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol{\mu}}) \leq \frac{(n-1)p}{(n-p)}F_{\alpha\ ;\ p\ ,\ n-p}\right]=1-\alpha
\]</span></p>
<p>y de lo anterior se tiene que, si <span class="math inline">\(\underline{\mathbf{x}}_1,\underline{\mathbf{x}}_2,\ldots,\underline{\mathbf{x}}_n\)</span> es una muestra aleatoria de una población <span class="math inline">\(N_p(\underline{\boldsymbol \mu} \ ,\ \mathbf{\Sigma} )\)</span>, entonces, simultáneamente para todo <span class="math inline">\(\forall \ \ \underline{a}\in \mathbb{R}^p\)</span>, el intervalo:
<span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \ \pm\ \    \underbrace{ \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p} }  } \frac{ \sqrt{ \underline{a}^t \mathbf{S} \underline{a}}}{ \sqrt{n} }
\]</span></p>
<p>contendrá a <span class="math inline">\(\underline{a}^t \underline{\boldsymbol \mu}\)</span> con probabilidad <span class="math inline">\(1-\alpha\)</span>.</p>
<p>A diferencia de:</p>
<p><span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \ \pm\ \ \underbrace{ t_{\alpha/2\ ;\ n-1}  }\frac{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}{\sqrt{n}}
\]</span></p>
<p>que lo contiene para un <span class="math inline">\(\underline{a}\)</span>-particular o individual.</p>
<div class="example">
<p><span id="exm:ejemplo1-ics" class="example"><strong>Ejemplo 4.28  (Ejemplo-1 IC T2-Simulténeos) </strong></span>Con las elecciones sucesiva de <span class="math inline">\(\underline{a}\)</span> para los intervalos-<span class="math inline">\(T^2\)</span>, dadas por:</p>
</div>
<p><span class="math display">\[
\underline{a}=\begin{bmatrix}
1 \\ 0 \\ \vdots \\ 0
\end{bmatrix} \ , \ \ \underline{a}=\begin{bmatrix}
0 \\ 1 \\ \vdots \\ 0
\end{bmatrix} \ , \cdots , \ \ \underline{a}=\begin{bmatrix}
0 \\ 0 \\ \vdots \\ 1
\end{bmatrix}
\]</span></p>
<p>se tiene que todos los siguientes intervalos son simultáneamente verdaderos con un coeficiente de confianza del (1-<span class="math inline">\(\alpha\)</span>):
<span class="math display">\[
\overline{x}_1 - \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{11}}{n}} \leq \mu_1 \leq  \overline{x}_1 + \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{11}}{n}}
\]</span>
<span class="math display">\[
\overline{x}_2 - \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{22}}{n}} \leq \mu_2 \leq  \overline{x}_2 + \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{22}}{n}}
\]</span>
<span class="math display">\[
\vdots
\]</span></p>
<p><span class="math display">\[
\overline{x}_p - \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{pp}}{n}} \leq \mu_p \leq  \overline{x}_p + \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{pp}}{n}}
\]</span></p>
<p>Similarmente, sin modificar el nivel de confianza de <span class="math inline">\((1-\alpha)\)</span>, se pueden hacer afirmaciones acerca de la diferencia de medias <span class="math inline">\(\mu_i-\mu_k\)</span>, correspondientes a: <span class="math inline">\(\underline{a}^t=(0 , \cdots , a_i, \cdots , a_k , \cdots ,0)\)</span> con <span class="math inline">\(a_i=1\)</span> y <span class="math inline">\(a_k=-1\)</span>.</p>
<p>En este caso se tiene que: <span class="math inline">\(\underline{a}^t \mathbf{S}\underline{a}=s_{ii}-2s_{ik}+s_{kk}\)</span>, y el I.C del <span class="math inline">\((1-\alpha)100\%\)</span> para la diferencias de medias <span class="math inline">\((\mu_i-\mu_k\)</span>) es:</p>
<p><span class="math display">\[
(\overline{x}_i-\overline{x}_k) \ \ \pm \ \  \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{ii}-2s_{ik}+s_{kk}}{n}}
\]</span></p>
<div class="remark">
<p><span id="unlabeled-div-16" class="remark"><em>Observación</em>. </span>Los I.C <span class="math inline">\(T^2\)</span>-simultáneos para las componentes individuales de un vector de medias <span class="math inline">\(\underline{\boldsymbol{\mu}}\)</span>, <strong>son las sombras o proyecciones de la elipse de confianza</strong> sobre los ejes componentes.</p>
</div>
<p>Los intervalos <span class="math inline">\(T^2\)</span>-simultáneos son útiles para examinar datos. El coeficiente de confianza <span class="math inline">\(1-\alpha\)</span> no cambia para cualquier elección de <span class="math inline">\(\underline{a}\)</span>. Por tanto, se pueden evaluar las combinaciones lineales de las componentes <span class="math inline">\(\mu_i\)</span> que ameriten inspección basados sobre un examen de los datos.</p>
<p>También podemos incluir afirmaciones sobre los pares de medias <span class="math inline">\((\mu_i\ ,\ \mu_k)\)</span> usando las elipses:</p>
<p><span class="math display">\[
n\begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}^t \begin{bmatrix}
s_{ii} &amp; s_{ik} \\ s_{ik} &amp; s_{kk}
\end{bmatrix}^{-1}  \begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}  \leq \frac{(n-1)p}{(n-p)}F_{p,n-p}(\alpha)
\]</span></p>
<p>o equivalentemente:
<span class="math display">\[
\begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}^t \begin{bmatrix}
s_{ii} &amp; s_{ik} \\ s_{ik} &amp; s_{kk}
\end{bmatrix}^{-1}  \begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}  \leq c^2=\frac{1}{n}\frac{(n-1)p}{(n-p)}F_{p,n-p}(\alpha)
\]</span></p>
<p>Las cuales conservan un coeficiente de confianza <span class="math inline">\(1-\alpha\)</span>.</p>
<div class="example">
<p><span id="exm:ejemplo2-ics" class="example"><strong>Ejemplo 4.29  (Ejemplo-2 IC T2-Simulténeos) </strong></span>En un ejemplo <a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#exm:ejemplo1-region-confianza">4.26</a> sobre datos de radiación se construyó una elipse del <span class="math inline">\(95\%\)</span> de confianza para las medias de la raíz cuarta de las variables de radiación a puerta cerrada y a puerta abierta de hornos microondas.</p>
</div>
<table>
<caption>
<span id="tab:unnamed-chunk-77">Tabla 4.23: </span>Datos de Radiación
</caption>
<thead>
<tr>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.03
</td>
<td style="text-align:center;">
0.05
</td>
</tr>
<tr>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.05
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.15
</td>
</tr>
<tr>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.30
</td>
</tr>
<tr>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.15
</td>
</tr>
<tr>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
0.28
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.07
</td>
<td style="text-align:center;">
0.07
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.11
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.30
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.45
</td>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.25
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.20
</td>
</tr>
<tr>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.04
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.40
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.33
</td>
</tr>
<tr>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.40
</td>
<td style="text-align:center;">
0.32
</td>
</tr>
<tr>
<td style="text-align:center;">
0.40
</td>
<td style="text-align:center;">
0.60
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
</tbody>
</table>
<p>Los intervalos <span class="math inline">\(T^2\)</span>-simultáneos del <span class="math inline">\(95\%\)</span> de confianza para las componentes de medias son:
<span class="math display">\[
\left(  \overline{x}_1 - \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{11}}{n}} \ \ , \ \   \overline{x}_1 + \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{11}}{n}}  \right)
\]</span></p>
<p><span class="math display">\[
\left( 0.564 - \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0144}{42}} \ \ , \ \  0.564 + \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0144}{42}}   \right)
\]</span></p>
<p><span class="math display">\[
\mu_1 \ \ \in \ \ \left( 0.5163 \ \ , \ \  0.6117   \right)
\]</span></p>
<p>y para <span class="math inline">\(\underline{\boldsymbol \mu}_2\)</span>
<span class="math display">\[
\left(  \overline{x}_2 - \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{22}}{n}} \ \ , \ \   \overline{x}_2 + \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{22}}{n}}  \right)
\]</span>
<span class="math display">\[
\left( 0.603 - \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0145}{42}} \ \ , \ \  0.603 + \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0145}{42}}   \right)
\]</span></p>
<p><span class="math display">\[
\mu_2 \ \ \in \ \ \left( 0.5552 \ \ , \ \  0.6508   \right)
\]</span></p>
<p><strong>Gráfico de Elipse de Confianza con IC-Simultáneos</strong></p>
<p>El siguiente gráfico muestra la elipse del <span class="math inline">\(95\%\)</span> de confianza y los intervalos simultáneos del <span class="math inline">\(95\%\)</span> de confianza para los datos del ejemplo anterior los cuales son sombras o proyecciones de la elipse sobre los ejes de las componentes de medias.</p>
<p><span class="math display">\[
\underline{\overline{\mathbf{x}}}=\begin{bmatrix}
0.564 \\ 0.603
\end{bmatrix}  \ \ \ \ \ \text{y} \ \ \ \ \ \  \mathbf{S}=\begin{bmatrix}
0.0144 &amp; 0.0117 \\ 0.0117 &amp; 0.0146
\end{bmatrix}
\]</span></p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p><strong>Gráfico de Elipse de Confianza e IC-Simultáneos</strong> <span class="math inline">\(T^2\)</span> <strong>de Hoteling como sombras de la Elipse de confianza</strong>.</p>
<p>El siguiente gráfico muestra la elipse del <span class="math inline">\(95\%\)</span> de confianza y los intervalos simultáneos del <span class="math inline">\(95\%\)</span> de confianza <strong>para datos Normales Bivariados simulados con los parámetros dados</strong>, los cuales son sombras o proyecciones de la elipse sobre los ejes de las componentes de medias.</p>
<p><span class="math display">\[
\underline{\overline{\mathbf{x}}}=\begin{bmatrix}
0.564 \\ 0.603
\end{bmatrix}  \ \ \ \ \ \text{y} \ \ \ \ \ \  \mathbf{S}=\begin{bmatrix}
0.0144 &amp; 0.0117 \\ 0.0117 &amp; 0.0146
\end{bmatrix}
\]</span></p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<div class="example">
<p><span id="exm:ejemplo3-ics" class="example"><strong>Ejemplo 4.30  (Ejemplo-3 IC T2-Simulténeos) </strong></span>Las notas obtenidas por <span class="math inline">\(n=87\)</span> estudiantes en la prueba CLEP
(College Level Examination Program), <span class="math inline">\(X_1\)</span>= ciencias sociales e
historia, y en la prueba CQT (College Qualification Test),
<span class="math inline">\(X_2\)</span> =aptitud verbal y <span class="math inline">\(X_3\)</span> =ciencias, están dadas en la siguiente tabla.</p>
</div>
<table>
<caption>
<span id="tab:unnamed-chunk-81">Tabla 4.24: </span>Datos de Notas de Prueba CLEP
</caption>
<thead>
<tr>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
<th style="text-align:center;">
X3
</th>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
<th style="text-align:center;">
X3
</th>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
<th style="text-align:center;">
X3
</th>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
<th style="text-align:center;">
X3
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
468
</td>
<td style="text-align:center;">
41
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
488
</td>
<td style="text-align:center;">
51
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
494
</td>
<td style="text-align:center;">
41
</td>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
468
</td>
<td style="text-align:center;">
49
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
428
</td>
<td style="text-align:center;">
39
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
488
</td>
<td style="text-align:center;">
62
</td>
<td style="text-align:center;">
18
</td>
<td style="text-align:center;">
541
</td>
<td style="text-align:center;">
47
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
26
</td>
</tr>
<tr>
<td style="text-align:center;">
514
</td>
<td style="text-align:center;">
53
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
587
</td>
<td style="text-align:center;">
56
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
362
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
17
</td>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
47
</td>
<td style="text-align:center;">
31
</td>
</tr>
<tr>
<td style="text-align:center;">
547
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
33
</td>
<td style="text-align:center;">
421
</td>
<td style="text-align:center;">
38
</td>
<td style="text-align:center;">
16
</td>
<td style="text-align:center;">
408
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
17
</td>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
47
</td>
<td style="text-align:center;">
26
</td>
</tr>
<tr>
<td style="text-align:center;">
614
</td>
<td style="text-align:center;">
61
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
481
</td>
<td style="text-align:center;">
52
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
594
</td>
<td style="text-align:center;">
68
</td>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
435
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
28
</td>
</tr>
<tr>
<td style="text-align:center;">
501
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
29
</td>
<td style="text-align:center;">
428
</td>
<td style="text-align:center;">
40
</td>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
501
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
660
</td>
<td style="text-align:center;">
70
</td>
<td style="text-align:center;">
25
</td>
</tr>
<tr>
<td style="text-align:center;">
421
</td>
<td style="text-align:center;">
46
</td>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
640
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
687
</td>
<td style="text-align:center;">
75
</td>
<td style="text-align:center;">
33
</td>
<td style="text-align:center;">
733
</td>
<td style="text-align:center;">
73
</td>
<td style="text-align:center;">
33
</td>
</tr>
<tr>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
50
</td>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
574
</td>
<td style="text-align:center;">
61
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
633
</td>
<td style="text-align:center;">
52
</td>
<td style="text-align:center;">
31
</td>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
45
</td>
<td style="text-align:center;">
28
</td>
</tr>
<tr>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
55
</td>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
547
</td>
<td style="text-align:center;">
64
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
647
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
29
</td>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
62
</td>
<td style="text-align:center;">
29
</td>
</tr>
<tr>
<td style="text-align:center;">
620
</td>
<td style="text-align:center;">
72
</td>
<td style="text-align:center;">
32
</td>
<td style="text-align:center;">
580
</td>
<td style="text-align:center;">
64
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
647
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
34
</td>
<td style="text-align:center;">
428
</td>
<td style="text-align:center;">
37
</td>
<td style="text-align:center;">
19
</td>
</tr>
<tr>
<td style="text-align:center;">
587
</td>
<td style="text-align:center;">
63
</td>
<td style="text-align:center;">
31
</td>
<td style="text-align:center;">
494
</td>
<td style="text-align:center;">
53
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
614
</td>
<td style="text-align:center;">
59
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
481
</td>
<td style="text-align:center;">
48
</td>
<td style="text-align:center;">
23
</td>
</tr>
<tr>
<td style="text-align:center;">
541
</td>
<td style="text-align:center;">
59
</td>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
554
</td>
<td style="text-align:center;">
51
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
633
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
61
</td>
<td style="text-align:center;">
19
</td>
</tr>
<tr>
<td style="text-align:center;">
561
</td>
<td style="text-align:center;">
53
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
647
</td>
<td style="text-align:center;">
58
</td>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
448
</td>
<td style="text-align:center;">
55
</td>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
66
</td>
<td style="text-align:center;">
23
</td>
</tr>
<tr>
<td style="text-align:center;">
468
</td>
<td style="text-align:center;">
62
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
408
</td>
<td style="text-align:center;">
51
</td>
<td style="text-align:center;">
19
</td>
<td style="text-align:center;">
488
</td>
<td style="text-align:center;">
41
</td>
<td style="text-align:center;">
28
</td>
</tr>
<tr>
<td style="text-align:center;">
614
</td>
<td style="text-align:center;">
65
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
454
</td>
<td style="text-align:center;">
52
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
441
</td>
<td style="text-align:center;">
35
</td>
<td style="text-align:center;">
22
</td>
<td style="text-align:center;">
607
</td>
<td style="text-align:center;">
69
</td>
<td style="text-align:center;">
28
</td>
</tr>
<tr>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
48
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
427
</td>
<td style="text-align:center;">
57
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
435
</td>
<td style="text-align:center;">
60
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
561
</td>
<td style="text-align:center;">
59
</td>
<td style="text-align:center;">
34
</td>
</tr>
<tr>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
32
</td>
<td style="text-align:center;">
27
</td>
<td style="text-align:center;">
521
</td>
<td style="text-align:center;">
66
</td>
<td style="text-align:center;">
26
</td>
<td style="text-align:center;">
501
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
614
</td>
<td style="text-align:center;">
70
</td>
<td style="text-align:center;">
23
</td>
</tr>
<tr>
<td style="text-align:center;">
580
</td>
<td style="text-align:center;">
64
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
468
</td>
<td style="text-align:center;">
57
</td>
<td style="text-align:center;">
14
</td>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
42
</td>
<td style="text-align:center;">
24
</td>
<td style="text-align:center;">
527
</td>
<td style="text-align:center;">
49
</td>
<td style="text-align:center;">
30
</td>
</tr>
<tr>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
59
</td>
<td style="text-align:center;">
21
</td>
<td style="text-align:center;">
587
</td>
<td style="text-align:center;">
55
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
620
</td>
<td style="text-align:center;">
71
</td>
<td style="text-align:center;">
36
</td>
<td style="text-align:center;">
474
</td>
<td style="text-align:center;">
41
</td>
<td style="text-align:center;">
16
</td>
</tr>
<tr>
<td style="text-align:center;">
521
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
61
</td>
<td style="text-align:center;">
31
</td>
<td style="text-align:center;">
415
</td>
<td style="text-align:center;">
52
</td>
<td style="text-align:center;">
20
</td>
<td style="text-align:center;">
441
</td>
<td style="text-align:center;">
47
</td>
<td style="text-align:center;">
26
</td>
</tr>
<tr>
<td style="text-align:center;">
574
</td>
<td style="text-align:center;">
52
</td>
<td style="text-align:center;">
25
</td>
<td style="text-align:center;">
574
</td>
<td style="text-align:center;">
54
</td>
<td style="text-align:center;">
31
</td>
<td style="text-align:center;">
554
</td>
<td style="text-align:center;">
69
</td>
<td style="text-align:center;">
30
</td>
<td style="text-align:center;">
607
</td>
<td style="text-align:center;">
67
</td>
<td style="text-align:center;">
32
</td>
</tr>
<tr>
<td style="text-align:center;">
587
</td>
<td style="text-align:center;">
64
</td>
<td style="text-align:center;">
31
</td>
<td style="text-align:center;">
507
</td>
<td style="text-align:center;">
53
</td>
<td style="text-align:center;">
23
</td>
<td style="text-align:center;">
348
</td>
<td style="text-align:center;">
28
</td>
<td style="text-align:center;">
18
</td>
<td style="text-align:center;">
NA
</td>
<td style="text-align:center;">
NA
</td>
<td style="text-align:center;">
NA
</td>
</tr>
</tbody>
</table>
<p>De los datos se tiene que:
<span class="math display">\[
\underline{\overline{\mathbf{x}}}=\begin{bmatrix}
526.586 \\ 54.69 \\ 25.126
\end{bmatrix} \ , \ \ \ \ \mathbf{S}=\begin{bmatrix}
5808.059 &amp; 597.835 &amp; 222.03 \\
597.835 &amp; 126.054 &amp; 23.389 \\
222.03 &amp; 23.389 &amp; 23.112
\end{bmatrix}
\]</span></p>
<p>Los intervalos de confianza del <span class="math inline">\(95\%\)</span> para las componentes del vector de medias son:</p>
<p><span class="math display">\[
\left(  \overline{x}_1 - \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{11}}{n}} \ \ , \ \   \overline{x}_1 + \sqrt{\frac{(n-1)p}{(n-p)}F_{\alpha; p, n-p}}   \sqrt{\frac{s_{11}}{n}}  \right)
\]</span></p>
<p><span class="math display">\[
\left( 526.586 - \sqrt{\frac{(86)3}{84}2.7132}   \sqrt{\frac{5808.059}{87}} \ \ , \ \  526.586 + \sqrt{\frac{(86)3}{84}2.7132}   \sqrt{\frac{5808.059}{87}}   \right)
\]</span></p>
<p><span class="math display">\[
\mu_1 \ \ \in \ \ \left( 502.999 \ \ , \ \  550.173   \right)
\]</span></p>
<p><span class="math display">\[
\left(  \overline{x}_2 - \sqrt{\frac{(n-1)p}{(n-p)}F_{p, n-p}(\alpha)}   \sqrt{\frac{s_{22}}{n}} \ \ , \ \   \overline{x}_2 + \sqrt{\frac{(n-1)p}{(n-p)}F_{p, n-p}(\alpha)}   \sqrt{\frac{s_{22}}{n}}  \right)
\]</span></p>
<p><span class="math display">\[
\left( 54.69 - \sqrt{\frac{(86)3}{84}2.7132}   \sqrt{\frac{126.054}{87}} \ \ , \ \  54.69 + \sqrt{\frac{(86)3}{84}2.7132}   \sqrt{\frac{126.054}{87}}   \right)
\]</span></p>
<p><span class="math display">\[
\mu_2 \ \ \in \ \ \left( 51.215 \ \ , \ \  58.165   \right)
\]</span></p>
<p><span class="math display">\[
\left(  \overline{x}_3 - \sqrt{\frac{(n-1)p}{(n-p)}F_{p, n-p}(\alpha)}   \sqrt{\frac{s_{33}}{n}} \ \ , \ \   \overline{x}_3 + \sqrt{\frac{(n-1)p}{(n-p)}F_{p, n-p}(\alpha)}   \sqrt{\frac{s_{33}}{n}}  \right)
\]</span></p>
<p><span class="math display">\[
\left( 25.126 - \sqrt{\frac{(86)3}{84}2.7132}   \sqrt{\frac{23.112}{87}} \ \ , \ \  25.126 + \sqrt{\frac{(86)3}{84}2.7132}   \sqrt{\frac{23.112}{87}}   \right)
\]</span></p>
<p><span class="math display">\[
\mu_3 \ \ \in \ \  \left( 23.638 \ \ , \ \  26.614   \right)
\]</span></p>
<p>Con la posible excepción de las notas sobre aptitud verbal <span class="math inline">\(X_2\)</span>, los gráficos <span class="math inline">\(Q-Q\)</span> y los diagramas de dispersión para cada par de variables no rebelan serios alejamientos de la normalidad.
Además, como lo veremos, aunque los datos no sean normalmente distribuidos, la metodología se puede justificar dado que la muestra es lo suficientemente grande.</p>
<p>Los intervalos <span class="math inline">\(T^2\)</span>-simultáneos son más amplios que los intervalos univariados debido a que los 3 intervalos son válidos para una misma confianza del <span class="math inline">\(95\%\)</span>.</p>
</div>
</div>
<div id="ic-t2-simultáneos-para-diferencias-de-medias" class="section level3 hasAnchor" number="4.9.4">
<h3><span class="header-section-number">4.9.4</span> IC <span class="math inline">\(T^2\)</span> Simultáneos para Diferencias de Medias<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#ic-t2-simultáneos-para-diferencias-de-medias" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los intervalos obtenidos anteriormente pueden ser más amplios de lo necesario, debido a que, con la misma confianza, podemos hacer inferencias para cualquier combinación lineal de las componentes de medias, tales como las diferencias de medias.</p>
<p>Por ejemplo, con <span class="math inline">\(\underline{a}=\begin{bmatrix} 0 \\ 1\\ -1 \end{bmatrix}\)</span> el intervalo para <span class="math inline">\(\mu_2-\mu_3\)</span>, tiene los siguientes límites:
<span class="math display">\[
(\overline{x}_2- \overline{x}_3) \ \ \pm \ \  \sqrt{\frac{(n-1)p}{(n-p)}F_{p, n-p}(\alpha)}   \sqrt{\frac{s_{22}+s_{33}-2s_{23}}{n}}
\]</span></p>
<p><span class="math display">\[
(54.69 - 25.126) \ \ \pm \ \  \sqrt{\frac{(87-1)3}{(87-3)}F_{1-\alpha\ ;\ p, n-p}}   \sqrt{\frac{126.054 + 23.112 - 2 (23.389) }{87}}
\]</span>
<span class="math display">\[
(29.564) \ \ \pm \ \  \sqrt{ 8.3335 } \sqrt{\frac{102.388}{87}}
\]</span></p>
<p><span class="math display">\[
(29.564) \ \ \pm \ \    3.1317
\]</span></p>
<p><span class="math display">\[
\mu_1-\mu_2 \ \ \in \ \  \biggl(
26.4323 \ \ , \ \
32.6957  
\biggr)
\]</span></p>
<p>Por tanto, <span class="math inline">\(\biggl(26.4323 \ \ , \ \ 32.6957 \biggr)\)</span> es un intervalo de confianza del <span class="math inline">\(95\%\)</span> para <span class="math inline">\(\mu_2-\mu_3\)</span>.</p>
<p>Similarmente, se pueden construir intervalos simultáneos para las otras diferencias de medias.</p>
<p>Finalmente, se pueden construir elipses de confianza del <span class="math inline">\(95\%\)</span> para cada par de medias y los mismos intervalos de confianza <span class="math inline">\(T^2\)</span>-simultáneos del <span class="math inline">\(95\%\)</span> se mantienen. Por ejemplo, para el par de medias <span class="math inline">\((\mu_2,\mu_3)\)</span>, se tiene que:</p>
<p><span class="math display">\[
n\begin{bmatrix}
\overline{x}_2-\mu_2 \\ \overline{x}_3-\mu_3
\end{bmatrix}^t \begin{bmatrix}
s_{22} &amp; s_{23} \\ s_{23} &amp; s_{33}
\end{bmatrix}^{-1}  \begin{bmatrix}
\overline{x}_2-\mu_2 \\ \overline{x}_3-\mu_3
\end{bmatrix}  \leq c^2=\frac{(n-1)p}{(n-p)}F_{p,n-p}(\alpha)
\]</span></p>
<p>o equivalentemente:</p>
<p><span class="math display">\[
\begin{bmatrix}
\overline{x}_2-\mu_2 \\ \overline{x}_3-\mu_3
\end{bmatrix}^t \begin{bmatrix}
s_{22} &amp; s_{23} \\ s_{23} &amp; s_{33}
\end{bmatrix}^{-1}  \begin{bmatrix}
\overline{x}_2-\mu_2 \\ \overline{x}_3-\mu_3
\end{bmatrix}  \leq k^2 \ \ \ \ \ \ \ \text{con:}\ \ \ \ \ \ k^2=\frac{c^2}{n}= \frac{\frac{(n-1)p}{(n-p)}F_{p,n-p}(\alpha)}{n}
\]</span></p>
<p>Para este ejemplo:</p>
<p><span class="math display">\[
87\begin{bmatrix}
54.69-\mu_2 \\ 25.13-\mu_3
\end{bmatrix}^t \begin{bmatrix}
126.05 &amp; 23.37 \\ 23.37 &amp; 23.11
\end{bmatrix}^{-1}  \begin{bmatrix}
54.69-\mu_2 \\ 25.13-\mu_3
\end{bmatrix}  \leq  8.3335  = c^2 = \frac{(86)3}{84}(2.7132 )
\]</span></p>
<p>equivalentemente a:</p>
<p><span class="math display">\[
\begin{bmatrix}
54.69-\mu_2 \\ 25.13-\mu_3
\end{bmatrix}^t \begin{bmatrix}
126.05 &amp; 23.37 \\ 23.37 &amp; 23.11
\end{bmatrix}^{-1}  \begin{bmatrix}
54.69-\mu_2 \\ 25.13-\mu_3
\end{bmatrix}  \leq  0.0958 = k^2  = \frac{c^2}{n} = \frac{  \frac{(86)3}{84}(2.7132)}{87}
\]</span></p>
<p>o equivalentemente:
<span class="math display">\[
0.849(54.69-\mu_2)^2+4.633(25.13-\mu_3)^2-2(54.69-\mu_2)(25.13-\mu_3)\leq 8.3335
\]</span></p>
<p>La siguiente gráfica presenta la elipse de confianza anterior del <span class="math inline">\(95\%\)</span> y las elipses para los otros 2-pares de medias, junto con los intervalos generados por las sombras o proyecciones de las elipses sobre los ejes de medias, los cuales son los respectivos intervalos de confianza <span class="math inline">\(T^2\)</span>-simultáneos.</p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
<div id="comparación-de-los-intervalos-de-confianza-simultáneos-con-los-intervalos-univariados-o-uno-a-la-vez" class="section level4 hasAnchor" number="4.9.4.1">
<h4><span class="header-section-number">4.9.4.1</span> Comparación de los Intervalos de Confianza Simultáneos con los Intervalos Univariados o uno a la vez<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#comparación-de-los-intervalos-de-confianza-simultáneos-con-los-intervalos-univariados-o-uno-a-la-vez" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Una aproximación alternativa para construir intervalos de confianza es considerar las componentes de <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> una a una con <span class="math inline">\(\underline{a}^t=(0, \cdots , a_i, \cdots,0)\)</span> con <span class="math inline">\(a_i=1\)</span>.</p>
<p>Esta aproximación ignora la estructura de covarianza de las <span class="math inline">\(p\)</span> variables y conduce a los intervalos dados por:
<span class="math display">\[
\overline{x}_1 - t_{\alpha/2\ ;\ n-1}  \sqrt{\frac{s_{11}}{n}} \leq \mu_1 \leq \overline{x}_1 + t_{\alpha/2\ ;\ n-1}  \sqrt{\frac{s_{11}}{n}}
\]</span>
<span class="math display">\[
\overline{x}_2 - t_{\alpha/2\ ;\ n-1}  \sqrt{\frac{s_{22}}{n}} \leq \mu_2 \leq \overline{x}_2 + t_{\alpha/2\ ;\ n-1}  \sqrt{\frac{s_{22}}{n}}
\]</span>
<span class="math display">\[
\vdots
\]</span>
<span class="math display">\[
\overline{x}_p - t_{\alpha/2\ ;\ n-1}  \sqrt{\frac{s_{pp}}{n}} \leq \mu_p \leq \overline{x}_p + t_{\alpha/2\ ;\ n-1}  \sqrt{\frac{s_{pp}}{n}}
\]</span></p>
<p>Aunque, antes de muestrear, el <span class="math inline">\(i\)</span>-ésimo intervalo tiene probabilidad <span class="math inline">\(1-\alpha\)</span> de contener a <span class="math inline">\(\mu_i\)</span>, sin embargo, en general no se puede asegurar cuál es la probabilidad de que todos los intervalos contengan a sus respectivos <span class="math inline">\(\mu_i\)</span>. Como se ha señalado, esta probabilidad no es <span class="math inline">\(1-\alpha\)</span>.</p>
<div class="example">
<p><span id="exm:ejemplo-comparación-de-ics" class="example"><strong>Ejemplo 4.31  (Comparación de ICS T2-Simultáneos con IC Individuales) </strong></span>Considere el caso especial donde las observaciones proceden de una distribución normal conjunta, con</p>
</div>
<p><span class="math display">\[
\mathbf{\Sigma}=\begin{bmatrix}
\sigma_{11} &amp; 0 &amp; \cdots &amp; 0 \\
&amp; \sigma_{22} &amp; \cdots &amp; 0 \\
&amp; &amp; \ddots &amp; \\
&amp;  &amp;  &amp; \sigma_{pp}
\end{bmatrix}
\]</span></p>
<p>es decir, las variables son independientes.</p>
<p>Sea <span class="math inline">\(I_i\)</span> el intervalo aleatorio para <span class="math inline">\(\mu_i\)</span> con probabilidad <span class="math inline">\((1-\alpha)\)</span>.</p>
<p>Debido a la independencia de las variables, se tiene que antes de que la muestra sea seleccionada se cumple que:</p>
<p><span class="math display">\[
\begin{align*}
&amp; P\biggl[ \text{Todos los t-intervalos contengan las} \ \mu_i \biggr]\\ \\ &amp;=P\biggl[\mu_1\in I_1 ,\mu_2\in I_2 , \ldots , \mu_p\in I_p \biggr] \\  \\ &amp;= \prod_{i=1}^p P\bigl[\mu_i\in I_i\bigr] \\ \\  &amp;=(1-\alpha)(1-\alpha)\cdots(1-\alpha)\\ \\ &amp;=(1-\alpha)^p
\end{align*}
\]</span></p>
<p>de donde por ejemplo, si <span class="math inline">\((1-\alpha)=0.95\)</span> y <span class="math inline">\(p=6\)</span>, entonces:
<span class="math display">\[
P\biggl[ \text{Todos los t-intervalos contengan las} \ \mu_i \biggr] =(0.95)^6=0.74.
\]</span></p>
<p>Para garantizar una probabilidad de <span class="math inline">\(1-\alpha\)</span> de que todos los intervalos contengan simultáneamente la componente de media respectiva <span class="math inline">\(\mu_i\)</span>, los intervalos individuales deberían ser más amplios que los intervalos separados basados en la <span class="math inline">\(t\)</span>-student, y el qué tan ancho, depende tanto de <span class="math inline">\(p\)</span> como de <span class="math inline">\(n\)</span> al igual que de <span class="math inline">\((1-\alpha)\)</span>.</p>
<p><strong>Por ejemplo:</strong> Para <span class="math inline">\((1-\alpha)=0.95\)</span>, <span class="math inline">\(n=15\)</span> y <span class="math inline">\(p=4\)</span>, el factor multiplicador de la cantidad:
<span class="math display">\[
\sqrt{ \frac{s_{ii}}{n}}
\]</span></p>
<p>para los intervalos separados (o individuales) es:</p>
<p><span class="math display">\[
t_{\alpha/2;n-1}=t_{0.025,14}=2.145
\]</span></p>
<p>y para los intervalos <span class="math inline">\(T^2\)</span>-simultáneos dicho factor es:
<span class="math display">\[
\sqrt{\frac{(n-1)p}{n-p}F_{\alpha;p,n-p}}=\sqrt{\frac{(14)4}{11}F_{0.05;4,11}}=\sqrt{\frac{56}{11}(3.36)}=4.14
\]</span></p>
<p>de donde en este caso, se tiene que los I.C <span class="math inline">\(T^2\)</span>-simultáneos son:
<span class="math display">\[
\frac{(4.14-2.145)}{2.145}100\%=93\%
\]</span></p>
<p>más anchos, que aquellos intervalos derivados usando la <span class="math inline">\(t\)</span>-student (o individuales).</p>
<p>En general, el ancho de los intervalos <span class="math inline">\(T^2\)</span>-simultáneos, relativo al ancho de los <span class="math inline">\(t\)</span>-intervalos individuales crece para <span class="math inline">\(n\)</span>-fijo, cuando <span class="math inline">\(p\)</span>-crece; y decrece para <span class="math inline">\(p\)</span>-fijo, cuando <span class="math inline">\(n\)</span>-crece. Ver la siguiente tabla del libro <span class="citation">(<a href="#ref-johnson2007applied">Johnson and Wichern 2007</a>)</span>, Pág. 231.</p>
<p><span class="math display">\[
\begin{array}{c|c|cc}\hline
&amp;&amp;\sqrt{\frac{(n-1)p}{n-p}\ F_{p\ ,\ n-p}(0.05)\ \ }\\\hline
n &amp; t_{n-1}(0.025) &amp; p=4 &amp; p=10 \\\hline
15&amp;2.145&amp;4.14&amp;11.52\\
25&amp;2.064&amp;3.60&amp;6.39\\
50&amp;2.010&amp;3.31&amp;5.05\\
100&amp;1.970&amp;3.19&amp;4.61\\
\infty &amp;1.960&amp;3.08&amp;4.28\\\hline
\end{array}
\]</span></p>
<p>La comparación de la tabla anterior es un poco injusta debido a que para <span class="math inline">\(n\)</span> fijo, el nivel de confianza asociada a un conjunto de intervalos <span class="math inline">\(T^2\)</span>-simultáneos es <span class="math inline">\(1-\alpha\)</span>, mientras que la confianza asociada a un conjunto de intervalos <span class="math inline">\(t\)</span>-student, para el mismo <span class="math inline">\(n\)</span>, puede ser menor que <span class="math inline">\(1-\alpha\)</span>, como vimos anteriormente.</p>
<p>Los intervalos <span class="math inline">\(t\)</span>-student son demasiado cortos (o precisos) para mantener un nivel de confianza global para los intervalos separados sobre, por ejemplo, las <span class="math inline">\(p\)</span> medias. Sin embargo, algunas veces se les considera la
mejor información posible sobre una media <span class="math inline">\(\mu_i\)</span> si es la única inferencia que nos interesa. Además, algunos investigadores piensan que <em>si se calculan los intervalos separados solamente cuando la prueba <span class="math inline">\(T^2\)</span>-de Hotelling rechaza la hipótesis nula, ellos pueden representar con más precisión la información sobre las medias <span class="math inline">\(\mu_i\)</span> que los intervalos <span class="math inline">\(T^2\)</span>-simultáenos</em>.</p>
<p>Los intervalos <span class="math inline">\(T^2\)</span>-<em>simultáneos son demasiado amplios si se aplican solamente a las <span class="math inline">\(p\)</span>-componentes de medias</em>. Para ver el porqué, considere la elipse de confianza y los intervalos <span class="math inline">\(T^2\)</span>-simultáneos del ejemplo anterior:</p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<p>Si <span class="math inline">\(\mu_1\)</span> cae en su intervalo <span class="math inline">\(T^2\)</span>-simultáneo y <span class="math inline">\(\mu_2\)</span> cae en su intervalo <span class="math inline">\(T^2\)</span>-simultáneo, entonces <span class="math inline">\((\mu_1 \ , \ \mu_2)\)</span> <em>cae en el rectángulo formado por estos dos intervalos</em>.</p>
<p><em>Este rectángulo contiene la elipse de confianza y algo más</em>. La elipse de confianza es más pequeña que el rectángulo, pero dicha elipse tiene una probabilidad <span class="math inline">\(1-\alpha\)</span> de contener al vector <span class="math inline">\(\underline{\boldsymbol \mu}=\begin{pmatrix} \mu_1 \\ \mu_2 \end{pmatrix}\)</span>.</p>
<p>En consecuencia, la probabilidad de contener la dos medias individuales <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span> será mayor que <span class="math inline">\(1-\alpha\)</span> <em>para el rectángulo formado por los intervalos <span class="math inline">\(T^2\)</span>-simultáneos</em>.</p>
<p>Este resultado conduce a considerar una segunda aproximación para hacer comparaciones simultáneas.</p>
</div>
</div>
<div id="IC-Bonferroni" class="section level3 hasAnchor" number="4.9.5">
<h3><span class="header-section-number">4.9.5</span> Método de Bonferroni para Comparaciones Múltiples<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#IC-Bonferroni" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Frecuentemente la atención está restringida a un número pequeño de intervalos de confianza.</p>
<p>En estos casos la metodología de los intervalos <span class="math inline">\(T^2\)</span>-simultáneos puede conducir a intervalos demasiado amplios.</p>
<p>Si el interés se centra en un número pequeño <span class="math inline">\(m\)</span> de componentes de medias especificas <span class="math inline">\(\mu_i\)</span> o de <span class="math inline">\(m\)</span> combinaciones lineales de la forma <span class="math inline">\(\underline{a}^t\underline{\boldsymbol{\mu}}=a_1\mu_1+a_2\mu_2+\cdots+a_p\mu_p\)</span> entonces, se pueden construir <strong>I.C simultáneos mas cortos</strong> (<em>más precisos</em>) que los intervalos <span class="math inline">\(T^2\)</span>-simultáneos.</p>
<p>El método alternativo a usar en este caso se llama: <strong>Método de Bonferroni</strong>, debido a que ha sido desarrollado a partir de la Desigualdad de Bonferroni, que se enuncia como sigue:</p>
<p>Para una familia finita o numerable de sucesos <span class="math inline">\(A_1\)</span>, <span class="math inline">\(A_2\)</span>, <span class="math inline">\(A_3\)</span>, <span class="math inline">\(\cdots\)</span>, se cumple:
<span class="math display">\[
P\biggl[ \bigcup_{i} A_i \biggr] \leq \sum_{i} P \bigl[A_i \bigr]
\]</span></p>
<p>Suponga que antes de recolectar los datos, se quieren construir intervalos de confianza simultáneos para <span class="math inline">\(m\)</span>-combinaciones lineales de la forma:
<span class="math display">\[
\underline{a}_1^t\underline{\boldsymbol{\mu}},\ \ \underline{a}_2^t\underline{\boldsymbol{\mu}}, \ \ \cdots , \ \  \underline{a}_m^t\underline{\boldsymbol{\mu}}
\]</span></p>
<p>Sea <span class="math inline">\(C_i\)</span> el intervalo para <span class="math inline">\(\underline{a}_i^t\underline{\boldsymbol{\mu}}\)</span>,    con:
<span class="math display">\[
P\biggl[\ \ C_i \ \ \text{contenga a:}\ \ \underline{a}_i^t\underline{\boldsymbol{\mu}}\ \ \biggr]=1-\alpha_i \ \ , \ \ \text{para} \ \ \ i=1,2,\ldots,m
\]</span></p>
<p>entonces se cumple que:
<span class="math display">\[
\begin{align*}
&amp; P\biggl[\ \underline{a}_1^t\underline{\boldsymbol{\mu}} \in C_1 \ , \ \underline{a}_2^t\underline{\boldsymbol{\mu}} \in C_2 \ , \ \cdots \ , \ \underline{a}_m^t\underline{\boldsymbol{\mu}} \in C_m \biggr] \\ \\
&amp;= P\left[\bigcap\limits_{i=1}^m  \underline{a}_i^t\underline{\boldsymbol{\mu}} \in C_i  \right]=1- P\left[\left( \bigcap\limits_{i=1}^m  \underline{a}_i^t\underline{\boldsymbol{\mu}} \in C_i \right)^c  \right]  \\ \\
&amp;= 1- P\left[ \bigcup\limits_{i=1}^m  \underline{a}_i^t\underline{\boldsymbol{\mu}} \not\in  C_i   \right] \geq  1- \sum\limits_{i=1}^m P\left[  \underline{a}_i^t\underline{\boldsymbol{\mu}} \not\in  C_i   \right]  \\ \\
&amp;=1- \sum\limits_{i=1}^m  \biggl[ 1- P\left(  \underline{a}_i^t\underline{\boldsymbol{\mu}} \in  C_i    \right) \biggr]  \\ \\
&amp;= 1-\biggl[ 1-(1-\alpha_1)+1-(1-\alpha_2)+\cdots+1-(1-\alpha_m) \biggr]\\ \\
&amp;= 1-\bigl[\alpha_1+\alpha_2+\cdots+\alpha_m \bigr]=1-\sum\limits_{i=1}^m \alpha_i
\end{align*}
\]</span></p>
<p>es decir,
<span class="math display">\[
P\biggl[\ \underline{a}_1^t\underline{\boldsymbol{\mu}} \in C_1 \ , \ \underline{a}_2^t\underline{\boldsymbol{\mu}} \in C_2 \ , \ \cdots \ , \ \underline{a}_m^t\underline{\boldsymbol{\mu}} \in C_m\biggr] \geq
1-\biggl(\alpha_1+\alpha_2+\cdots+\alpha_m \biggr)
\]</span>
La expresión anterior es un caso especial de la desigualdad de Bonferroni y permite al investigador controlar el error global <span class="math inline">\(\alpha_1+\alpha_2+\cdots+\alpha_m\)</span>, <em>sin tener en cuenta la estructura de correlación del sistema de variables aleatorias</em>.</p>
<p>También tiene la flexibilidad de controlar la tasa de error global de un grupo de intervalos importantes y balancearla con otra elección de los intervalos menos importantes.</p>
<div id="ic-simultáneos-para-un-grupo-restringido-de-componentes-mu_i." class="section level4 hasAnchor" number="4.9.5.1">
<h4><span class="header-section-number">4.9.5.1</span> IC Simultáneos para un Grupo Restringido de Componentes <span class="math inline">\(\mu_i\)</span>.<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#ic-simultáneos-para-un-grupo-restringido-de-componentes-mu_i." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Considere los intervalos <span class="math inline">\(t\)</span>-student individuales:
<span class="math display">\[
\underline{\overline{\mathbf{x}}}_i \ \ \pm \ \ t_{\alpha_i/2\ ; \ n-1}\sqrt{\frac{s_{ii}}{n}} \ , \ \ \text{para} \ \ i=1,2,\ldots,m
\]</span></p>
<p>con <span class="math inline">\(\alpha_i=\alpha/m\)</span>, es decir que:</p>
<p><span class="math display">\[
\underline{\overline{\mathbf{x}}}_i \ \ \pm \ \ t_{\alpha/2m\ ; \ n-1}\ \sqrt{\frac{s_{ii}}{n}} \ , \ \ \text{para} \ \ i=1,2,\ldots,m
\]</span></p>
<p>Ahora, puesto que,
<span class="math display">\[
P\left[\mu_i \in \left( \underline{\overline{\mathbf{x}}}_i - t_{\alpha_i/2\ ; \ n-1}\sqrt{\frac{s_{ii}}{n}} \ \ ,\ \ \underline{\overline{\mathbf{x}}}_i + t_{\alpha_i/2\ ; \ n-1}\sqrt{\frac{s_{ii}}{n}}    \right) \right]=1-\alpha_i=1-\alpha/m
\]</span></p>
<p>para cada <span class="math inline">\(i=1,2,\ldots,m\)</span>, entonces por la anterior desigualdad se tiene que:</p>
<p><span class="math display">\[
\begin{align*}
&amp;P\left[\mu_i \in \left( \underline{\overline{\mathbf{x}}}_i - t_{\alpha_i/2\ ; \ n-1}\sqrt{\frac{s_{ii}}{n}} \ , \ \underline{\overline{\mathbf{x}}}_i + t_{\alpha_i/2\ ; \ n-1}\sqrt{\frac{s_{ii}}{n}}    \right)\ \ , \ \ \text{para todo} \ i \right]\\ \\  &amp;\geq 1- \sum\limits_{i=1}^m\alpha_i \\ \\
&amp;= 1- \left(\frac{\alpha}{m}+\frac{\alpha}{m}+\cdots +\frac{\alpha}{m} \right)=1-m\biggl(\frac{\alpha}{m}\biggr) \\ \\
&amp;= 1-\alpha
\end{align*}
\]</span></p>
<p>Por lo tanto, <em>con un nivel de confianza global</em> <strong>mayor o igual a</strong> <span class="math inline">\(1-\alpha\)</span>, <em>los siguientes intervalos simultáneos son válidos para las <span class="math inline">\(p\)</span> medias</em>:</p>
<p><span class="math display">\[
\overline{x}_1 - t_{\frac{\alpha}{2p}\ ;\ n-1}  \sqrt{\frac{s_{11}}{n}} \leq \mu_1 \leq \overline{x}_1 + t_{\frac{\alpha}{2p}\ ;\ n-1}  \sqrt{\frac{s_{11}}{n}}
\]</span></p>
<p><span class="math display">\[
\overline{x}_2 - t_{\frac{\alpha}{2p}\ ;\ n-1}  \sqrt{\frac{s_{2}}{n}} \leq \mu_2 \leq \overline{x}_2 + t_{\frac{\alpha}{2p}\ ;\ n-1}  \sqrt{\frac{s_{2}}{n}}
\]</span></p>
<p><span class="math display">\[
\vdots
\]</span></p>
<p><span class="math display">\[
\vdots
\]</span></p>
<p><span class="math display">\[
\overline{x}_p - t_{\frac{\alpha}{2p}\ ;\ n-1}  \sqrt{\frac{s_{pp}}{n}} \leq \mu_p \leq \overline{x}_p + t_{\frac{\alpha}{2p}\ ;\ n-1}  \sqrt{\frac{s_{pp}}{n}}
\]</span></p>
<div class="example">
<p><span id="exm:ejemplo-ics-bonferroni" class="example"><strong>Ejemplo 4.32  (Ejemplo IC Simultáneos de Bonferroni) </strong></span>En el ejemplo <a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#exm:ejemplo1-region-confianza">4.26</a> sobre datos de radiación se construyó una elipse del <span class="math inline">\(95\%\)</span> de confianza para las medias de la raíz cuarta de las variables de radiación a puerta cerrada y a puerta abierta de hornos microondas.</p>
</div>
<table>
<caption>
<span id="tab:unnamed-chunk-86">Tabla 4.25: </span>Datos de Radiación
</caption>
<thead>
<tr>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
<th style="text-align:center;">
X1
</th>
<th style="text-align:center;">
X2
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.03
</td>
<td style="text-align:center;">
0.05
</td>
</tr>
<tr>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.05
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.15
</td>
</tr>
<tr>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.30
</td>
</tr>
<tr>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.15
</td>
<td style="text-align:center;">
0.15
</td>
</tr>
<tr>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
</tr>
<tr>
<td style="text-align:center;">
0.08
</td>
<td style="text-align:center;">
0.09
</td>
<td style="text-align:center;">
0.18
</td>
<td style="text-align:center;">
0.28
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.07
</td>
<td style="text-align:center;">
0.07
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.11
</td>
<td style="text-align:center;">
0.10
</td>
</tr>
<tr>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.30
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.45
</td>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.25
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.20
</td>
<td style="text-align:center;">
0.20
</td>
</tr>
<tr>
<td style="text-align:center;">
0.02
</td>
<td style="text-align:center;">
0.04
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.40
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.33
</td>
</tr>
<tr>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.01
</td>
<td style="text-align:center;">
0.40
</td>
<td style="text-align:center;">
0.32
</td>
</tr>
<tr>
<td style="text-align:center;">
0.40
</td>
<td style="text-align:center;">
0.60
</td>
<td style="text-align:center;">
0.30
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
<tr>
<td style="text-align:center;">
0.10
</td>
<td style="text-align:center;">
0.12
</td>
<td style="text-align:center;">
0.05
</td>
<td style="text-align:center;">
0.12
</td>
</tr>
</tbody>
</table>
<p>Los intervalos <span class="math inline">\(T^2\)</span>-simultáneos del <span class="math inline">\(95\%\)</span> de confianza para las componentes del vector de medias fueron:
<span class="math display">\[
\left(  \overline{x}_1 - \sqrt{\frac{(n-1)p}{(n-p)}\ F_{\alpha\ ;\  p\ ,\  n-p}}\   \sqrt{\frac{s_{11}}{n}} \ \ , \ \   \overline{x}_1 + \sqrt{\frac{(n-1)p}{(n-p)}\ F_{\alpha\ ;\ p\ ,\ n-p}}  \  \sqrt{\frac{s_{11}}{n}}  \right)
\]</span></p>
<p><span class="math display">\[
\left( 0.564 - \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0144}{42}} \ \ , \ \  0.564 + \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0144}{42}}   \right)
\]</span></p>
<p><span class="math display">\[
\mu_1 \ \ \in \ \ \left( 0.5163 \ \ , \ \  0.6117   \right)
\]</span></p>
<p>y para <span class="math inline">\(\underline{\boldsymbol \mu}_2\)</span>
<span class="math display">\[
\left(  \overline{x}_2 - \sqrt{\frac{(n-1)p}{(n-p)}\ F_{\alpha\ ;\ p\ ,\  n-p}}\   \sqrt{\frac{s_{22}}{n}} \ \ , \ \   \overline{x}_2 + \sqrt{\frac{(n-1)p}{(n-p)}\ F_{\alpha\ ;\ p\ ,\  n-p}}\    \sqrt{\frac{s_{22}}{n}}  \right)
\]</span>
<span class="math display">\[
\left( 0.603 - \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0145}{42}} \ \ , \ \  0.603 + \sqrt{\frac{(41)2}{40}3.2317}   \sqrt{\frac{0.0145}{42}}   \right)
\]</span></p>
<p><span class="math display">\[
\mu_2 \ \ \in \ \ \left( 0.5552 \ \ , \ \  0.6508   \right)
\]</span></p>
<p>El siguiente gráfico muestra la elipse de confianza del <span class="math inline">\(95\%\)</span> y los intervalos de confianza <span class="math inline">\(T^2\)</span>-simultáneos del <span class="math inline">\(95\%\)</span>, los cuales son sombras o proyecciones de la elipse sobre los ejes de las componentes del vector de medias.</p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-87-1.png" width="672" /></p>
<p><strong>Ahora, los IC-Simultáneos de Bonferroni están dados por</strong>:
<span class="math display">\[
\overline{x}_1 \ \ \pm \ \ t_{\frac{\alpha}{2p}\ ; \ n-1}\   \sqrt{\frac{s_{11}}{n}}
\]</span></p>
<p><span class="math display">\[
0.564 \ \ \pm \ \ t_{0.05/2(2)\ ;\ 41}  \sqrt{ \frac{0.0144}{42} }
\]</span>
<span class="math display">\[
0.564 \ \ \pm \ \ 0.0374
\]</span></p>
<p><span class="math display">\[
\ \ ie. \ \ \:   0.5266  \leq \mu_1 \leq  0.6014
\]</span></p>
<p>y para <span class="math inline">\(\mu_2\)</span> se tiene:</p>
<p><span class="math display">\[
\overline{x}_2 \ \ \pm \ \ t_{\frac{\alpha}{2p}\ ; \ n-1}\   \sqrt{\frac{s_{33}}{n}}
\]</span></p>
<p><span class="math display">\[
0.603 \ \ \pm \ \ t_{0.05/2(2)\ ;\  41}  \sqrt{ \frac{0.0145}{42} }
\]</span>
<span class="math display">\[
0.603 \ \ \pm \ \ 0.0375
\]</span></p>
<p><span class="math display">\[
\ \ ie. \ \ \:   0.5655  \leq \mu_2 \leq  0.6405
\]</span></p>
<p>El siguiente gráfico muestra los Intervalos de Confianza Simultáneos de Bonferroni del <span class="math inline">\(95\%\)</span> para <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span>. Al igual que la respectiva Región de Confianza.</p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-88-1.png" width="672" /></p>
<p>El siguiente gráfico muestra los Intervalos de Confianza <span class="math inline">\(T^2\)</span>-simultáneos del <span class="math inline">\(95\%\)</span> para <span class="math inline">\(\mu_1\)</span> y <span class="math inline">\(\mu_2\)</span> junto con los Intervalos de Confianza Simultáneos de Bonferroni del <span class="math inline">\(95\%\)</span>. Al igual que la respectiva Región de Confianza.</p>
<p><img src="bookdown-iam_files/figure-html/unnamed-chunk-89-1.png" width="672" /></p>
<p>Para cada componente, el intervalo de Bonferroni cae dentro del correspondiente intervalo <span class="math inline">\(T^2\)</span>.</p>
<p>Por tanto, la región rectangular formada por los Intervalos de Confianza de Bonferroni cae dentro la región rectangular formada por los Intervalos de Confianza <span class="math inline">\(T^2\)</span>-simultáneos.</p>
<p>Por otro lado, la región (o elipse) de confianza del <span class="math inline">\(95\%\)</span> del vector <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> proporciona todos los valores plausibles para los pares <span class="math inline">\((\mu_1 \ , \ \mu_2)\)</span> cuando se tiene en cuenta la correlación entre las variables medidas.</p>
</div>
<div id="comparación-de-ic-t2-simultáneos-con-los-ic-simultáneos-de-bonferroni" class="section level4 hasAnchor" number="4.9.5.2">
<h4><span class="header-section-number">4.9.5.2</span> Comparación de IC <span class="math inline">\(T^2\)</span>-Simultáneos con los IC Simultáneos de Bonferroni<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#comparación-de-ic-t2-simultáneos-con-los-ic-simultáneos-de-bonferroni" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Los intervalos de confianza de Bonferroni para combinaciones lineales <span class="math inline">\(\underline{a}^t \underline{\boldsymbol \mu}\)</span> y los análogos intervalos de confianza <span class="math inline">\(T^2\)</span>-simultáneos, tienen la forma general,</p>
<p><span class="math display">\[
\underline{a}^t \underline{\overline{\mathbf{x}}} \ \ \pm \ \ (\text{Valor Crítico}) \sqrt{\frac{\underline{a}^t \mathbf{S}\underline{a}}{n}}
\]</span></p>
<p>Por tanto, para cada grupo de <span class="math inline">\(m\)</span> intervalos simultáneos la razón entre las longitudes de de los IC de Bonferroni y los IC <span class="math inline">\(T^2\)</span>-Simultáneos está dada por:</p>
<p><span class="math display">\[
\frac{\text{Longitud del Intervalo de Bonferroni}}{\text{Longitud del Intervalo}\ T^2}=\frac{t_{\alpha/2m\ ; \ n-1}}{\sqrt{\frac{(n-1)p}{n-p}\ F_{\alpha\ ; \ p\ ,\ n-p}\ \ }\ \  }
\]</span></p>
<p>lo cual no depende de las cantidades aleatorias <span class="math inline">\(\underline{\overline{\mathbf{x}}}\)</span> y <span class="math inline">\(\mathbf{S}\)</span>. Entre más cercano a uno esté dicha razón, mas similares son dichos intervalos, y entre más alejado de uno esté dicha razón, más precisos son los IC de Bonferroni comparados con los <span class="math inline">\(T^2\)</span>-Simultáneos.</p>
<p>Para un número pequeño <span class="math inline">\(m\)</span> de funciones específicas <span class="math inline">\(\underline{a}^t \underline{\boldsymbol \mu}\)</span>, los intervalos de Bonferroni <em>siempre serán más cortos</em>.</p>
<p>La siguiente tabla muestra cuánto más cortos son para valores seleccionados de <span class="math inline">\(n\)</span> y <span class="math inline">\(p\)</span>.</p>
<p>A continuación se tiene la comparación de la razón entre dichas longitudes para <span class="math inline">\(1-\alpha=0.95\)</span> y <span class="math inline">\(m=p\)</span> para distintos valores.
<span class="math display">\[
\begin{array}{c|ccc}\hline
&amp; &amp; m=p\\\hline
n&amp;2&amp;4&amp;10\\\hline
15&amp;0.88&amp;0.69&amp;0.29\\
25&amp;0.90&amp;0.75&amp;0.48\\
50&amp;0.91&amp;0.78&amp;0.58\\
100&amp;0.91&amp;0.80&amp;0.62\\
\infty &amp;0.91&amp;0.81&amp;0.66\\
\end{array}
\]</span></p>
<p>Se observa que el método de Bonferroni simepre proporciona intervalos más cortos cuando <span class="math inline">\(m=p\)</span>. Debido a que los intervalos simultáneos de Bonferroni son más fáciles de aplicar y son relativamente más cortos para hacer inferencia, en la práctica, <em>generalmente son preferidos</em>.</p>
</div>
</div>
<div id="intervalos-de-confianza-simultáneos-chi2-caso-n-grande" class="section level3 hasAnchor" number="4.9.6">
<h3><span class="header-section-number">4.9.6</span> Intervalos de Confianza Simultáneos <span class="math inline">\(\chi^2\)</span> (caso n-Grande)<a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#intervalos-de-confianza-simultáneos-chi2-caso-n-grande" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cuando el tamaño de la muestra es grande, las pruebas de hipótesis y las regiones de confianza para <span class="math inline">\(\underline{\boldsymbol \mu}\)</span>, pueden construirse sin el supuesto de normalidad. Las desviaciones serias o graves de normalidad pueden superarse con muestras de gran tamaño. Tanto las pruebas de hipótesis como las afirmaciones de confianza simultáneas tendrán entonces (aproximadamente) sus niveles nominales.</p>
<p>Las ventajas asociadas con el uso de muestras grandes pueden compensarse parcialmente por una pérdida de información en la muestra, causada por el uso solamente de las estadísticas de resumen <span class="math inline">\(\underline{\overline{\mathbf{x}}}\)</span> y <span class="math inline">\(\mathbf{S}\)</span>. Por otro lado, debido a que <span class="math inline">\((\underline{\overline{\mathbf{x}}} \ , \ \mathbf{S})\)</span> es una estadística de resumen suficiente para poblaciones normales multivariadas, entonces entre más cerca se encuentre la población objeto de estudio a la normalidad multivariada, la información muestral será utilizada mas eficientemente para hacer inferencias.</p>
<p>Todas las inferencias acerca de <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> en el caso de muestras grandes se basan en la distribución <span class="math inline">\(\chi^2\)</span>. Como se conoce de temas tratados anteriormente para <span class="math inline">\(n\)</span>-grande se tiene que:
<span class="math display">\[
n\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu} \bigr)^t \mathbf{S}^{-1}\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu} \bigr) \approx \chi_p^2
\]</span></p>
<p>por lo tanto:
<span class="math display">\[
P\biggl[ n\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu} \bigr)^t \mathbf{S}^{-1}\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu} \bigr)  \leq \chi_{\alpha\ ,\ p}^2 \biggr]= 1-\alpha
\]</span></p>
<p>donde <span class="math inline">\(\chi_{\alpha\ ,\ p}^2\)</span>-es el percentil <span class="math inline">\((1-\alpha)100\%\)</span> de la distribución <span class="math inline">\(\chi^2\)</span>.</p>
<p>Lo anterior nos lleva a procedimientos de pruebas de hipótesis e intervalos de confianza simultáneos definidos en los resultados que siguen.</p>
<div class="theorem">
<p><span id="thm:teorema-ph-con-reg-confianza-chi2" class="theorem"><strong>Teorema 4.2  (PH a Partir de Regiones de Confianza Chi2) </strong></span>Sea <span class="math inline">\(\underline{\mathbf{x}}_1,\underline{\mathbf{x}}_2,\ldots,\underline{\mathbf{x}}_n\)</span> una m.a de una población <span class="math inline">\(p\)</span>-variada, con media <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> y matriz de var-cov <span class="math inline">\(\mathbf{\Sigma}\)</span>-definida positiva, entonces <em>cuando <span class="math inline">\(n-p\)</span>-es grande</em>, en la prueba de hipóteis:</p>
</div>
<p><span class="math display">\[
\begin{cases} H_{\ 0} \ \ : \ \ \underline{\boldsymbol \mu}=\underline{\boldsymbol \mu}_{\ 0} \\  \\
H_{\ 0} \ \ : \ \ \underline{\boldsymbol \mu}\neq \underline{\boldsymbol \mu}_{\ 0}
\end{cases}
\]</span></p>
<p><em>se rechaza</em> <span class="math inline">\(H_{\ 0}\)</span> en favor de <span class="math inline">\(H_1\)</span> <em>con un nivel de significancia de aproximadamente</em> <span class="math inline">\(\alpha\)</span> si se cumple que:
<span class="math display">\[
n\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu}_{\ 0} \bigr)^t \mathbf{S}^{-1}\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu}_{\ 0} \bigr) &gt; \chi_{\alpha}^2
\]</span></p>
<p>donde <span class="math inline">\(\chi_{\alpha\ ,\ p}^2\)</span>-es el percentil <span class="math inline">\((1-\alpha)100\%\)</span> de la distribución <span class="math inline">\(\chi^2\)</span>.</p>
<p>En el caso del uso de la teoría de la distribución normal (muestras pequeñas) se tenía que:</p>
<p><span class="math display">\[
n\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu} \bigr)^t \mathbf{S}^{-1}\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu} \bigr) \sim \frac{(n-1)p}{n-p}\ F_{a-\alpha\ ,\ p,\ n-p}
\]</span></p>
<p>con lo cual la Estadística de Prueba usada en ambos casos es la misma, ie.
<span class="math display">\[
T^2=n\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu}_{\ 0} \bigr)^t \mathbf{S}^{-1}\bigl(\underline{\overline{\mathbf{x}}}-\underline{\boldsymbol \mu}_{\ 0} \bigr)
\]</span></p>
<p>pero, <em>los valores críticos usados en cada caso son diferentes</em>.</p>
<p>Sin embargo, <strong>ambos procedimientos de pruebas de hipótesis producen los mismos resultados</strong> en los casos en donde la prueba <span class="math inline">\(\chi^2\)</span>-es adecuada, es decir cuando <span class="math inline">\(n\)</span>-es grande, lo cual se debe a que ambos valores críticos</p>
<p><span class="math display">\[
\frac{(n-1)p}{n-p}F_{a-\alpha\ ,\ p,n-p} \ \ \ \ \ \text{y} \ \ \ \ \ \chi_{\alpha\ , \ p}^2
\]</span></p>
<p>son aproximadamente iguales en el caso de <span class="math inline">\(n\)</span>-grande con respecto a <span class="math inline">\(p\)</span>, ie. si <span class="math inline">\(n-p\)</span>-es grande, es decir:</p>
<p><span class="math display">\[
\frac{(n-1)p}{n-p}F_{a-\alpha\ ,\ p,n-p} \ \ \approx \ \ \chi_{\alpha\ , \ p}^2.
\]</span></p>
<div class="theorem">
<p><span id="thm:teorema-ics-chi2" class="theorem"><strong>Teorema 4.3  (IC Simultáneos Chi2) </strong></span>Sea <span class="math inline">\(\underline{\mathbf{x}}_1,\underline{\mathbf{x}}_2,\ldots,\underline{\mathbf{x}}_n\)</span> una m.a de una población <span class="math inline">\(p\)</span>-variada, con vector de medias <span class="math inline">\(\underline{\boldsymbol \mu}\)</span> y matriz de var-cov <span class="math inline">\(\mathbf{\Sigma}\)</span>-definida positiva, entonces <em>cuando <span class="math inline">\(n-p\)</span>-es grande</em></p>
</div>
<p>los intervalos:</p>
<p><span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \pm\    \underbrace{ \sqrt{\chi_{\alpha\ ;\ p}^2 }  } \frac{ \sqrt{ \underline{a}^t \mathbf{S} \underline{a}}}{ \sqrt{n} }
\]</span></p>
<p>A diferencia de los IC <span class="math inline">\(T^2\)</span>-Simultáneos y de los IC de Bonferroni:</p>
<p><span class="math display">\[
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \pm\    \underbrace{ \sqrt{\frac{(n-1)p}{(n-p)}\ F_{\alpha\ ;\ p\ ,\  n-p} }  } \frac{ \sqrt{ \underline{a}^t \mathbf{S} \underline{a}}}{ \sqrt{n} }
\ \ \ \ \ \ \ \ \text{y} \ \ \ \ \ \ \
\underline{a}^t\underline{\overline{\mathbf{x}}}\ \pm\  \underbrace{ t_{\alpha/2p\ ;\ n-1}  }\frac{\sqrt{\underline{a}^t \mathbf{S} \underline{a}}}{\sqrt{n}}
\]</span></p>
<p>contendrá a <span class="math inline">\(\underline{a}^t \underline{\boldsymbol{\mu}}\)</span> para todo <span class="math inline">\(\underline{a}\)</span>, con una probabilidad <em>aproximada</em> de <span class="math inline">\((1-\alpha)\)</span>.</p>
<p>A estos I.C simultáneos, se les llaman <strong>Intervalos de Confianza</strong> <span class="math inline">\(\chi^2\)</span>-<strong>simultáneos</strong>, ya que la probabilidad de cobertura de dichos intervalos se determina con la distribución <span class="math inline">\(\chi^2\)</span>.</p>
<p>Por lo tanto, los intervalos o afirmaciones de confianza simultáneos para las componentes de medias <span class="math inline">\(\mu_i\)</span>, con una confianza aproximada del <span class="math inline">\(100(1-\alpha)\%\)</span> son:</p>
<p><span class="math display">\[
\overline{x}_1 - \sqrt{\chi_{\alpha\ ; \ p}^2}\   \sqrt{\frac{s_{11}}{n}} \leq \mu_1 \leq \overline{x}_1 + \sqrt{\chi_{\alpha\ ; \ p}^2}\  \sqrt{\frac{s_{11}}{n}}
\]</span></p>
<p><span class="math display">\[
\overline{x}_2 - \sqrt{\chi_{\alpha\ ; \ p}^2}\  \sqrt{\frac{s_{22}}{n}} \leq \mu_2 \leq \overline{x}_2 + \sqrt{\chi_{\alpha\ ; \ p}^2}\  \sqrt{\frac{s_{22}}{n}}
\]</span></p>
<p><span class="math display">\[
\vdots
\]</span></p>
<p><span class="math display">\[
\vdots
\]</span></p>
<p><span class="math display">\[
\overline{x}_p - \sqrt{\chi_{\alpha\ ; \ p}^2}\  \sqrt{\frac{s_{pp}}{n}} \leq \mu_p \leq \overline{x}_p + \sqrt{\chi_{\alpha\ ; \ p}^2}\  \sqrt{\frac{s_{pp}}{n}}
\]</span></p>
<p>Además, cada par de medias <span class="math inline">\((\mu_i,\mu_k)\)</span>, <span class="math inline">\(i, k=1, 2, \cdots, p\)</span>, estarán contenidas en la elipse de confianza del <span class="math inline">\((1-1)100\%\)</span> dada por:</p>
<p><span class="math display">\[
n\begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}^t \begin{bmatrix}
s_{ii} &amp; s_{ik} \\ s_{ik} &amp; s_{kk}
\end{bmatrix}^{-1}  \begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}  \leq \chi_{\alpha\ ; \ p}^2
\]</span></p>
<p>o equivalentemente:
<span class="math display">\[
\begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}^t \begin{bmatrix}
s_{ii} &amp; s_{ik} \\ s_{ik} &amp; s_{kk}
\end{bmatrix}^{-1}  \begin{bmatrix}
\overline{x}_i-\mu_i \\ \overline{x}_k-\mu_k
\end{bmatrix}  \leq k^2= \frac{ \chi_{\alpha\ ; \ p}^2}{n}
\]</span></p>
<p><strong>Observaciónes:</strong></p>
<p>Es una buena práctica estadística sujetar estos procedimientos para muestras grandes a los mismos chequeos usados para el caso de los métodos normales. Aunque desviaciones pequeñas o moderadas de la normalidad no causan problemas cuando <span class="math inline">\(n\)</span> es grande, las desviaciones extremas sí pueden causarlos. Concretamente, la verdadera tasa de error puede estar lejos de su nivel nominal <span class="math inline">\(\alpha\)</span>.</p>
<p>Si, basados en los gráficos <span class="math inline">\(Q-Q\)</span>-plot y otras herramientas de diagnóstico, se detectan observaciones atípicas y otras formas de desviaciones extremas, se deben aplicar acciones correctivas
adecuadas, las cuales pueden incluir transformaciones de los datos.</p>
<p>En general, los resultados anteriores son útiles para muestras muy grandes.</p>
<div class="example">
<p><span id="exm:ejemplo-ics-chi2" class="example"><strong>Ejemplo 4.33  (Ejemplo IC Simultáneos Chi2) </strong></span>Un profesor de música examinó las habilidades musicales de miles de estudiantes nativos finlandeses para establecer las normas nacionales en Finlandia. Los siguientes resultados están basados en <span class="math inline">\(n=96\)</span> estudiantes.</p>
</div>
<table>
<thead>
<tr class="header">
<th align="center">Variables</th>
<th align="center">Media</th>
<th align="center">Desviación Estándar</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(X_1\)</span>-Melodía</td>
<td align="center"><span class="math inline">\(28.1\)</span></td>
<td align="center"><span class="math inline">\(5.76\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_2\)</span>-Armonía</td>
<td align="center"><span class="math inline">\(26.6\)</span></td>
<td align="center"><span class="math inline">\(5.85\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_3\)</span>-Tono</td>
<td align="center"><span class="math inline">\(35.4\)</span></td>
<td align="center"><span class="math inline">\(3.82\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_4\)</span>-Métrica</td>
<td align="center"><span class="math inline">\(34.2\)</span></td>
<td align="center"><span class="math inline">\(5.12\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_5\)</span>-Fraséo</td>
<td align="center"><span class="math inline">\(23.6\)</span></td>
<td align="center"><span class="math inline">\(3.76\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_6\)</span>-Balance</td>
<td align="center"><span class="math inline">\(22.0\)</span></td>
<td align="center"><span class="math inline">\(3.93\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_7\)</span>-Estilo</td>
<td align="center"><span class="math inline">\(22.7\)</span></td>
<td align="center"><span class="math inline">\(4.03\)</span></td>
</tr>
</tbody>
</table>
<p>De los resultados anteriores, los intervalos simultáneos del <span class="math inline">\(90\%\)</span> de confianza para las componentes de medias <span class="math inline">\(\mu_i\)</span>, <span class="math inline">\(i=1,2,\ldots,p=7\)</span> son de la forma:
<span class="math display">\[
\overline{x}_i\ \pm\ \sqrt{\chi_{1-\alpha\ , \ p=7}^2 }  \sqrt{\frac{s_{ii}}{n}}
\]</span></p>
<p>donde <span class="math inline">\(\chi_{0.9\ ; \ 7}^2 =12.017\)</span>.</p>
<p>Por lo tanto, con una confianza aproximada del <span class="math inline">\(90\%\)</span> los intervalos de confianza <span class="math inline">\(\chi^2\)</span>-simultáneos para cada media <span class="math inline">\(\mu_i\)</span> están dados por:</p>
<p><span class="math display">\[
\overline{x}_1 - \sqrt{\chi_{1-\alpha\ , \ p}^2 }\  \sqrt{\frac{S_{11}}{n} }\ \ \  \leq \mu_1 \leq \ \ \ \overline{x}_1 + \sqrt{\chi_{1-\alpha\ , \ p}^2 }\  \sqrt{\frac{S_{11}}{n} }
\]</span></p>
<p><span class="math display">\[
28.1 - \sqrt{12.017}  \sqrt{\frac{33.1776}{96} } \ \ \ \leq \mu_1 \leq \ \ \ 28.1 + \sqrt{12.017}  \sqrt{\frac{33.1776}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_1 \ \ \ \in \ \ \ \ 26.0621\ \ \ \leq \mu_1 \leq \ \ \   30.1379
\]</span></p>
<p><span class="math display">\[
\overline{x}_2 - \sqrt{\chi_{1-\alpha\ , \ p}^2 }\  \sqrt{\frac{S_{22}}{n} }\ \ \  \leq \mu_2 \leq \ \ \
\overline{x}_2 + \sqrt{\chi_{1-\alpha\ , \ p}^2 } \ \sqrt{\frac{S_{22}}{n} }
\]</span></p>
<p><span class="math display">\[
26.6 - \sqrt{12.017}  \sqrt{\frac{34.2225}{96} } \ \ \ \leq \mu_2 \leq \ \ \
26.6 + \sqrt{12.017}  \sqrt{\frac{34.2225}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_2 \ \ \ \in \ \ \ \ 24.5302\ \ \ \leq \mu_2 \leq \ \ \   
28.6698
\]</span></p>
<p><span class="math display">\[
\overline{x}_3 - \sqrt{\chi_{1-\alpha\ , \ p}^2 }\  \sqrt{\frac{S_{33}}{n} }\ \ \  \leq \mu_3 \leq \ \ \
\overline{x}_3 + \sqrt{\chi_{1-\alpha\ , \ p}^2 }\  \sqrt{\frac{S_{33}}{n} }
\]</span></p>
<p><span class="math display">\[
35.4 - \sqrt{12.017}  \sqrt{\frac{14.5924}{96} } \ \ \ \leq \mu_3 \leq \ \ \
35.4 + \sqrt{12.017}  \sqrt{\frac{14.5924}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_3 \ \ \ \in \ \ \ \ 34.0485\ \ \ \leq \mu_3 \leq \ \ \   
36.7515
\]</span></p>
<p><span class="math display">\[
\overline{x}_4 - \sqrt{\chi_{1-\alpha\ , \ p}^2 }\  \sqrt{\frac{S_{44}}{n} }\ \ \  \leq \mu_4 \leq \ \ \
\overline{x}_4 + \sqrt{\chi_{1-\alpha\ , \ p}^2 }\  \sqrt{\frac{S_{44}}{n} }
\]</span></p>
<p><span class="math display">\[
34.2 - \sqrt{12.017}  \sqrt{\frac{26.2144}{96} } \ \ \ \leq \mu_4 \leq \ \ \
34.2 + \sqrt{12.017}  \sqrt{\frac{26.2144}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_4 \ \ \ \in \ \ \ \ 32.3885\ \ \ \leq \mu_4 \leq \ \ \   
36.0115
\]</span></p>
<p><span class="math display">\[
\overline{x}_5 - \sqrt{\chi_{1-\alpha\ , \ p}^2 } \ \sqrt{\frac{S_{55}}{n} }\ \ \  \leq \mu_5 \leq \ \ \
\overline{x}_5 + \sqrt{\chi_{1-\alpha\ , \ p}^2 } \ \sqrt{\frac{S_{55}}{n} }
\]</span></p>
<p><span class="math display">\[
23.6 - \sqrt{12.017}  \sqrt{\frac{14.1376}{96} } \ \ \ \leq \mu_5 \leq \ \ \
23.6 + \sqrt{12.017}  \sqrt{\frac{14.1376}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_5 \ \ \ \in \ \ \ \ 22.2697\ \ \ \leq \mu_5 \leq \ \ \   
24.9303
\]</span></p>
<p><span class="math display">\[
\overline{x}_6 - \sqrt{\chi_{1-\alpha\ , \ p}^2 } \ \sqrt{\frac{S_{66}}{n} }\ \ \  \leq \mu_6 \leq \ \ \
\overline{x}_6 + \sqrt{\chi_{1-\alpha\ , \ p}^2 } \ \sqrt{\frac{S_{66}}{n} }
\]</span></p>
<p><span class="math display">\[
22 - \sqrt{12.017}  \sqrt{\frac{15.4449}{96} } \ \ \ \leq \mu_6 \leq \ \ \
22 + \sqrt{12.017}  \sqrt{\frac{15.4449}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_6 \ \ \ \in \ \ \ \ 20.6096\ \ \ \leq \mu_6 \leq \ \ \   
23.3904
\]</span></p>
<p><span class="math display">\[
\overline{x}_7 - \sqrt{\chi_{1-\alpha\ , \ p}^2 } \ \sqrt{\frac{S_{77}}{n} }\ \ \  \leq \mu_7 \leq \ \ \
\overline{x}_7 + \sqrt{\chi_{1-\alpha\ , \ p}^2 } \ \sqrt{\frac{S_{77}}{n} }
\]</span></p>
<p><span class="math display">\[
22.7 - \sqrt{12.017}  \sqrt{\frac{16.2409}{96} } \ \ \ \leq \mu_7 \leq \ \ \
22.7 + \sqrt{12.017}  \sqrt{\frac{16.2409}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_7 \ \ \ \in \ \ \ \ 21.2742\ \ \ \leq \mu_7 \leq \ \ \   
24.1258
\]</span></p>
</div>
<div id="ic-simultáneos-para-n-grande-usando-la-normal-estándar-z_alpha" class="section level3 hasAnchor" number="4.9.7">
<h3><span class="header-section-number">4.9.7</span> IC Simultáneos para n-Grande Usando la Normal Estándar <span class="math inline">\(Z_\alpha\)</span><a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#ic-simultáneos-para-n-grande-usando-la-normal-estándar-z_alpha" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora, basado en miles de estudiantes americanos, el investigador podría querer probar la hipótesis de que el perfil musical esta dado por:
<span class="math display">\[
\underline{\boldsymbol \mu}=\underline{\boldsymbol \mu}_{\ 0}=\begin{bmatrix}
31 \\ 27 \\ 34 \\ 31 \\ 23 \\ 22 \\ 22
\end{bmatrix}
\]</span></p>
<p>De los intervalos o afirmaciones simultáneos anteriores, se observa que las componentes de <em>melodía</em> (<span class="math inline">\(X_1\)</span>), <em>tono</em> (<span class="math inline">\(X_3\)</span>) y <em>métrica</em> (<span class="math inline">\(X_4\)</span>) de <span class="math inline">\(\underline{\boldsymbol \mu}_{\ 0}\)</span> no parecen ser valores viables para los valores de las medias correspondientes a los estudiantes finlandeses.</p>
<p>Cuando el tamaño muestral es grande, los intervalos de confianza uno a la vez o separados para las medias individuales <span class="math inline">\(\mu_i\)</span> son de la forma:
<span class="math display">\[
\overline{x}_i - Z_{\alpha/2}  \sqrt{\frac{s_{ii}}{n}} \leq \mu_i \leq \overline{x}_i
+ Z_{\alpha/2}  \sqrt{\frac{s_{ii}}{n}} \ , \ \ i=1,2,\ldots,p
\]</span>
donde <span class="math inline">\(Z_{\alpha/2}\)</span> es el percentil <span class="math inline">\((1-\alpha/2)100\)</span>-superior de la distribución normal estándar, ie. de la <span class="math inline">\(N(0,1)\)</span>.</p>
<p><strong>Los intervalos de confianza simultáneos de Bonferroni</strong> para <span class="math inline">\(m=p\)</span>-afirmaciones sobre las medias individuales tienen la misma forma vista anteriormente (ver. <a href="regiones-de-confianza-y-comparaciones-simultáneas-entre-las-componentes-del-vector-de-medias-underlineboldsymbol-mu.html#IC-Bonferroni">4.9.5</a>), <strong>pero con valores críticos dados por</strong> <span class="math inline">\(Z_{\alpha/2p}\)</span>, es decir:</p>
<p><span class="math display">\[
\overline{x}_i - Z_{\alpha /2p}\  \sqrt{\frac{s_{ii}}{n}} \leq \mu_i \leq \overline{x}_i - Z_{\alpha/2p}\   \sqrt{\frac{s_{ii}}{n}} \ , \ \ i=1,2,\ldots,p
\]</span></p>
<p>La siguiente tabla presenta los intervalos de confianza individuales o uno a la vez <span class="math inline">\(Z_{\alpha/2}\)</span>, IC de Bonferroni usando <span class="math inline">\(Z_{\alpha/2p}\)</span> y los IC <span class="math inline">\(\chi^2\)</span>-simultáneos ( los cuales son las sombras o proyecciones de las elipses de confianza usando <span class="math inline">\(\chi^2_{1-\alpha\ ,\ p}\approx F_{1-\alpha\ ; \ p,n-p }\)</span>) para los datos de aptitud musical.</p>
<p>Los percentiles usados para cada caso son:</p>
<p><span class="math display">\[
Z_{\alpha/2}=Z_{0.975}=1.96\ \ ; \ \ Z_{\alpha/2p}=Z_{1-0.05/(2*7)}=Z_{0.996}=2.69 \ \  \  y \ \ \chi^2_{\alpha\ ,\ p}=\chi_{0.95\ , \ 7}^2=14.07
\]</span>.</p>
<table>
<colgroup>
<col width="12%" />
<col width="29%" />
<col width="32%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Variables</th>
<th align="center">Intervalos <span class="math inline">\(Z_{\alpha/2}=1.96\)</span></th>
<th align="center">Intervalos de Bonferroni con <span class="math inline">\(Z_{\alpha/2p}=2.69\)</span></th>
<th align="center">Intervalos <span class="math inline">\(\chi^2\)</span> (o sombras de <span class="math inline">\(\chi^2(\alpha)=14.07\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(X_1\)</span></td>
<td align="center">26.95 - 29.25</td>
<td align="center">25.52 - 29.68</td>
<td align="center">25.90 - 30.30</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_2\)</span></td>
<td align="center">25.43 - 27.77</td>
<td align="center">24.99 - 28.21</td>
<td align="center">24.36 - 28.84</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_3\)</span></td>
<td align="center">34.64 - 36.16</td>
<td align="center">34.35 - 36.45</td>
<td align="center">33.94 - 36.86</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_4\)</span></td>
<td align="center">33.18 - 35.22</td>
<td align="center">32.79 - 35.61</td>
<td align="center">32.24 - 36.16</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_5\)</span></td>
<td align="center">22.85 - 24.35</td>
<td align="center">22.57 - 24.63</td>
<td align="center">22.16 - 25.04</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_6\)</span></td>
<td align="center">21.21 - 22.79</td>
<td align="center">20.92 - 23.08</td>
<td align="center">20.50 - 23.50</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_7\)</span></td>
<td align="center">21.89 - 23.51</td>
<td align="center">21.59 - 23.81</td>
<td align="center">21.16 - 24.24</td>
</tr>
</tbody>
</table>
<p><strong>Por ejemplo</strong>, para la variable <span class="math inline">\(X_1\)</span> se tienen los cálculos dados por:</p>
<p><span class="math display">\[
\overline{x}_1 -  Z_{\alpha/2}  \sqrt{\frac{S_{11}}{n} }\ \ \  \leq \mu_1 \leq \ \ \ \overline{x}_1
+  Z_{\alpha/2}  \sqrt{\frac{S_{11}}{n} }
\]</span>
<span class="math display">\[
28.1 - 1.96  \sqrt{\frac{33.1776}{96} } \ \ \ \leq \mu_1 \leq \ \ \ 28.1 +
1.96  \sqrt{\frac{33.1776}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_1 \ \ \ \in \ \ \ \ 26.9478\ \ \ \leq \mu_1 \leq \ \ \   29.2522
\]</span></p>
<p><span class="math display">\[
\overline{x}_1 - Z_{\alpha /2p}  \sqrt{\frac{S_{11}}{n} }\ \ \  \leq \mu_1 \leq \ \ \ \overline{x}_1
+ Z_{\alpha /2p}  \sqrt{\frac{S_{11}}{n} }
\]</span>
<span class="math display">\[
28.1 - 2.6901  \sqrt{\frac{33.1776}{96} } \ \ \ \leq \mu_1 \leq \ \ \ 28.1 +
2.6901  \sqrt{\frac{33.1776}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_1 \ \ \ \in \ \ \ \ 26.5186\ \ \ \leq \mu_1 \leq \ \ \   29.6814
\]</span></p>
<p><span class="math display">\[
\overline{x}_1 - \sqrt{\chi_{1-\alpha\ , \ p}^2 }  \sqrt{\frac{S_{11}}{n} }\ \ \  \leq \mu_1 \leq \ \ \ \overline{x}_1 + \sqrt{\chi_{1-\alpha\ , \ p}^2 }  \sqrt{\frac{S_{11}}{n} }
\]</span>
<span class="math display">\[
28.1 - \sqrt{14.0671}  \sqrt{\frac{33.1776}{96} } \ \ \ \leq \mu_1 \leq \ \ \ 28.1 + \sqrt{14.0671}  \sqrt{\frac{33.1776}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_1 \ \ \ \in \ \ \ \ 25.8951\ \ \ \leq \mu_1 \leq \ \ \   30.3049
\]</span></p>
<p>Aunque el tamaño muestral puede ser grande, en la práctica algunos estadísticos, <em>generalmente prefieren usar los percentiles basados en las distribuciones <span class="math inline">\(F\)</span> y <span class="math inline">\(t\)</span> de Student</em> <strong>en lugar de usar</strong> <em>los percentiles basados en la distribución chi-cuadrado y normal estándar</em>. Estos últimos valores (ie. los percentiles d ela chi-cuadrado y la normal) son los límites de los valores de las distribuciones <span class="math inline">\(F\)</span> y <span class="math inline">\(t\)</span> para tamaños muestrales infinitos.</p>
<p>Los valores de los percentiles basados en las distribuciones <span class="math inline">\(F\)</span> y <span class="math inline">\(t\)</span> <em>producen intervalos más amplios y por tanto, son más conservadores</em>.</p>
<p>La siguiente tabla presenta IC usando los valores de los percentiles basados en las distribuciones <span class="math inline">\(F\)</span> y <span class="math inline">\(t\)</span>, es decir, los intervalos de confianza individuales con <span class="math inline">\(t_{\alpha/2,n-1}\)</span>, los IC de Bonferroni usando <span class="math inline">\(t_{\alpha/2p,n-1}\)</span> y los IC <span class="math inline">\(T^2\)</span>-simultáneos ( los cuales son las sombras o proyecciones de las elipses de confianza usando <span class="math inline">\(F_{1-\alpha\ ; \ p,n-p }\)</span>) para los datos de aptitud musical.</p>
<p>Los valoresm críticos de los percentiles usados para cada caso son:</p>
<p><span class="math display">\[
t_{\alpha/2,n-1}=t_{0.975\ , \ 95}=1.99 \ \ ,\ \  t_{1-\alpha/2p,n-1}=t_{1-0.05/(2*7)\ , \ 95}=2.75 \ \ \  y \ \ \  F_{0.05\ ; \ 7\ ,\ 89}=2.11
\]</span></p>
<table>
<colgroup>
<col width="12%" />
<col width="29%" />
<col width="32%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Variables</th>
<th align="center">Intervalos <span class="math inline">\(t\)</span>-Student <span class="math inline">\(t_{\alpha/2,n-1}=1.99\)</span></th>
<th align="center">Intervalos de Bonferroni con <span class="math inline">\(t_{1-\alpha/2p,n-1}=2.75\)</span></th>
<th align="center">Intervalos <span class="math inline">\(T^2\)</span> (o sombras de <span class="math inline">\(F_{1-\alpha\ ; \ p,n-p }=2.11\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(X_1\)</span></td>
<td align="center">26.93 - 29.27</td>
<td align="center">26.48 - 29.72</td>
<td align="center">25.76 - 30.44</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_2\)</span></td>
<td align="center">25.41 - 27.79</td>
<td align="center">24.96 - 28.24</td>
<td align="center">24.23 - 28.97</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_3\)</span></td>
<td align="center">34.63 - 36.17</td>
<td align="center">34.33 - 36.47</td>
<td align="center">33.85 - 36.95</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_4\)</span></td>
<td align="center">33.16 - 35.24</td>
<td align="center">32.76 - 35.64</td>
<td align="center">32.12 - 36.28</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_5\)</span></td>
<td align="center">22.84 - 24.36</td>
<td align="center">22.54 - 24.66</td>
<td align="center">22.07 - 25.13</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(X_6\)</span></td>
<td align="center">21.20 - 22.80</td>
<td align="center">20.90 - 23.10</td>
<td align="center">20.41 - 23.59</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(X_7\)</span></td>
<td align="center">21.88 - 23.52</td>
<td align="center">21.57 - 23.83</td>
<td align="center">21.07 - 24.33</td>
</tr>
</tbody>
</table>
<p><strong>Por ejemplo</strong>, para la variable <span class="math inline">\(X_1\)</span> se tienen los cálculos dados por:</p>
<p><span class="math display">\[
\overline{x}_1 -  t_{1-\alpha/2,n-1}  \sqrt{\frac{S_{11}}{n} }\ \ \  \leq \mu_1 \leq \ \ \ \overline{x}_1
+  t_{1-\alpha/2,n-1}  \sqrt{\frac{S_{11}}{n} }
\]</span>
<span class="math display">\[
28.1 - 1.9853  \sqrt{\frac{33.1776}{96} } \ \ \ \leq \mu_1 \leq \ \ \ 28.1 +
1.9853  \sqrt{\frac{33.1776}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_1 \ \ \ \in \ \ \ \ 26.9329\ \ \ \leq \mu_1 \leq \ \ \   29.2671
\]</span></p>
<p><span class="math display">\[
\overline{x}_1 - t_{1-\alpha /2p,n-1}  \sqrt{\frac{S_{11}}{n} }\ \ \  \leq \mu_1 \leq \ \ \ \overline{x}_1
+ t_{1-\alpha /2p,n-1}  \sqrt{\frac{S_{11}}{n} }
\]</span>
<span class="math display">\[
28.1 - 2.7496  \sqrt{\frac{33.1776}{96} } \ \ \ \leq \mu_1 \leq \ \ \ 28.1 +
2.7496  \sqrt{\frac{33.1776}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_1 \ \ \ \in \ \ \ \ 26.4836\ \ \ \leq \mu_1 \leq \ \ \   29.7164
\]</span></p>
<p><span class="math display">\[
\overline{x}_1 - \sqrt{ \frac{(n-1)p}{n-p}F_{1-\alpha\ ; \ p,n-p} }  \sqrt{\frac{S_{11}}{n} }\ \ \  \leq \mu_1 \leq \ \ \ \overline{x}_1 + \sqrt{ \frac{(n-1)p}{n-p}F_{1-\alpha\ ; \ p,n-p} }  \sqrt{\frac{S_{11}}{n} }
\]</span>
<span class="math display">\[
28.1 - \sqrt{15.7975}  \sqrt{\frac{33.1776}{96} } \ \ \ \leq \mu_1 \leq \ \ \ 28.1 + \sqrt{15.7975}  \sqrt{\frac{33.1776}{96} }
\]</span></p>
<p><span class="math display">\[
\ \ \mu_1 \ \ \ \in \ \ \ \ 25.7634\ \ \ \leq \mu_1 \leq \ \ \   30.4366
\]</span></p>
<p>Comparando las dos últimas tablas, se observa que <strong>todos los intervalos de la última tabla son más amplios</strong>. Sin embargo, debido al tamaño relativamente grande de <span class="math inline">\(n=96\)</span>, <strong>las diferencias son de décimas</strong>.</p>
<p><strong>Observación final:</strong></p>
<p>Finalmente, la independencia de las observaciones multivariadas es crucial, y los resultados vistos basados sobre este supuesto pueden estar muy equivocados si las observaciones son dependientes.</p>
<p><strong>Lectura:</strong> Inferencias para muestras grandes sobre proporciones, ver. <span class="citation">(<a href="#ref-johnson2007applied">Johnson and Wichern 2007</a>,pag. 234)</span>.</p>

</div>
</div>
<!-- </div> -->
<h3>Bibliografía<a href="bibliografía.html#bibliografía" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-johnson2007applied" class="csl-entry">
Johnson, Richard A, and Dean W Wichern. 2007. <em>Applied Multivariate Statistical Analysis. 6th</em>. <em>New Jersey, US: Pearson Prentice Hall</em>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inferencia-para-la-matriz-de-varianzas-covarianza.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mrlm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-iam.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsubsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
